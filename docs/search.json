[
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "El curso de Estadística Correlacional considera la elaboración de un trabajo grupal como instancia final de evaluación. El trabajo a realizar es la elaboración de un reporte de análisis bivariado.\nLa nota de este trabajo equivale a un 30% de la nota final del curso, donde 20% equivale al reporte escrito y 10% a la presentación (en formato póster)."
  },
  {
    "objectID": "trabajos.html#organización-de-actividades",
    "href": "trabajos.html#organización-de-actividades",
    "title": "Trabajos",
    "section": "9.1 Organización de actividades",
    "text": "9.1 Organización de actividades\nHay 4 semanas para realizar el trabajo. Durante este tiempo los horarios de clases estarán destinados a contenidos asociados a la realización de los reportes, así como también a asesorar a los grupos. Se sugiere organizar las actividades de la siguiente manera:\n\nSemana 1: definición de grupos, temas y base de datos\nSemana 2: análisis descriptivos univariados, chequeo de nivel de medición de variables, varianza y casos perdidos\nSemana 3: escritura de introducción y análisis bivariados. Diseño de póster.\nSemana 4: conclusiones y redacción final, presentación de póster y entrega de reporte."
  },
  {
    "objectID": "trabajos.html#escritura-académica",
    "href": "trabajos.html#escritura-académica",
    "title": "Trabajos",
    "section": "9.2 Escritura académica",
    "text": "9.2 Escritura académica\n\nUna idea por párrafo\nUso de “oración principal” (topic sentence): usualmente es la oración al principio del párrafo, que resume el sentido del párrafo completo y que conecta con el párrafo anterior.\nRecursos de apoyo a la escritura académica de la Universidad de Chile"
  },
  {
    "objectID": "trabajos.html#a-tener-en-cuenta",
    "href": "trabajos.html#a-tener-en-cuenta",
    "title": "Trabajos",
    "section": "9.3 A tener en cuenta:",
    "text": "9.3 A tener en cuenta:\n\nlos conceptos centrales deben estar en las hipótesis y también luego operacionalizarse en variables. No presentar variables que no se relacionen con los conceptos centrales de la sección inicial\nsi hay muchos casos perdidos (mas de un tercio de datos originales), explicar claramente a qué se debe esta pérdida. Existe la posibilidad de recuperar casos perdidos de predictores categóricos (o recodificados a categóricos) agregando una categoría adicional de perdidos. Esto se explica en la guía de índices y transformación de variables.\ninterpretación de hipótesis e inferencia: las hipótesis nunca se comprueban o se descartan, solo se puede hablar de que existe o no existe evidencia a favor de la hipótesis planteada. Recordar que la ausencia de evidencia no es evidencia de ausencia.\nevitar términos técnicos estadísticos (ej: correlación) antes de la sección de metodología\nmantener coherencia entre conceptos, hipótesis, descripción de variables, análisis, discusión, ojalá siempre en el mismo orden."
  },
  {
    "objectID": "schedule2.html",
    "href": "schedule2.html",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\n\nMiércoles 27\n\n[suspensión]\n\n\n\n\n Septiembre \n\n\n\n\n\n\nLunes 1\n[suspensión]\n\n\n\n\n\nMiércoles 03\n\nPráctico Inferencia 2\n\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\nEjercicio preparación prueba\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\n\nLunes 22\nEvaluación 1\n\n\n\n\n\nMiércoles 24\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n\n Octubre \n\n\n\n\n\n\nMiércoles 01\n\nPráctico. Bivariada 1\n\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 2\n\n\n\n\nLunes 13\n\nPráctico: Bivariada 3\n\n\n\n\nMiércoles 15\nPreparación prueba 2\n\n\n\n\n\nLunes 20\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\n\n\nMiércoles 22\nSeminario de Encuestas\nDefinición de grupos y temas\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n\n Noviembre\n\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n\n Noviembre\n\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule2.html#forma-general-de-funcionamiento",
    "href": "schedule2.html#forma-general-de-funcionamiento",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\n\nMiércoles 27\n\n[suspensión]\n\n\n\n\n Septiembre \n\n\n\n\n\n\nLunes 1\n[suspensión]\n\n\n\n\n\nMiércoles 03\n\nPráctico Inferencia 2\n\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\nEjercicio preparación prueba\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\n\nLunes 22\nEvaluación 1\n\n\n\n\n\nMiércoles 24\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n\n Octubre \n\n\n\n\n\n\nMiércoles 01\n\nPráctico. Bivariada 1\n\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 2\n\n\n\n\nLunes 13\n\nPráctico: Bivariada 3\n\n\n\n\nMiércoles 15\nPreparación prueba 2\n\n\n\n\n\nLunes 20\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\n\n\nMiércoles 22\nSeminario de Encuestas\nDefinición de grupos y temas\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n\n Noviembre\n\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n\n Noviembre\n\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule2.html#exámenes-finales-orales",
    "href": "schedule2.html#exámenes-finales-orales",
    "title": "Planificación",
    "section": "Exámenes finales (orales)",
    "text": "Exámenes finales (orales)\nVer requisitos de aprobación y eximición\n\nExamen de primera oportunidad: Miércoles 11 Diciembre desde las 9:30\nExamen de segunda oportunidad: Lunes 16 Diciembre desde las 10:15"
  },
  {
    "objectID": "resource/varios.html",
    "href": "resource/varios.html",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#reporte",
    "href": "resource/varios.html#reporte",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#estadística-descriptiva",
    "href": "resource/varios.html#estadística-descriptiva",
    "title": "Varios",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#uso-de-r",
    "href": "resource/varios.html#uso-de-r",
    "title": "Varios",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#inferencia",
    "href": "resource/varios.html#inferencia",
    "title": "Varios",
    "section": "Inferencia",
    "text": "Inferencia\n\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#visualización",
    "href": "resource/varios.html#visualización",
    "title": "Varios",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#bases-de-datos",
    "href": "resource/varios.html#bases-de-datos",
    "title": "Varios",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "En esta sección se irán subiendo una serie de recursos relacionados con el curso.",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#glosario-de-conceptos",
    "href": "resource/index.html#glosario-de-conceptos",
    "title": "Recursos",
    "section": "Glosario de conceptos",
    "text": "Glosario de conceptos\n\n\n\nConcepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#reporte",
    "href": "resource/index.html#reporte",
    "title": "Recursos",
    "section": "Reporte",
    "text": "Reporte\n\nTablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#estadística-descriptiva",
    "href": "resource/index.html#estadística-descriptiva",
    "title": "Recursos",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#uso-de-r",
    "href": "resource/index.html#uso-de-r",
    "title": "Recursos",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#inferencia",
    "href": "resource/index.html#inferencia",
    "title": "Recursos",
    "section": "Inferencia",
    "text": "Inferencia\n\nInfer: Inferencia estadística en R, acá video tutorial en español\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#visualización",
    "href": "resource/index.html#visualización",
    "title": "Recursos",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#bases-de-datos",
    "href": "resource/index.html#bases-de-datos",
    "title": "Recursos",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Informaciones",
    "section": "",
    "text": "Acá las principales informaciones y actualizaciones del curso.\n\n\n   \n    \n    \n      Ordenar por\n      Por defecto\n      \n        Fecha - Menos reciente\n      \n      \n        Fecha - Más reciente\n      \n      \n        Título\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nFecha\n\n\n\nTítulo\n\n\n\nCategorías\n\n\n\n\n\n\n\n\nmartes octubre 14, 2025 at 12:00 AM\n\n\nPreparación Evaluación 2\n\n\ninfo, mail-UCursos\n\n\n\n\n\n\nmiércoles septiembre 24, 2025 at 12:00 AM\n\n\nReporte Evaluación 1\n\n\ninfo, mail-UCursos\n\n\n\n\n\n\nmartes agosto 19, 2025 at 12:00 AM\n\n\nInicio practicos\n\n\ninfo\n\n\n\n\n\n\nmiércoles agosto 13, 2025 at 12:00 AM\n\n\nPadlet\n\n\ninfo\n\n\n\n\n\n\nlunes agosto 19, 2024 at 12:00 AM\n\n\nInformaciones por acá\n\n\ninfo\n\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes.\n\n\n\n\n\n RSS"
  },
  {
    "objectID": "news/2025-09-25_reporte-notas1.html",
    "href": "news/2025-09-25_reporte-notas1.html",
    "title": "Reporte Evaluación 1",
    "section": "",
    "text": "← News\nEste reporte realiza un análisis de la Evaluación 1 sobre la Unidad 1: Inferencia estadística"
  },
  {
    "objectID": "news/2025-09-25_reporte-notas1.html#solicitudes-de-recorrección",
    "href": "news/2025-09-25_reporte-notas1.html#solicitudes-de-recorrección",
    "title": "Reporte Evaluación 1",
    "section": "Solicitudes de recorrección",
    "text": "Solicitudes de recorrección\n\nEnviar correo a apoyo docente Kevin Carrasco, kevin.carrasco@uchile.cl, quien estará coordinando estas solicitudes\nEn el correo:\n\nmencionar pregunta a corregir\nargumento y puntaje esperado\nfoto de la pregunta\n\n\nSolicitudes hasta el miércoles 1 de Octubre 23:59, las solicitudes se responderán en un plazo máximo el lunes 6 de Octubre."
  },
  {
    "objectID": "news/2025-09-25_reporte-notas1.html#etiquetados",
    "href": "news/2025-09-25_reporte-notas1.html#etiquetados",
    "title": "Reporte Evaluación 1",
    "section": "Etiquetados",
    "text": "Etiquetados\n\n# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Error tipo II\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Significancia\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistencia &lt;- set_label(x = prueba1$asistencia, \n                         label = \"Asistencia \")\nprueba1$grupo &lt;- set_label(x = prueba1$grupo, \n                         label = \"Grupo u-cursos\")"
  },
  {
    "objectID": "news/2025-09-25_reporte-notas1.html#tabla-descriptiva",
    "href": "news/2025-09-25_reporte-notas1.html#tabla-descriptiva",
    "title": "Reporte Evaluación 1",
    "section": "Tabla descriptiva",
    "text": "Tabla descriptiva\n\nprueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n3\np1a\nError tipo II\n75\n0.53\n0.45\n1 (0-1)\n\n\n4\np1b\nSignificancia\n75\n0.30\n0.43\n1 (0-1)\n\n\n5\np1c\nRechazo H0 valor p\n75\n0.27\n0.49\n2 (0-2)\n\n\n6\np2a\nFormulación hipótesis\n75\n1.69\n0.60\n2 (0-2)\n\n\n7\np2b\nContraste de prueba t\n75\n2.82\n1.40\n4 (0-4)\n\n\n8\np2c\nIntervalo confianza de prueba t\n75\n1.32\n0.81\n2 (0-2)\n\n\n9\npuntaje\npuntaje\n75\n6.94\n2.58\n11 (0-11)\n\n\n2\nnota\nNota final\n75\n44.91\n12.93\n55 (10-65)\n\n\n1\nasistencia\nAsistencia\n75\n52.86\n19.86\n71.4 (14.3-85.7)"
  },
  {
    "objectID": "news/2025-09-25_reporte-notas1.html#gráficos-descriptivos",
    "href": "news/2025-09-25_reporte-notas1.html#gráficos-descriptivos",
    "title": "Reporte Evaluación 1",
    "section": "Gráficos descriptivos",
    "text": "Gráficos descriptivos\n\nhist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,40,50,60, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n22\n29.33\n29.33\n29.33\n\n\n\n4.0-5.0\n26\n34.67\n34.67\n64.00\n\n\n\n5.0-6.0\n24\n32.00\n32.00\n96.00\n\n\n\n6.0-7.0\n3\n4.00\n4.00\n100.00\n\n\n\ntotal N=75 · valid N=72 · x̄=2.11 · σ=0.88\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "news/2025-08-12_padlet.html",
    "href": "news/2025-08-12_padlet.html",
    "title": "Padlet",
    "section": "",
    "text": "← News\n\n\n\n\n\nVamos a probar Padlet para realizar preguntas sobre los contenidos del curso, se pueden hacer durante o después de clases, pueden ser anónimas.\nLink: https://padlet.com/juancarloscastillo/correlacional\nY acá disponible (con QR):"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "",
    "text": "Inferencia, asociación y reporte\n        \n        \n            SOC01019 • Segundo Semestre 2025Departamento de Sociología, Facultad de Ciencias SocialesUniversidad de Chile"
  },
  {
    "objectID": "index.html#últimas-informaciones",
    "href": "index.html#últimas-informaciones",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Últimas informaciones",
    "text": "Últimas informaciones\n\n\n\n\n\n\n\n\nInformaciones Evaluación 2\n\n\n\n\n\n\n\n\n\nOct 21, 2025\n\n\n\n\n\n\n\n\n\n\n\nPreparación Evaluación 2\n\n\n\n\n\n\n\n\n\nOct 14, 2025\n\n\n\n\n\n\n\n\n\n\n\nReporte Evaluación 1\n\n\n\n\n\n\n\n\n\nSep 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nInicio practicos\n\n\n\n\n\n\n\n\n\nAug 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPadlet\n\n\n\n\n\n\n\n\n\nAug 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformaciones por acá\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\nNo matching items\n\n-&gt; ir a la página de Informaciones del sitio."
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "evaluations/prueba2.html",
    "href": "evaluations/prueba2.html",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "",
    "text": "Usted es parte de un equipo de investigación en un centro de estudios que se encuentra analizando cómo ciertos factores sociales se asocian con actitudes políticas. El centro realizó una encuesta y cuenta con una base de datos con las siguientes variables:\nLa base de datos se encuentra aquí: link"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "href": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?",
    "text": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?\n1.1 Estime la asociación entre ambas variables utilizando R y genere un diagrama de dispersión (nube de puntos/scatterplot). Corte y pegue el código en el recuadro de abajo. (1p)\n1.2 Interprete el coeficiente de correlación (considerando inferencia estadística, magnitud y sentido del efecto). (3p)"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?",
    "text": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?\n2.1 Estime y reporte la matriz de correlaciones de las variables de nivel educacional, autoritarismo y los ingresos. (1p)\n2.2 Tomando en cuenta la Tabla 1 comente sobre el tratamiento de casos perdidos en el cálculo de las correlaciones, así como también del tipo de correlación calculada entre ingresos y educación. (3p)\n\n\n\n\nTabla 1: Distribución de casos perdidos por variable\n\n\n\n\n\n\n\nVariable\nEtiqueta\nn casos perdidos\n% casos perdidos\n\n\n\n\neduc_rec\nNivel educacional\n0\n0%\n\n\ningresos\nIngresos\n150\n15%\n\n\nautoritarismo\nAutoritarismo\n10\n1%"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?",
    "text": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?\nUtilizando la versión categórica de ingresos:\n3.1 Reporte tabla de contigencia y el calculo de Chi2 (corte y pegue el código). (1p)\n3.2 Interprete el Chi2 en términos de inferencia y magnitud del efecto. (3p)"
  },
  {
    "objectID": "evaluations/index.html",
    "href": "evaluations/index.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "evaluations/index.html#descripción",
    "href": "evaluations/index.html#descripción",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "content/foro-clases.html",
    "href": "content/foro-clases.html",
    "title": "Foro clases",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre los contenidos del curso vistos en clases. Para poder participar en el foro hay que abir una cuenta en Github",
    "crumbs": [
      "Clases",
      "Foro Clases"
    ]
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Asociación con categóricas 2: Chi 2",
    "section": "",
    "text": "Sesión del domingo, 5 de octubre de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 5"
    ]
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Ordinales y matrices",
    "section": "",
    "text": "Sesión del miércoles, 24 de septiembre de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 3"
    ]
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Bivariada 1 - Asociación y covarianza",
    "section": "",
    "text": "Sesión del lunes, 8 de septiembre de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 1"
    ]
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Inferencia 5 - Prueba t + hipótesis direccionales",
    "section": "",
    "text": "Sesión del lunes, 25 de agosto de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 5"
    ]
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Inferencia 3 - Intervalos de confianza",
    "section": "",
    "text": "Sesión del martes, 20 de agosto de 2024\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 3"
    ]
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Inferencia 1: Datos, probabilidad y distribuciones muestrales",
    "section": "",
    "text": "Sesión del miércoles, 6 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 1"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html",
    "href": "assignment/resumen-asociacion.html",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "",
    "text": "Sesión del lunes, 20 de octubre de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html#correlación-para-variables-ordinales",
    "href": "assignment/resumen-asociacion.html#correlación-para-variables-ordinales",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "3.1 Correlación para variables ordinales",
    "text": "3.1 Correlación para variables ordinales\n\n3.1.1 Coeficiente de correlación de Spearman\nEn R calcularlo es sencillo, pero debemos tener en cuenta que las variables que relacionemos tengan un orden de rango similar: por ejemplo, que el valor más bajo sea el rango más bajo y que el valor más alto sea el rango más alto.\nObservemos las frecuencias de las variables ideal (Estebarrio es ideal para mi) e integracion (Me siento integrado en este barrio)\n\nsjmisc::frq(proc_data$ideal)\n\nEste barrio es ideal para mi (x) &lt;numeric&gt; \n# total N=2927 valid N=2926 mean=2.62 sd=1.02\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |       Totalmente en desacuerdo |  114 |  3.89 |    3.90 |   3.90\n    1 |                  En desacuerdo |  413 | 14.11 |   14.11 |  18.01\n    2 | Ni de acuerdo ni en desacuerdo |  379 | 12.95 |   12.95 |  30.96\n    3 |                     De acuerdo | 1599 | 54.63 |   54.65 |  85.61\n    4 |          Totalmente de acuerdo |  421 | 14.38 |   14.39 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    1 |  0.03 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_data$integracion)\n\nMe siento integrado en este barrio (x) &lt;numeric&gt; \n# total N=2927 valid N=2923 mean=2.57 sd=1.00\n\nValue |                          Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------------------------------\n    0 |       Totalmente en desacuerdo |  109 |  3.72 |    3.73 |   3.73\n    1 |                  En desacuerdo |  436 | 14.90 |   14.92 |  18.65\n    2 | Ni de acuerdo ni en desacuerdo |  408 | 13.94 |   13.96 |  32.60\n    3 |                     De acuerdo | 1633 | 55.79 |   55.87 |  88.47\n    4 |          Totalmente de acuerdo |  337 | 11.51 |   11.53 | 100.00\n &lt;NA&gt; |                           &lt;NA&gt; |    4 |  0.14 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nAhora, calculemos el coeficiente de correlación de Spearman con cor.test.\n\ncor.test(proc_data$ideal, proc_data$integracion, method = \"spearman\") #especificamos metodo spearman\n\n\n    Spearman's rank correlation rho\n\ndata:  proc_data$ideal and proc_data$integracion\nS = 1652768221, p-value &lt; 0.00000000000000022\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.6025133 \n\n\nAhora conocemos el valor del coeficiente de Spearman mediante al argumento rho, que es igual a 0.6, siendo positivo y gramde según los criterios de Cohen (1988).\n\n\n3.1.2 Coeficiente de correlación Tau de Kendall\nRecomendado cuando hay un set de datos pequeños y/o cuando hay mucha repetición de observaciones en el mismo ranking. Se basa en una comparación de pares de observaciones concordantes y discordantes.\nAhora, calculemos el coeficiente de correlación Tau de Kendall con cor.test.\n\ncor.test(proc_data$ideal, proc_data$integracion, method = \"kendall\") #especificamos metodo kendall\n\n\n    Kendall's rank correlation tau\n\ndata:  proc_data$ideal and proc_data$integracion\nz = 34.923, p-value &lt; 0.00000000000000022\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.5569015 \n\n\nEl valor del coeficiente de Kendall mediante al argumento tau, es igual a 0.56, siendo positivo y grande según los criterios de Cohen (1988).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html#matrices-de-correlación",
    "href": "assignment/resumen-asociacion.html#matrices-de-correlación",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "3.3 Matrices de correlación",
    "text": "3.3 Matrices de correlación\nEn su forma simple en R se aplica la función cor a la base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\n\nM &lt;- cor(proc_data, use = \"complete.obs\") \nM\n\n                     ideal integracion identificacion pertenencia     m0_sexo\nideal           1.00000000  0.60986590     0.58426016  0.61435602 -0.05131174\nintegracion     0.60986590  1.00000000     0.65241440  0.63128010 -0.03532181\nidentificacion  0.58426016  0.65241440     1.00000000  0.68974639 -0.01999725\npertenencia     0.61435602  0.63128010     0.68974639  1.00000000 -0.02160000\nm0_sexo        -0.05131174 -0.03532181    -0.01999725 -0.02160000  1.00000000\nm0_edad         0.12402201  0.12674576     0.17855004  0.20642161  0.06180434\neducacion       0.02719214 -0.03236403    -0.07009810 -0.05085423 -0.04709029\n                   m0_edad   educacion\nideal           0.12402201  0.02719214\nintegracion     0.12674576 -0.03236403\nidentificacion  0.17855004 -0.07009810\npertenencia     0.20642161 -0.05085423\nm0_sexo         0.06180434 -0.04709029\nm0_edad         1.00000000 -0.27056315\neducacion      -0.27056315  1.00000000\n\n\nEste es el reporte simple, pero no muy amigable a la vista. Para una versión más reportable, utilizamos la función tab_corr.\n\nsjPlot::tab_corr(proc_data, \n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nEste barrio es ideal para mi\nMe siento integrado en este barrio\nMe identifico con la gente de este\nbarrio\nMe siento parte de este barrio\nSexo del entrevistado\nEdad del entrevistado\neducacion\n\n\nEste barrio es ideal para mi\n \n \n \n \n \n \n \n\n\nMe siento integrado en este barrio\n0.610***\n \n \n \n \n \n \n\n\nMe identifico con la gente de este\nbarrio\n0.584***\n0.652***\n \n \n \n \n \n\n\nMe siento parte de este barrio\n0.614***\n0.631***\n0.690***\n \n \n \n \n\n\nSexo del entrevistado\n-0.051**\n-0.035\n-0.020\n-0.022\n \n \n \n\n\nEdad del entrevistado\n0.124***\n0.127***\n0.179***\n0.206***\n0.062***\n \n \n\n\neducacion\n0.027\n-0.032\n-0.070***\n-0.051**\n-0.047*\n-0.271***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLa distinción entre listwise y pairwise es relevante al momento de estimar matrices de correlación, donde esta decisión debe estar claramente explicitada y fundamentada. En el ejemplo de tabla anterior usamos listwise que es el argumento por defecto (y nos lo indica al final de la tabla).\nVeamos cómo hacerlo con pairwise:\n\nsjPlot::tab_corr(proc_data, \n                 na.deletion = \"pairwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nEste barrio es ideal para mi\nMe siento integrado en este barrio\nMe identifico con la gente de este\nbarrio\nMe siento parte de este barrio\nSexo del entrevistado\nEdad del entrevistado\neducacion\n\n\nEste barrio es ideal para mi\n \n \n \n \n \n \n \n\n\nMe siento integrado en este barrio\n0.610***\n \n \n \n \n \n \n\n\nMe identifico con la gente de este\nbarrio\n0.584***\n0.653***\n \n \n \n \n \n\n\nMe siento parte de este barrio\n0.614***\n0.632***\n0.690***\n \n \n \n \n\n\nSexo del entrevistado\n-0.052**\n-0.036\n-0.021\n-0.022\n \n \n \n\n\nEdad del entrevistado\n0.124***\n0.126***\n0.178***\n0.206***\n0.062***\n \n \n\n\neducacion\n0.028\n-0.032\n-0.069***\n-0.051**\n-0.047*\n-0.272***\n \n\n\nComputed correlation used pearson-method with pairwise-deletion.\n\n\n\n\n\nOtra manera de presentar matrices de correlación es mediante gráficos. Veamos un ejemplo con la función corrplot de la librería corrplot sobre nuestra matriz M ya creada.\n\ndiag(M) &lt;- NA\ncorrplot::corrplot(M,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"#0D0887\"))(12),\n                   bg = \"white\",\n                   na.label = \"-\")",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html#baterías-e-índices",
    "href": "assignment/resumen-asociacion.html#baterías-e-índices",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "3.4 Baterías e índices",
    "text": "3.4 Baterías e índices\nEn la literatura sobre cohesión barrial se suele utilizar un índice sumativo o promedio entre los distintos indicadores sobre cohesión barrial: ideal,integracion,identificacion,pertenencia.\n\nM_cohesion &lt;- proc_data %&gt;% \n  dplyr::select(ideal, integracion, identificacion, pertenencia)\n\nsjPlot::tab_corr(M_cohesion, \n                 na.deletion = \"listwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n \nEste barrio es ideal para mi\nMe siento integrado en este barrio\nMe identifico con la gente de este\nbarrio\nMe siento parte de este barrio\n\n\nEste barrio es ideal para mi\n \n \n \n \n\n\nMe siento integrado en este barrio\n0.610***\n \n \n \n\n\nMe identifico con la gente de este\nbarrio\n0.584***\n0.653***\n \n \n\n\nMe siento parte de este barrio\n0.614***\n0.632***\n0.690***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLos ítems se correlacionan de manera positiva y con tamaños de efecto moderados y altos para las ciencias sociales. Con ello, podemos pasar a evaluar sus relaciones tienen consistencia interna.\n\nalpha_psci &lt;- psych::alpha(M_cohesion)\nalpha_psci$total$raw_alpha\n\n[1] 0.8720242\n\n\nDe acuerdo con este resultado, el alpha de Cronbach reflejado en el raw_alpha del output es superior al estandar de 0.6 en ciencias sociales, por lo que se sostiene su consistencia.\nAhora, generemos el índice cohesion\n\nproc_data &lt;- cbind(proc_data, \"cohesion\" = rowMeans(proc_data %&gt;% select(ideal, integracion, identificacion, pertenencia), na.rm=TRUE))\n\nproc_data &lt;- proc_data %&gt;%\n  mutate(\n    cohesion_dic = case_when(\n      cohesion &gt;= mean(cohesion, na.rm = TRUE) ~ 1,\n      cohesion &lt;  mean(cohesion, na.rm = TRUE) ~ 0,\n      TRUE ~ NA_real_\n    )\n  )\n\nproc_data %&gt;% select(cohesion, cohesion_dic) %&gt;%\n  sjmisc::descr(, show = c(\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\")) %&gt;%\n  kable(.,\"markdown\")\n\n\n\n\nvar\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\ncohesion\n2927\n0\n2.5829917\n0.8491213\n4 (0-4)\n\n\ncohesion_dic\n2927\n0\n0.6026648\n0.4894300\n1 (0-1)\n\n\n\n\n\n\n3.5 Correlación punto biserial\nLa correlación punto biserial se utiliza para calcular la correlación entre una variable categórica dicotómica y una variable continua.\nVeamos la frecuencia de sexo y la media de ingresos y1.\n\nsjmisc::frq(proc_data$m0_sexo)\n\nSexo del entrevistado (x) &lt;numeric&gt; \n# total N=2927 valid N=2927 mean=1.60 sd=0.49\n\nValue |  Label |    N | Raw % | Valid % | Cum. %\n------------------------------------------------\n    1 | Hombre | 1163 | 39.73 |   39.73 |  39.73\n    2 |  Mujer | 1764 | 60.27 |   60.27 | 100.00\n &lt;NA&gt; |   &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nmean(proc_data$cohesion, na.rm = T)\n\n[1] 2.582992\n\n\nObtengamos la correlación punto biserial entre sexo e ingresos.\n\ncor.test(proc_data$m0_sexo, proc_data$cohesion)\n\n\n    Pearson's product-moment correlation\n\ndata:  proc_data$m0_sexo and proc_data$cohesion\nt = -2.1022, df = 2925, p-value = 0.03562\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.074965499 -0.002614513\nsample estimates:\n        cor \n-0.03884091 \n\n\n\n\n3.6 Correlación tetracorica\nLa correlación tetracórica se utiliza para calcular la correlación entre dos variables binarias categóricas, es decir, variables nominales dicómoticas (solo dos posibles valores).\nObtengamos la correlación tetrácorica entre sexo y educacion.\n\nmatriz &lt;- proc_data %&gt;% select(m0_sexo, educacion) # creamos matriz con var de interes\n\npsych::tetrachoric(matriz, na.rm = T)\n\nCall: psych::tetrachoric(x = matriz, na.rm = T)\ntetrachoric correlation \n          m0_sx edccn\nm0_sexo    1.00      \neducacion -0.08  1.00\n\n with tau of \n  m0_sexo educacion \n    -0.26      0.39",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html#tablas-de-contingencia",
    "href": "assignment/resumen-asociacion.html#tablas-de-contingencia",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "4.1. Tablas de contingencia",
    "text": "4.1. Tablas de contingencia\n\nsjPlot::sjt.xtab(var.row = proc_data$m0_sexo, \n                 var.col = proc_data$educacion, \n                 show.summary = F, \n                 emph.total = T, \n                 show.row.prc = T, # porcentaje fila\n                 show.col.prc = T # porcentaje columna\n                 )\n\n\n\n\n\n\n\n\n\n\nSexo del\nentrevistado\neducacion\nTotal\n\n\n1\n2\n\n\nHombre\n726\n62.4 %\n38.1 %\n437\n37.6 %\n42.9 %\n1163\n100 %\n39.8 %\n\n\nMujer\n1181\n67 %\n61.9 %\n581\n33 %\n57.1 %\n1762\n100 %\n60.2 %\n\n\nTotal\n1907\n65.2 %\n100 %\n1018\n34.8 %\n100 %\n2925\n100 %\n100 %",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/resumen-asociacion.html#prueba-de-chi-cuadrado",
    "href": "assignment/resumen-asociacion.html#prueba-de-chi-cuadrado",
    "title": "Práctico resumen: Asociación categóricas, matrices de correlación y chi-cuadrado",
    "section": "4.2 Prueba de Chi-cuadrado",
    "text": "4.2 Prueba de Chi-cuadrado\nEn R, utilizamos la función chisq.test():\n\nchi_results &lt;- chisq.test(table(proc_data$m0_sexo, proc_data$educacion))\n\nchi_results\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(proc_data$m0_sexo, proc_data$educacion)\nX-squared = 6.3358, df = 1, p-value = 0.01183\n\n\nObtuvimos nuestro resultado, pero no es muy amigable a la vista. Generemos una tabla de calidad para que sea reportable.\n\nstats.table &lt;- tidy(chi_results, conf_int = T)\nnice_table(stats.table)\n\n\n\nTabla 1\n\n\n\nstatisticpparameterMethod6.34.012*1Pearson's Chi-squared test with Yates' continuity correction",
    "crumbs": [
      "Prácticos",
      "Guías",
      "Resumen asociación"
    ]
  },
  {
    "objectID": "assignment/foro-practicos.html",
    "href": "assignment/foro-practicos.html",
    "title": "Foro prácticos",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre llas guías prácticas. Para poder participar en el foro hay que abir una cuenta en Github\n\n¿Cuándo usar este foro?\n\n\n\n\n\nMuchas veces sucede que los códigos de análisis no resultan, lo que puede deberse a errores menores en la escritura de código, otras a versiones de librerías, y la mayoría a que R es algo mañoso.\nCuando hay un error o el código no corre lo importante es evitar que la frustración lleve a desmotivarse o tirar el computador por la ventana. Por eso se sugiere:\n\nintentar resolverlo por no más de 10 minutos: en este tiempo revisar bien el material disponible y lo que hay en la web. Un lugar clásico donde se discuten problemas de código es Stack overflow.\nsi no se logra solucionar entonces se sugiere encarecidamente usar el foro al final de esta página, ya que nos sirve para dejar la respuesta disponible para otr_s compañer_s que pueden tener la misma duda (generalmente es así)\n\n\n\n¿Cómo preguntar?\n\nDesripción general del problema, código y error que ocurre\nSi con esta información no basta para solucionar el problema, entonces se le podrá solicitar información adicionales, tales como el archivo de código y la información de la versión de las librerías que aparece al ejecutar el comando sessionInfo()\n\n\n\nForo prácticos",
    "crumbs": [
      "Prácticos",
      "Foro Prácticos"
    ]
  },
  {
    "objectID": "assignment/08-practico.html",
    "href": "assignment/08-practico.html",
    "title": "Plantilla reporte final",
    "section": "",
    "text": "Sesión del martes, 19 de noviembre de 2024\nEl objetivo de esta guía es explicar el formato del informe de los trabajos del curso. Ya que la elaboración de los informes incluye análisis en R, la idea es poder aprovechar los recursos existentes para poder realizar escritura y análisis en un mismo documento. La base de esto eslla clase sobre documentos dinámicos y también los prácticos sobre generación de tablas y gráficos en documentos dinámicos.\nPara facilitar el desarrollo de los trabajos en este entorno ponemos a disposición una carpeta que se puede bajar aquí. Esta carpeta está basada en el protocolo IPO, mencionado en la clase sobre documentos dinámicos, con la siguente estructura de archivos y carpetas:\nEn detalle, aprenderemos los siguientes contenidos:"
  },
  {
    "objectID": "assignment/08-practico.html#crear-un-documento-quarto",
    "href": "assignment/08-practico.html#crear-un-documento-quarto",
    "title": "Plantilla reporte final",
    "section": "Crear un documento Quarto",
    "text": "Crear un documento Quarto\nPara generar un documento Quarto hacemos lo siguiente: en RStudio File &gt; New File &gt; Quarto Document"
  },
  {
    "objectID": "assignment/08-practico.html#encabezado-o-yaml",
    "href": "assignment/08-practico.html#encabezado-o-yaml",
    "title": "Plantilla reporte final",
    "section": "Encabezado o YAML",
    "text": "Encabezado o YAML\nPara comenzar, definiremos los elementos que van en el encabezado (front matter o YAML), al menos debemos especificar:\n\nTítulo\nSubtítulo\nAutores\nFecha\nIdioma\n\n\nCon ese YAML el encabezado se ve de la siguiente forma:"
  },
  {
    "objectID": "assignment/08-practico.html#apartados-y-subapartados",
    "href": "assignment/08-practico.html#apartados-y-subapartados",
    "title": "Plantilla reporte final",
    "section": "Apartados y subapartados",
    "text": "Apartados y subapartados\nPara los títulos de los apartados deben poner un # antes del nombre, y para los subapartados cada vez más pequeños dos o más #.\nPor ejemplo, si ponemos:\n# Variables\n## Descripción de variables\nLos apartados y subapartados diferirán en su tamaño y se verán de esta forma."
  },
  {
    "objectID": "assignment/08-practico.html#insertar-imágenes",
    "href": "assignment/08-practico.html#insertar-imágenes",
    "title": "Plantilla reporte final",
    "section": "Insertar imágenes",
    "text": "Insertar imágenes\nPara llamar una imagen se puede utilizar el código markdown:\n![](acá_ruta_a_imagen)\nPor ejemplo, para llamar una imagen que está en la web:\n![](https://www.desarrollosocialyfamilia.gob.cl/storage/image/banner-saludmental.png)\nSe vé luego así al renderizar:\n\nO si la imagen está en una carpeta local, ejemplo:\n\nPara cambiar el tamaño de la imagen usar width, y para cambiar la alineación fig-align:\n![](input/imagen/banner-saludmental.png){width=50% fig-align=\"center\"}\nResulta en:"
  },
  {
    "objectID": "assignment/08-practico.html#carga-de-librerías",
    "href": "assignment/08-practico.html#carga-de-librerías",
    "title": "Plantilla reporte final",
    "section": "Carga de librerías",
    "text": "Carga de librerías\nLas librerías que utilizaremos en esta guía práctica son:\n\nlibrary(pacman)\npacman::p_load(tidyverse,   # manipulacion datos\n               sjPlot,      # tablas\n               confintr,    # IC\n               gginference, # visualizacion \n               rempsyc,     # reporte\n               broom,       # varios\n               sjmisc,      # para descriptivos\n               knitr)       # para       \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "assignment/08-practico.html#carga-de-datos",
    "href": "assignment/08-practico.html#carga-de-datos",
    "title": "Plantilla reporte final",
    "section": "Carga de datos",
    "text": "Carga de datos\nComo señalamos antes, cargaremos los datos del Estudio Longitudinal Social de Chile (ELSOC) para ejemplificar. En esta guía práctica llamaremos los datos desde la web, pero en la carpeta del proyecto se encuentran alojados en la carpeta input/data, y se llama de la siguiente forma:\nload(\"input/data/ELSOC_Long.RData\")\nPero, para llamar la base de datos desde la web:\n\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\"))"
  },
  {
    "objectID": "assignment/08-practico.html#limpieza-de-datos",
    "href": "assignment/08-practico.html#limpieza-de-datos",
    "title": "Plantilla reporte final",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nRealizaremos un tratamiento simple de los casos:\n\n# Filtrar casos y seleccionar variables\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% \n  filter(ola==1) %&gt;%\n  select(sexo=m0_sexo,edad=m0_edad,nedu=m01,\n         s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09)\n\n# remover NA's\ndata &lt;- data %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()\n\n# crear variable nueva \ndata &lt;- data %&gt;% \n  rowwise() %&gt;%\n  mutate(sint_depresivos = mean(c(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09))) %&gt;% \n  ungroup()"
  },
  {
    "objectID": "assignment/08-practico.html#guardar-base-de-datos-resultante",
    "href": "assignment/08-practico.html#guardar-base-de-datos-resultante",
    "title": "Plantilla reporte final",
    "section": "Guardar base de datos resultante",
    "text": "Guardar base de datos resultante\nGuardamos la base de datos procesada en la carpeta de output, con\nsaveRDS(data, \"output/data.Rdata\")"
  },
  {
    "objectID": "assignment/08-practico.html#introducción",
    "href": "assignment/08-practico.html#introducción",
    "title": "Plantilla reporte final",
    "section": "Introducción",
    "text": "Introducción\n\nEn este apartado pueden poner su introducción, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nEn este ejemplo daremos una mirada a la salud mental, y exploraremos posibles asociaciones con la edad, sexo y nivel educacional."
  },
  {
    "objectID": "assignment/08-practico.html#variables",
    "href": "assignment/08-practico.html#variables",
    "title": "Plantilla reporte final",
    "section": "Variables",
    "text": "Variables\n\nEn este apartado pueden poner sus variables, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nA continuación, en nuestro ejemplo describiremos las variables necesarias para responder a nuestro objetivo."
  },
  {
    "objectID": "assignment/08-practico.html#descripción-de-variables",
    "href": "assignment/08-practico.html#descripción-de-variables",
    "title": "Plantilla reporte final",
    "section": "Descripción de variables",
    "text": "Descripción de variables\nEn este ejemplo, se seleccionaron las variables:\n\nsexo: sexo del encuestado, con nivel de medición nominal\nedad: edad del encuestado, con nivel de medición intervalar\nnedu: nivel educativo del encuestado, con nivel de medición ordinal\n\nY las variables del módulo de Salud y Bienestar, referentes a Estado de ánimo: sintomatología depresiva, con nivel de medición ordinal, los ítems son los siguientes:\n\nFrecuencia: Poco interés o alegría\nFrecuencia: Decaimiento, pesadez o desesperanza\nFrecuencia: Dificultad para dormir o exceso de sueño\nFrecuencia: Cansancio o sensación de falta de energía\nFrecuencia: Apetito disminuido o aumentado\nFrecuencia: Dificultad para concentrarse\nFrecuencia: Mala opinión de sí mismo\nFrecuencia: Enlentecimiento físico\nFrecuencia: Pensamiento de muerte o dañarse\n\n\nPodemos caargar los datos en nuestro informe sin que se vea poniendo la option echo=FALSE: data &lt;-readRDS(\"output/data.RData\").\n\n\ntab1 &lt;- data %&gt;%\n  group_by(sexo) %&gt;% # agrupamos por sexo\n  summarise(n = n()) %&gt;% # contamos por categ de respuesta\n  mutate(prop = round((n / sum(n)) * 100, 2)) # porcentaje\n \npm &lt;- as.numeric(tab1[2,3])\nph &lt;- as.numeric(tab1[1,3])\n\ntabla1 &lt;- tab1 %&gt;% \n  kableExtra::kable(format = \"html\",\n                    align = \"c\",\n                    col.names = c(\"Sexo\", \"n\", \"Proporción\"),\n                    caption = \"Tabla 1. Distribución de sexo\") %&gt;% \n  kableExtra::kable_classic(full_width = FALSE, position = \"center\", font_size = 14) %&gt;% \n  kableExtra::add_footnote(label = \"Fuente: Elaboración propia en base a ELSOC 2016.\")\n\nEn la Tabla 1 podemos ver que la proporción de mujeres que responde la encuesta corresponde a 60.12%, mientras que la propoción de hombres corresponde a 39.88%.\n\ntabla1\n\n\n\nTabla 1: Distribución de sexo\n\n\n\n\nTabla 1. Distribución de sexo\n\n\nSexo\nn\nProporción\n\n\n\n\n1\n1151\n39.88\n\n\n2\n1735\n60.12\n\n\n\na Fuente: Elaboración propia en base a ELSOC 2016.\n\n\n\n\n\n\n\n\n\n\n\n\nEn las options del chunk desde el que llamamos a la tabla le ponemos tbl-nombre tabla para etiquetarla, y luego en el texto ponemos @tbl-nombre-tabla para referenciarla. También, cuando queremos llamar un valor, es necesario asignarlo a un objeto, y en el texto lo llamamos con:"
  },
  {
    "objectID": "assignment/08-practico.html#análisis",
    "href": "assignment/08-practico.html#análisis",
    "title": "Plantilla reporte final",
    "section": "Análisis",
    "text": "Análisis\n\nEn este apartado pueden poner sus análisis, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nEn nuestro ejemplo, analizaremos la correlación entre algunas variables.\n\ncor_edad_dep &lt;- cor(data$edad, data$sint_depresivos)\ncor_nedu_dep &lt;- cor(data$nedu, data$sint_depresivos)\ncor_nedu_edad &lt;- cor(data$nedu, data$edad)\n\n\ng1 &lt;- data %&gt;% \n  group_by(nedu) %&gt;% \n  summarise(sint_dep = mean(sint_depresivos, na.rm = T),\n            edad=mean(edad, na.rm = T))\n\ngrafico1 &lt;- ggplot(data = g1,\n       mapping = aes(x = sint_dep, y = edad, label = nedu)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",colour = \"black\",fill=\"lightblue\",size=0.5) + \n  labs(x = \"Sintomatología depresiva\",\n       y = \"Edad\",\n       caption = \"Fuente: Elaboración propia en base a ELSOC 2026\") +\n  theme_bw()\n\nEn la Figura 1 es posible apreciar… La correlación entre la edad y el promedio de la sintomatología depresiva corresponde a 0.0176236.\n\ngrafico1\n\n\n\n\n\n\n\nFigura 1: Correlación entre edad y sintomatología depresiva\n\n\n\n\n\n\nEn las options del chunk desde el que llamamos a la figura le ponemos fig-nombre figura para etiquetarla, y luego en el texto ponemos @fig-nombre-figura para referenciarla."
  },
  {
    "objectID": "assignment/08-practico.html#conclusiones",
    "href": "assignment/08-practico.html#conclusiones",
    "title": "Plantilla reporte final",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nEn este apartado pueden poner sus conclusiones, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nAquí redactamos algunas conclusiones."
  },
  {
    "objectID": "assignment/08-practico.html#bibliografía",
    "href": "assignment/08-practico.html#bibliografía",
    "title": "Plantilla reporte final",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nEn este apartado pueden poner su bibliografía, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nPonemos un - para generar un listado.\n\nCOES (2023). Radiografía del Cambio Social: Análisis de Resultados Longitudinales ELSOC 2016-2022. Presentación de Resultados COES. Marzo, Santiago de Chile.\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/."
  },
  {
    "objectID": "assignment/06-practico.html",
    "href": "assignment/06-practico.html",
    "title": "Tablas en reportes dinámicos",
    "section": "",
    "text": "Sesión del martes, 12 de noviembre de 2024"
  },
  {
    "objectID": "assignment/06-practico.html#recursos-de-la-práctica",
    "href": "assignment/06-practico.html#recursos-de-la-práctica",
    "title": "Tablas en reportes dinámicos",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018."
  },
  {
    "objectID": "assignment/06-practico.html#chunks",
    "href": "assignment/06-practico.html#chunks",
    "title": "Tablas en reportes dinámicos",
    "section": "Chunks",
    "text": "Chunks\nPara integrar código de R en un archivo Quarto usamos los chunks, que son trozos de código dentro de nuestra hoja. Estos permiten hacer análisis dentro del documento visualizando los resultados en el documento final. Un chunk se especifica mediante una línea de código inicial ```{r}, y se cierra con ```\nLos chunks se ven así dentro del .qmd:\n```{r}\n1 + 1\n```\n\nInsertar chunks\nHay tres formas de insertar chunks:\n\nPulsar ⌘⌥I en macOS o Control + Alt + I en Windows\nPulsa el botón “Insert” en la parte superior de la ventana del editor\n\n\n\n\n\n\n\n\n\n\n\nEscribirlo manualmente\n\n\n\nNombre de chunk\nPara añadir un nombre, inclúyelo inmediatamente después de la {r en la primera línea del chunk. Los nombres no pueden contener espacios, pero sí guiones bajos y guiones.\nImportante: Todos los nombres de chunk de tu documento deben ser únicos.\n```{r nombre-chunk}\n1 + 1\n```\n\n\nOpciones de chunk\nHay distintas opciones diferentes que puedes establecer para cada chunk. Puedes ver una lista completa en la Guía de referencia de RMarkdown o en el sitio web de knitr. Estos recursos se crearon inicialmente para RMarkdown, pero también son aplicables a Quarto.\nEn Quarto, las opciones del chunk van inmediatamente después de la sección {r}. Para especificar una opción, se debe partir con #|, luego la opción y luego el valor lógico. Por ejemplo:\n```{r}\n#| message: false\n#| echo: true\n1 + 1\n```\nOtra forma de hacerlo es configurar las opciones generales de todos los chunks que hagamos al inicio del documento en el YAML:\n\n\n\n\n\n\n\n\n\nDe esta manera ya no es necesario indicar en cada chunk las opciones, y se aplicaran las configuraciones generales que indicamos al comienzo."
  },
  {
    "objectID": "assignment/06-practico.html#preparación-de-datos",
    "href": "assignment/06-practico.html#preparación-de-datos",
    "title": "Tablas en reportes dinámicos",
    "section": "Preparación de datos",
    "text": "Preparación de datos\nComencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.\n\npacman::p_load(tidyverse, # Manipulacion datos\n               sjmisc, # Descriptivos\n               knitr, # Render y tablas\n               kableExtra, # Formateo tablas\n               summarytools, # Tablas\n               sjPlot, # Tablas y gráficos\n               stargazer, # Tablas\n               janitor, # Tablas y formateo\n               crosstable, # Tablas\n               table1 # Tablas\n               ) \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\nCargamos los datos desde internet.\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/lapop_proc_2018.RData\")) #Cargar base de datos\n\n# Un pequeño procesamiento para algunas variables que usaremos más adelante\nlapop &lt;- lapop %&gt;% mutate(across(c(\"gini\", \"gdp\"), ~ as.numeric(.))) \n\nA continuación, exploramos la base de datos lapop.\n\nnames(lapop) # Nombre de columnas\n\n [1] \"year\"        \"pais\"        \"pais_name\"   \"idnum\"       \"upm\"        \n [6] \"strata\"      \"wt\"          \"weight1500\"  \"sexo\"        \"edad\"       \n[11] \"educ\"        \"l1\"          \"ideologia_f\" \"empleo\"      \"decile\"     \n[16] \"it1\"         \"prot3\"       \"aoj12\"       \"b2\"          \"b3\"         \n[21] \"b4\"          \"b10a\"        \"b12\"         \"b20\"         \"b20a\"       \n[26] \"b21\"         \"b21a\"        \"n9\"          \"n11\"         \"n15\"        \n[31] \"ros4\"        \"ing4\"        \"eff1\"        \"pn4\"         \"exc7\"       \n[36] \"pol1\"        \"vb2\"         \"gini\"        \"gdp\"        \n\ndim(lapop) # Dimensiones\n\n[1] 23386    39\n\n\nContamos con 39 variables (columnas) y 23.386 observaciones (filas)."
  },
  {
    "objectID": "assignment/06-practico.html#funciones-para-tablas-univariadas",
    "href": "assignment/06-practico.html#funciones-para-tablas-univariadas",
    "title": "Tablas en reportes dinámicos",
    "section": "Funciones para tablas univariadas",
    "text": "Funciones para tablas univariadas\nEstas tablas suelen incluir estadísticas descriptivas de una sola variable como medias, medianas, desviaciones estándar, entre otras.\n\nsummarytools:\n\nsummarytools::dfSummary(): Genera un resumen univariado completo de cada variable en el dataset, con estadísticas, frecuencia de valores y gráficos.\n\n\nsummarytools::dfSummary(data_example) %&gt;% \n  summarytools::view(method = \"render\") \n\n\nData Frame Summary\nsummarytools::dfSummary\nDimensions: 23386 x 6\n  Duplicates: 16464\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\npais [character]\nPaís\n\n\n\n1. BOL\n\n\n2. COL\n\n\n3. CHL\n\n\n4. URY\n\n\n5. MEX\n\n\n6. HND\n\n\n7. PAN\n\n\n8. ECU\n\n\n9. ARG\n\n\n10. PER\n\n\n[ 5 others ]\n\n\n\n\n\n\n1682\n(\n7.2%\n)\n\n\n1663\n(\n7.1%\n)\n\n\n1638\n(\n7.0%\n)\n\n\n1581\n(\n6.8%\n)\n\n\n1580\n(\n6.8%\n)\n\n\n1560\n(\n6.7%\n)\n\n\n1559\n(\n6.7%\n)\n\n\n1533\n(\n6.6%\n)\n\n\n1528\n(\n6.5%\n)\n\n\n1521\n(\n6.5%\n)\n\n\n7541\n(\n32.2%\n)\n\n\n\n\n23386 (100.0%)\n0 (0.0%)\n\n\n2\nit1 [numeric]\nConfianza Interpersonal\n\n\n\nMean (sd) : 2.7 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 3 ≤ 4\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n\n\n\n1\n:\n2580\n(\n11.3%\n)\n\n\n2\n:\n7157\n(\n31.4%\n)\n\n\n3\n:\n7693\n(\n33.8%\n)\n\n\n4\n:\n5353\n(\n23.5%\n)\n\n\n\n\n22783 (97.4%)\n603 (2.6%)\n\n\n3\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 40.5 (16.8)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 38 ≤ 99\n\n\nIQR (CV) : 25 (0.4)\n\n\n\n81 distinct values\n\n23372 (99.9%)\n14 (0.1%)\n\n\n4\nsexo [factor]\nSexo\n\n\n\n1. Hombre\n\n\n2. Mujer\n\n\n\n\n\n\n11634\n(\n49.8%\n)\n\n\n11739\n(\n50.2%\n)\n\n\n\n\n23373 (99.9%)\n13 (0.1%)\n\n\n5\ngini [numeric]\n\n\n\n\nMean (sd) : 45.8 (4)\n\n\nmin ≤ med ≤ max:\n\n\n38 ≤ 45.7 ≤ 53.3\n\n\nIQR (CV) : 6.1 (0.1)\n\n\n\n15 distinct values\n\n23386 (100.0%)\n0 (0.0%)\n\n\n6\ngdp [numeric]\n\n\n\n\nMean (sd) : 8.7 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n2.5 ≤ 8 ≤ 16\n\n\nIQR (CV) : 7.2 (0.5)\n\n\n\n15 distinct values\n\n23386 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-26\n\n\n\n\nsummarytools::descr(): Proporciona estadísticas descriptivas para variables numéricas.\n\n\nsummarytools::descr(data_example$edad) %&gt;%\n  summarytools::view(method = \"render\")\n\nError : Can't find summarytools\n\n\n\nDescriptive Statistics\nvalue\nLabel: Edad\n  N: 23386\n\n\n\n\n\n\nvalue\n\n\n\n\nMean\n40.46\n\n\nStd.Dev\n16.80\n\n\nMin\n16.00\n\n\nQ1\n27.00\n\n\nMedian\n38.00\n\n\nQ3\n52.00\n\n\nMax\n99.00\n\n\nMAD\n17.79\n\n\nIQR\n25.00\n\n\nCV\n0.42\n\n\nSkewness\n0.57\n\n\nSE.Skewness\n0.02\n\n\nKurtosis\n-0.58\n\n\nN.Valid\n23372\n\n\nPct.Valid\n 99.94\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-26\n\n\n\n\n\nstargazer:\n\nstargazer::stargazer(): Para reportar estadísticas descriptivas.\n\nstargazer(as.data.frame(data_example), type = \"html\", summary.stat = c(\"mean\", \"sd\", \"min\", \"max\"))\n\n\n\n\n\n\n\nStatistic\n\n\nMean\n\n\nSt. Dev.\n\n\nMin\n\n\nMax\n\n\n\n\n\n\n\n\nit1\n\n\n2.694\n\n\n0.953\n\n\n1\n\n\n4\n\n\n\n\nedad\n\n\n40.461\n\n\n16.798\n\n\n16\n\n\n99\n\n\n\n\ngini\n\n\n45.778\n\n\n4.043\n\n\n38.000\n\n\n53.300\n\n\n\n\ngdp\n\n\n8.748\n\n\n4.278\n\n\n2.475\n\n\n16.038\n\n\n\n\n\n\n\n\n\npsych:\n\npsych::describe(): Calcula estadísticas descriptivas adicionales, como curtosis y asimetría.\n\n\npsych::describe(data_example) %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\n\npais*\n1\n23386\n7.950911\n4.3253391\n8.000000\n7.935810\n5.930400\n1.00000\n15.00000\n14.00000\n0.0201754\n-1.2152000\n0.0282841\n\n\nit1\n2\n22783\n2.694333\n0.9532423\n3.000000\n2.742909\n1.482600\n1.00000\n4.00000\n3.00000\n-0.1424032\n-0.9507169\n0.0063154\n\n\nedad\n3\n23372\n40.460551\n16.7983821\n38.000000\n39.158199\n17.791200\n16.00000\n99.00000\n83.00000\n0.5674996\n-0.5770780\n0.1098802\n\n\nsexo*\n4\n23373\n1.502246\n0.5000057\n2.000000\n1.502808\n0.000000\n1.00000\n2.00000\n1.00000\n-0.0089842\n-2.0000048\n0.0032705\n\n\ngini\n5\n23386\n45.777846\n4.0429160\n45.700000\n45.896141\n4.151280\n38.00000\n53.30000\n15.30000\n-0.2035078\n-0.6251471\n0.0264373\n\n\ngdp\n6\n23386\n8.747801\n4.2779214\n7.997761\n8.634054\n6.045964\n2.47517\n16.03793\n13.56276\n0.2534969\n-1.2525404\n0.0279740\n\n\n\n\n\n\n\nsjmisc:\n\nsjmisc::frq(): Para tablas de frecuencias detalladas de variables categóricas. Incluye labels.\n\n\nsjmisc::frq(data_example$it1) %&gt;%\n  kable() \n\n\n\n\n\n\n\n\nval\nlabel\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\n\n1\nNada confiable\n2580\n11.03\n11.32\n11.32\n\n\n2\nPoco confiable\n7157\n30.60\n31.41\n42.74\n\n\n3\nAlgo confiable\n7693\n32.90\n33.77\n76.50\n\n\n4\nMuy confiable\n5353\n22.89\n23.50\n100.00\n\n\nNA\nNA\n603\n2.58\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\ntable1:\n\ntable1::table1(): Permite ver tanto variables categoricas como numericas en la misma tabla de manera estética\n\n\ntable1::table1(~ factor(sexo) + edad + gini + gdp, data = data_example)\n\n\n\n\n\n\n\n\n\n\nOverall\n(N=23386)\n\n\n\n\nfactor(sexo)\n\n\n\nHombre\n11634 (49.7%)\n\n\nMujer\n11739 (50.2%)\n\n\nMissing\n13 (0.1%)\n\n\nEdad\n\n\n\nMean (SD)\n40.5 (16.8)\n\n\nMedian [Min, Max]\n38.0 [16.0, 99.0]\n\n\nMissing\n14 (0.1%)\n\n\ngini\n\n\n\nMean (SD)\n45.8 (4.04)\n\n\nMedian [Min, Max]\n45.7 [38.0, 53.3]\n\n\ngdp\n\n\n\nMean (SD)\n8.75 (4.28)\n\n\nMedian [Min, Max]\n8.00 [2.48, 16.0]"
  },
  {
    "objectID": "assignment/06-practico.html#funciones-para-tablas-bivariadas",
    "href": "assignment/06-practico.html#funciones-para-tablas-bivariadas",
    "title": "Tablas en reportes dinámicos",
    "section": "Funciones para tablas bivariadas",
    "text": "Funciones para tablas bivariadas\nLas tablas bivariadas permiten explorar relaciones entre pares de variables, útiles para comparar medias o analizar frecuencias conjuntas en tablas de contingencia.\n\nsjPlot:\n\nsjPlot::tab_xtab(): Produce tablas cruzadas de frecuencias y porcentajes, y es útil para comparar variables categóricas entre grupos.\n\n\nsjPlot::tab_xtab(data_example$pais, data_example$it1, show.row.prc = TRUE)\n\n\n \n País\n ConfianzaInterpersonal\n Total\n \n \n\n Nada confiable\n Poco confiable\n Algo confiable\n Muy confiable\n \n \n \nARG\n1228.1 %\n33122.1 %\n68946 %\n35523.7 %\n1497100 % \n\n \n \nBOL\n22813.9 %\n68141.5 %\n53632.7 %\n19511.9 %\n1640100 % \n\n \n \nBRA\n19313.2 %\n68046.4 %\n29620.2 %\n29620.2 %\n1465100 % \n\n \n \nCHL\n17310.7 %\n38423.6 %\n66440.9 %\n40324.8 %\n1624100 % \n\n \n \nCOL\n1529.3 %\n42826.2 %\n57235 %\n48229.5 %\n1634100 % \n\n \n \nCRI\n1288.7 %\n33923 %\n52035.4 %\n48432.9 %\n1471100 % \n\n \n \nDOM\n17111.8 %\n44030.4 %\n47432.7 %\n36425.1 %\n1449100 % \n\n \n \nECU\n17911.8 %\n58038.2 %\n49432.5 %\n26517.5 %\n1518100 % \n\n \n \nHND\n21914.8 %\n44730.2 %\n35624.1 %\n45730.9 %\n1479100 % \n\n \n \nMEX\n17711.6 %\n52434.4 %\n49732.6 %\n32721.4 %\n1525100 % \n\n \n \nPAN\n22214.5 %\n53034.6 %\n49132.1 %\n28818.8 %\n1531100 % \n\n \n \nPER\n22715.1 %\n64442.7 %\n47531.5 %\n16110.7 %\n1507100 % \n\n \n \nPRY\n14710.1 %\n36525 %\n54037 %\n40727.9 %\n1459100 % \n\n \n \nSLV\n1308.9 %\n48833.5 %\n39727.3 %\n44130.3 %\n1456100 % \n\n \n \nURY\n1127.3 %\n29619.4 %\n69245.3 %\n42828 %\n1528100 % \n\n \n \nTotal\n258011.3 %\n715731.4 %\n769333.8 %\n535323.5 %\n22783100 % \n\nχ2=1306.960 · df=42 · Cramer's V=0.138 · p=0.000 \n\n \n\n\n\n\n\nsummarytools:\n\nsummarytools::ctable(): Para tablas de contingencia que incluyen porcentajes y frecuencias, con opciones de personalización.\n\n\nsummarytools::ctable(data_example$pais, data_example$sexo) %&gt;% \n  summarytools::view(method = \"render\")\n\nError : Can't find summarytools\nError : Can't find summarytools\n\n\n\nCross-Tabulation, Row Proportions\ndata_example$pais * data_example$sexo\n\n\n\n\n\ndata_example$sexo\n\n\n\ndata_example$pais\nHombre\nMujer\n&lt;NA&gt;\nTotal\n\n\n\n\nARG\n758\n(\n49.6%\n)\n770\n(\n50.4%\n)\n0\n(\n0.00%\n)\n1528\n(\n100.0%\n)\n\n\nBOL\n846\n(\n50.3%\n)\n836\n(\n49.7%\n)\n0\n(\n0.00%\n)\n1682\n(\n100.0%\n)\n\n\nBRA\n748\n(\n49.9%\n)\n750\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1498\n(\n100.0%\n)\n\n\nCHL\n813\n(\n49.6%\n)\n824\n(\n50.3%\n)\n1\n(\n0.06%\n)\n1638\n(\n100.0%\n)\n\n\nCOL\n830\n(\n49.9%\n)\n833\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1663\n(\n100.0%\n)\n\n\nCRI\n750\n(\n50.0%\n)\n751\n(\n50.0%\n)\n0\n(\n0.00%\n)\n1501\n(\n100.0%\n)\n\n\nDOM\n753\n(\n49.7%\n)\n761\n(\n50.2%\n)\n2\n(\n0.13%\n)\n1516\n(\n100.0%\n)\n\n\nECU\n760\n(\n49.6%\n)\n764\n(\n49.8%\n)\n9\n(\n0.59%\n)\n1533\n(\n100.0%\n)\n\n\nHND\n778\n(\n49.9%\n)\n782\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1560\n(\n100.0%\n)\n\n\nMEX\n775\n(\n49.1%\n)\n805\n(\n50.9%\n)\n0\n(\n0.00%\n)\n1580\n(\n100.0%\n)\n\n\nPAN\n782\n(\n50.2%\n)\n777\n(\n49.8%\n)\n0\n(\n0.00%\n)\n1559\n(\n100.0%\n)\n\n\nPER\n758\n(\n49.8%\n)\n762\n(\n50.1%\n)\n1\n(\n0.07%\n)\n1521\n(\n100.0%\n)\n\n\nPRY\n755\n(\n49.8%\n)\n760\n(\n50.2%\n)\n0\n(\n0.00%\n)\n1515\n(\n100.0%\n)\n\n\nSLV\n755\n(\n50.0%\n)\n756\n(\n50.0%\n)\n0\n(\n0.00%\n)\n1511\n(\n100.0%\n)\n\n\nURY\n773\n(\n48.9%\n)\n808\n(\n51.1%\n)\n0\n(\n0.00%\n)\n1581\n(\n100.0%\n)\n\n\nTotal\n11634\n(\n49.7%\n)\n11739\n(\n50.2%\n)\n13\n(\n0.06%\n)\n23386\n(\n100.0%\n)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.2)2025-08-26\n\n\n\n\n\ncrosstable:\n\ncrosstable::crosstable(): También produce tablas de continencia con opciones de personalización.\n\n\ncrosstable::crosstable(data_example, pais, by = sexo, margin=c(\"row\", \"col\"), total = \"both\") %&gt;% \n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\n.id\nlabel\nvariable\nHombre\nMujer\nNA\nTotal\n\n\n\n\npais\nPaís\nARG\n758 (6.52% / 49.61%)\n770 (6.56% / 50.39%)\n0\n1528 (6.53%)\n\n\npais\nPaís\nBOL\n846 (7.27% / 50.30%)\n836 (7.12% / 49.70%)\n0\n1682 (7.19%)\n\n\npais\nPaís\nBRA\n748 (6.43% / 49.93%)\n750 (6.39% / 50.07%)\n0\n1498 (6.41%)\n\n\npais\nPaís\nCHL\n813 (6.99% / 49.66%)\n824 (7.02% / 50.34%)\n1\n1638 (7.00%)\n\n\npais\nPaís\nCOL\n830 (7.13% / 49.91%)\n833 (7.10% / 50.09%)\n0\n1663 (7.11%)\n\n\npais\nPaís\nCRI\n750 (6.45% / 49.97%)\n751 (6.40% / 50.03%)\n0\n1501 (6.42%)\n\n\npais\nPaís\nDOM\n753 (6.47% / 49.74%)\n761 (6.48% / 50.26%)\n2\n1516 (6.48%)\n\n\npais\nPaís\nECU\n760 (6.53% / 49.87%)\n764 (6.51% / 50.13%)\n9\n1533 (6.56%)\n\n\npais\nPaís\nHND\n778 (6.69% / 49.87%)\n782 (6.66% / 50.13%)\n0\n1560 (6.67%)\n\n\npais\nPaís\nMEX\n775 (6.66% / 49.05%)\n805 (6.86% / 50.95%)\n0\n1580 (6.76%)\n\n\npais\nPaís\nPAN\n782 (6.72% / 50.16%)\n777 (6.62% / 49.84%)\n0\n1559 (6.67%)\n\n\npais\nPaís\nPER\n758 (6.52% / 49.87%)\n762 (6.49% / 50.13%)\n1\n1521 (6.50%)\n\n\npais\nPaís\nPRY\n755 (6.49% / 49.83%)\n760 (6.47% / 50.17%)\n0\n1515 (6.48%)\n\n\npais\nPaís\nSLV\n755 (6.49% / 49.97%)\n756 (6.44% / 50.03%)\n0\n1511 (6.46%)\n\n\npais\nPaís\nURY\n773 (6.64% / 48.89%)\n808 (6.88% / 51.11%)\n0\n1581 (6.76%)\n\n\npais\nPaís\nTotal\n11634 (49.78%)\n11739 (50.22%)\n13\n23386 (100.00%)\n\n\n\n\n\n\n\ntable1:\n\ntable1::table1(): También se puede utilizar agrupando las variables (numericas o categoricas) por alguna variable categórica.\n\n\ntable1::table1(~ factor(sexo) + edad + gini + gdp | pais, data = data_example)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nARG\n(N=1528)\nBOL\n(N=1682)\nBRA\n(N=1498)\nCHL\n(N=1638)\nCOL\n(N=1663)\nCRI\n(N=1501)\nDOM\n(N=1516)\nECU\n(N=1533)\nHND\n(N=1560)\nMEX\n(N=1580)\nPAN\n(N=1559)\nPER\n(N=1521)\nPRY\n(N=1515)\nSLV\n(N=1511)\nURY\n(N=1581)\nOverall\n(N=23386)\n\n\n\n\nfactor(sexo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHombre\n758 (49.6%)\n846 (50.3%)\n748 (49.9%)\n813 (49.6%)\n830 (49.9%)\n750 (50.0%)\n753 (49.7%)\n760 (49.6%)\n778 (49.9%)\n775 (49.1%)\n782 (50.2%)\n758 (49.8%)\n755 (49.8%)\n755 (50.0%)\n773 (48.9%)\n11634 (49.7%)\n\n\nMujer\n770 (50.4%)\n836 (49.7%)\n750 (50.1%)\n824 (50.3%)\n833 (50.1%)\n751 (50.0%)\n761 (50.2%)\n764 (49.8%)\n782 (50.1%)\n805 (50.9%)\n777 (49.8%)\n762 (50.1%)\n760 (50.2%)\n756 (50.0%)\n808 (51.1%)\n11739 (50.2%)\n\n\nMissing\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n2 (0.1%)\n9 (0.6%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n13 (0.1%)\n\n\nEdad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n41.8 (17.8)\n39.5 (16.3)\n39.1 (16.2)\n42.2 (16.8)\n40.4 (16.3)\n40.5 (16.9)\n40.0 (17.0)\n38.2 (17.1)\n38.2 (16.3)\n42.1 (17.0)\n39.6 (16.2)\n38.8 (15.5)\n40.0 (16.3)\n40.0 (16.6)\n46.2 (17.9)\n40.5 (16.8)\n\n\nMedian [Min, Max]\n39.0 [16.0, 90.0]\n36.0 [18.0, 89.0]\n37.0 [16.0, 92.0]\n40.0 [18.0, 92.0]\n37.0 [18.0, 90.0]\n37.0 [18.0, 89.0]\n37.0 [18.0, 87.0]\n35.0 [16.0, 92.0]\n34.0 [18.0, 89.0]\n40.0 [18.0, 88.0]\n37.5 [18.0, 93.0]\n36.0 [18.0, 91.0]\n37.0 [18.0, 87.0]\n38.0 [18.0, 99.0]\n44.0 [18.0, 95.0]\n38.0 [16.0, 99.0]\n\n\nMissing\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n2 (0.1%)\n9 (0.6%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n14 (0.1%)\n\n\ngini\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n41.1 (0)\n44.6 (0)\n53.3 (0)\n44.4 (0)\n49.7 (0)\n48.3 (0)\n45.7 (0)\n44.7 (0)\n49.4 (0)\n46.3 (0)\n49.9 (0)\n43.3 (0)\n48.5 (0)\n38.0 (0)\n39.5 (0)\n45.8 (4.04)\n\n\nMedian [Min, Max]\n41.1 [41.1, 41.1]\n44.6 [44.6, 44.6]\n53.3 [53.3, 53.3]\n44.4 [44.4, 44.4]\n49.7 [49.7, 49.7]\n48.3 [48.3, 48.3]\n45.7 [45.7, 45.7]\n44.7 [44.7, 44.7]\n49.4 [49.4, 49.4]\n46.3 [46.3, 46.3]\n49.9 [49.9, 49.9]\n43.3 [43.3, 43.3]\n48.5 [48.5, 48.5]\n38.0 [38.0, 38.0]\n39.5 [39.5, 39.5]\n45.7 [38.0, 53.3]\n\n\ngdp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n13.1 (0)\n3.29 (0)\n8.58 (0)\n13.9 (0)\n6.27 (0)\n12.5 (0)\n8.00 (0)\n5.95 (0)\n2.48 (0)\n9.95 (0)\n14.9 (0)\n6.57 (0)\n5.87 (0)\n3.92 (0)\n16.0 (0)\n8.75 (4.28)\n\n\nMedian [Min, Max]\n13.1 [13.1, 13.1]\n3.29 [3.29, 3.29]\n8.58 [8.58, 8.58]\n13.9 [13.9, 13.9]\n6.27 [6.27, 6.27]\n12.5 [12.5, 12.5]\n8.00 [8.00, 8.00]\n5.95 [5.95, 5.95]\n2.48 [2.48, 2.48]\n9.95 [9.95, 9.95]\n14.9 [14.9, 14.9]\n6.57 [6.57, 6.57]\n5.87 [5.87, 5.87]\n3.92 [3.92, 3.92]\n16.0 [16.0, 16.0]\n8.00 [2.48, 16.0]\n\n\n\n\n\n\n\n\n\ndplyr y janitor:\n\ndplyr + janitor::tabyl(): Puedes hacer resúmenes bivariados personalizados con count() o group_by(), y tabyl() genera tablas de contingencia de frecuencias para un vistazo rápido.\n\n\ndata_example %&gt;%\n  janitor::tabyl(pais, it1) %&gt;% # Esto reemplaza el procesamiento, buena alternativa\n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\npais\n1\n2\n3\n4\nNA_\n\n\n\n\nARG\n122\n331\n689\n355\n31\n\n\nBOL\n228\n681\n536\n195\n42\n\n\nBRA\n193\n680\n296\n296\n33\n\n\nCHL\n173\n384\n664\n403\n14\n\n\nCOL\n152\n428\n572\n482\n29\n\n\nCRI\n128\n339\n520\n484\n30\n\n\nDOM\n171\n440\n474\n364\n67\n\n\nECU\n179\n580\n494\n265\n15\n\n\nHND\n219\n447\n356\n457\n81\n\n\nMEX\n177\n524\n497\n327\n55\n\n\nPAN\n222\n530\n491\n288\n28\n\n\nPER\n227\n644\n475\n161\n14\n\n\nPRY\n147\n365\n540\n407\n56\n\n\nSLV\n130\n488\n397\n441\n55\n\n\nURY\n112\n296\n692\n428\n53"
  },
  {
    "objectID": "assignment/06-practico.html#a.-tablas",
    "href": "assignment/06-practico.html#a.-tablas",
    "title": "Tablas en reportes dinámicos",
    "section": "a. Tablas",
    "text": "a. Tablas\nPor ejemplo, si queremos referenciar a nuestra tabla1, en el chunk en donde la ejecutemos debemos indicar:\n```{r}\n#| label: tbl-confianza\n\ntabla1\n```\n\ntabla1\nnames(lapop)\n\n [1] \"year\"        \"pais\"        \"pais_name\"   \"idnum\"       \"upm\"        \n [6] \"strata\"      \"wt\"          \"weight1500\"  \"sexo\"        \"edad\"       \n[11] \"educ\"        \"l1\"          \"ideologia_f\" \"empleo\"      \"decile\"     \n[16] \"it1\"         \"prot3\"       \"aoj12\"       \"b2\"          \"b3\"         \n[21] \"b4\"          \"b10a\"        \"b12\"         \"b20\"         \"b20a\"       \n[26] \"b21\"         \"b21a\"        \"n9\"          \"n11\"         \"n15\"        \n[31] \"ros4\"        \"ing4\"        \"eff1\"        \"pn4\"         \"exc7\"       \n[36] \"pol1\"        \"vb2\"         \"gini\"        \"gdp\"        \n\n\n\n\nTabla 1: Confianza interpersonal según país\n\n\n\n\nTabla 1. Confianza interpersonal según país\n\n\nPaís\nNada confiable\nPoco confiable\nAlgo confiable\nMuy confiable\n\n\n\n\nARG\n7.98\n21.66\n45.09\n23.23\n\n\nBOL\n13.56\n40.49\n31.87\n11.59\n\n\nBRA\n12.88\n45.39\n19.76\n19.76\n\n\nCHL\n10.56\n23.44\n40.54\n24.60\n\n\nCOL\n9.14\n25.74\n34.40\n28.98\n\n\nCRI\n8.53\n22.58\n34.64\n32.25\n\n\nDOM\n11.28\n29.02\n31.27\n24.01\n\n\nECU\n11.68\n37.83\n32.22\n17.29\n\n\nHND\n14.04\n28.65\n22.82\n29.29\n\n\nMEX\n11.20\n33.16\n31.46\n20.70\n\n\nPAN\n14.24\n34.00\n31.49\n18.47\n\n\nPER\n14.92\n42.34\n31.23\n10.59\n\n\nPRY\n9.70\n24.09\n35.64\n26.86\n\n\nSLV\n8.60\n32.30\n26.27\n29.19\n\n\nURY\n7.08\n18.72\n43.77\n27.07\n\n\n\na Fuente: Elaboración propia en base a LAPOP 2018.\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este caso, a nuestra tabla le daremos el nombre de confianza más el prefijo tbl-. Y para referenciar dentro de un texto a la tabla usamos: @tbl-confianza.\nTexto de ejemplo:\n\nEn la Tabla 1 se muestra la distribución porcentual del grado de confianza interpersonal por país."
  },
  {
    "objectID": "assignment/06-practico.html#b.-resultados",
    "href": "assignment/06-practico.html#b.-resultados",
    "title": "Tablas en reportes dinámicos",
    "section": "b. Resultados",
    "text": "b. Resultados\nTambién podemos referenciar a resultados estadísticos que hayamos realizado con anterioridad en nuestro documento.\nComo ejemplo, obtengamos la correlación entre el índice de Gini de los países y su producto interno bruto (PIB) y lo guardamos en un objeto M.\n\nM &lt;- cor(lapop$gini, lapop$gdp)\n\nM\n\n[1] -0.1125219\n\n\nPara referenciar este resultado, usamos en el texto:\n `r `\nDentro de las comillas ’ ’ y después de la letra r, indicamos el nombre del objeto que contiene un resultado. En este caso, para referenciar el resultado indicamos:\n\nTexto de ejemplo:\n\nEl coeficiente de correlación de Pearson entre el índice de Gini y el producto interno bruto es negativo y pequeño = 'r M'.\n\nTexto de resultado:\n\nEl coeficiente de correlación de Pearson entre el índice de Gini y el producto interno bruto es negativo y pequeño = -0.1125219.\n\nEsta opción es especialmente útil cuando estamos escribiendo un análisis de resultados, ya que ante cualqueier contingencia con los datos, no es necesario cambiar los datos en el texto.\nUn uso más avanzado de esta opción es hacer condicional el texto en base al objeto guardado. Por ejemplo:\n\nEl coeficiente de correlación de Pearson entre el índice de Gíni y el producto interno bruto es 'r if(M &gt; 0){\"positivo\"} else {\"negativo\"}' y pequeño = 'r M'.\n\nY el resultado sería:\n\nEl coeficiente de correlación de Pearson entre el índice de Gíni y el producto interno bruto es negativo y pequeño = -0.1125219."
  },
  {
    "objectID": "assignment/04-practico.html",
    "href": "assignment/04-practico.html",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "",
    "text": "Sesión del miércoles, 8 de octubre de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#recursos-de-la-práctica",
    "href": "assignment/04-practico.html#recursos-de-la-práctica",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuesta del Módulo de Desigualdad Social de la International Social Survey Programme (ISSP) para Chile del año 2009. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ISSP Chile 2009. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ISSP 2009 para Chile.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "href": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.1 Correlación para variables ordinales",
    "text": "3.1 Correlación para variables ordinales\n\n3.1.1 Coeficiente de correlación de Spearman\nEn R calcularlo es sencillo, pero debemos tener en cuenta que las variables que relacionemos tengan un orden de rango similar: por ejemplo, que el valor más bajo sea el rango más bajo y que el valor más alto sea el rango más alto.\nObservemos las frecuencias de las variables conflict_rp (conflictos ricos-pobres) y perc_ineq (percepción desigualdad)\n\nsjmisc::frq(proc_issp$conflict_rp)\n\nConflictos: ricos - pobres (x) &lt;numeric&gt; \n# total N=1505 valid N=1438 mean=2.61 sd=0.87\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 161 | 10.70 |   11.20 |  11.20\n    2 | 442 | 29.37 |   30.74 |  41.93\n    3 | 627 | 41.66 |   43.60 |  85.54\n    4 | 208 | 13.82 |   14.46 | 100.00\n &lt;NA&gt; |  67 |  4.45 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_issp$perc_ineq)\n\nPercepción desigualdad (x) &lt;numeric&gt; \n# total N=1505 valid N=1492 mean=4.19 sd=0.83\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  16 |  1.06 |    1.07 |   1.07\n    2 |  65 |  4.32 |    4.36 |   5.43\n    3 | 105 |  6.98 |    7.04 |  12.47\n    4 | 742 | 49.30 |   49.73 |  62.20\n    5 | 564 | 37.48 |   37.80 | 100.00\n &lt;NA&gt; |  13 |  0.86 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nAhora, calculemos el coeficiente de correlación de Spearman con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"spearman\") #especificamos metodo spearman\n\n\n    Spearman's rank correlation rho\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nS = 430911455, p-value = 0.000008055\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1176912 \n\n\nAhora conocemos el valor del coeficiente de Spearman mediante al argumento rho, que es igual a 0.12, siendo positivo y pequeño según los criterios de Cohen (1988).\n\n\n3.1.2 Coeficiente de correlación Tau de Kendall\nRecomendado cuando hay un set de datos pequeños y/o cuando hay mucha repetición de observaciones en el mismo ranking. Se basa en una comparación de pares de observaciones concordantes y discordantes.\nAhora, calculemos el coeficiente de correlación Tau de Kendall con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"kendall\") #especificamos metodo kendall\n\n\n    Kendall's rank correlation tau\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nz = 4.4558, p-value = 0.000008358\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.1043735 \n\n\nEl valor del coeficiente de Kendall mediante al argumento tau, es igual a 0.1, siendo positivo y pequeño según los criterios de Cohen (1988).\n¿PERO QUÉ HACER CON LOS CASOS PERDIDOS?",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "href": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.2 Tratamiento de casos perdidos",
    "text": "3.2 Tratamiento de casos perdidos\nExisten varias formas de tratar valores perdidos, que van desde enfoques simples hasta métodos más complejos, como la imputación. En esta ocasión, nos centraremos en las dos estrategias más comunes:\n\ntrabajar exclusivamente con casos completos (listwise) o\nretener los casos con valores perdidos, pero excluyéndolos al calcular estadísticas (pairwise).\n\n\n3.2.1 Analísis con casos completos: listwise deletion\nEste enfoque es uno de los más conocidos: implica remover completamente las observaciones que tienen valores perdidos en cualquier variable de interés. En otras palabras, si una fila/caso en un conjunto de datos tiene al menos un valor faltante en alguna de las variables que estás considerando, se eliminará por completo.\nEn R, esto podemos hacerlo con la función na.omit. Para hacer esto, sigamos estos pasos:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos)\ncontamos el número de casos con el comando dim.\ncontamos cuántos y en dónde tenemos casos perdidos.\nborramos los casos perdidos con na.omit.\ncontamos nuevamente con dim para asegurarnos que se borraron.\n\n\nproc_issp_original &lt;- proc_issp\ndim(proc_issp)\n\n[1] 1505    9\n\n\n\nsum(is.na(proc_issp))\n\n[1] 745\n\n\n\ncolSums(is.na(proc_issp))\n\n          age       educyrs        income        topbot     perc_ineq \n            0            54           359            15            13 \n  conflict_rp conflict_wcmc   conflict_mw   conflict_tb \n           67            79            78            80 \n\n\n\nproc_issp &lt;- na.omit(proc_issp)\ndim(proc_issp)\n\n[1] 1021    9\n\n\nAhora nos quedamos con 1021 observaciones sin casos perdidos.\nAunque simple de implementar, con este enfoque podemos perder información importante, especialmente si los valores perdidos no se distribuyen aleatoriamente.\n\nSiempre hay que intentar rescatar la mayor cantidad de casos posibles. Por lo tanto, si un listwise genera más de un 10% de casos perdidos se debe detectar qué variables esta produciendo esta pérdida e intentar recuperar datos. Puedes revisar un ejemplo aquí.\n\n\n\n3.2.2 Retener pero excluir: pairwise deletion\nPara hacer esto en R debemos siempre verificar e indicar en nuestro código si queremos (o no) remover los NA para realizar los análisis.\n\nmean(proc_issp_original$conflict_rp); mean(proc_issp_original$perc_ineq)\n\n[1] NA\n\n\n[1] NA\n\nmean(proc_issp_original$conflict_rp, na.rm = TRUE); mean(proc_issp_original$perc_ineq, na.rm = TRUE)\n\n[1] 2.613352\n\n\n[1] 4.188338\n\n\nCon el primer código no obtuvimos información sustantiva en ciertas variables, pero con el segundo sí al remover los NA solo de dicha variable para un cálculo determinado.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#matrices-de-correlación",
    "href": "assignment/04-practico.html#matrices-de-correlación",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.3 Matrices de correlación",
    "text": "3.3 Matrices de correlación\nEn su forma simple en R se aplica la función cor a la base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\n\nM &lt;- cor(proc_issp_original, use = \"complete.obs\") \nM\n\n                       age     educyrs       income      topbot   perc_ineq\nage            1.000000000 -0.38639503 -0.028812258 -0.13419732 -0.05862427\neducyrs       -0.386395026  1.00000000  0.429527855  0.40464701  0.05369064\nincome        -0.028812258  0.42952785  1.000000000  0.31867065  0.05266991\ntopbot        -0.134197318  0.40464701  0.318670648  1.00000000 -0.04046890\nperc_ineq     -0.058624269  0.05369064  0.052669910 -0.04046890  1.00000000\nconflict_rp   -0.021976042 -0.08653773 -0.062332705 -0.09543086  0.07244029\nconflict_wcmc  0.027803884 -0.13270803 -0.127695665 -0.10271518 -0.02023346\nconflict_mw   -0.007098218 -0.00320080 -0.009719637 -0.08839869  0.09639380\nconflict_tb   -0.017972485 -0.01935586 -0.006374423 -0.07742800  0.09545628\n              conflict_rp conflict_wcmc  conflict_mw  conflict_tb\nage           -0.02197604    0.02780388 -0.007098218 -0.017972485\neducyrs       -0.08653773   -0.13270803 -0.003200800 -0.019355856\nincome        -0.06233270   -0.12769567 -0.009719637 -0.006374423\ntopbot        -0.09543086   -0.10271518 -0.088398687 -0.077427998\nperc_ineq      0.07244029   -0.02023346  0.096393796  0.095456283\nconflict_rp    1.00000000    0.49981470  0.494650501  0.666310943\nconflict_wcmc  0.49981470    1.00000000  0.448317804  0.413692854\nconflict_mw    0.49465050    0.44831780  1.000000000  0.524011301\nconflict_tb    0.66631094    0.41369285  0.524011301  1.000000000\n\n\nEste es el reporte simple, pero no muy amigable a la vista. Para una versión más reportable, utilizamos la función tab_corr.\n\nsjPlot::tab_corr(proc_issp_original, \n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nEdad\nNivel educativo\nDecil ingreso\nEstatus social subjetivo\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nEdad\n \n \n \n \n \n \n \n \n \n\n\nNivel educativo\n-0.386***\n \n \n \n \n \n \n \n \n\n\nDecil ingreso\n-0.029\n0.430***\n \n \n \n \n \n \n \n\n\nEstatus social subjetivo\n-0.134***\n0.405***\n0.319***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n-0.059\n0.054\n0.053\n-0.040\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.022\n-0.087**\n-0.062*\n-0.095**\n0.072*\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n0.028\n-0.133***\n-0.128***\n-0.103**\n-0.020\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.007\n-0.003\n-0.010\n-0.088**\n0.096**\n0.495***\n0.448***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.018\n-0.019\n-0.006\n-0.077*\n0.095**\n0.666***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLa distinción entre listwise y pairwise es relevante al momento de estimar matrices de correlación, donde esta decisión debe estar claramente explicitada y fundamentada. En el ejemplo de tabla anterior usamos listwise que es el argumento por defecto (y nos lo indica al final de la tabla).\nVeamos cómo hacerlo con pairwise:\n\nsjPlot::tab_corr(proc_issp_original, \n                 na.deletion = \"pairwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nEdad\nNivel educativo\nDecil ingreso\nEstatus social subjetivo\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nEdad\n \n \n \n \n \n \n \n \n \n\n\nNivel educativo\n-0.382***\n \n \n \n \n \n \n \n \n\n\nDecil ingreso\n-0.065*\n0.429***\n \n \n \n \n \n \n \n\n\nEstatus social subjetivo\n-0.138***\n0.402***\n0.326***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n-0.070**\n0.057*\n0.041\n-0.034\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.036\n-0.068*\n-0.057\n-0.094***\n0.087***\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n0.018\n-0.139***\n-0.122***\n-0.118***\n-0.025\n0.518***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.040\n-0.016\n-0.005\n-0.079**\n0.100***\n0.499***\n0.438***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.049\n-0.037\n0.007\n-0.076**\n0.089***\n0.651***\n0.441***\n0.527***\n \n\n\nComputed correlation used pearson-method with pairwise-deletion.\n\n\n\n\n\nCon esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n\nEn esta matriz las variables están representadas en las filas y en las columnas.\nCada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de educyrs y income es 0.43.\nLa información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno. Por convención en general se omiten las correlaciones redundantes sobre la diagonal, por eso aparece en blanco.\nEn la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva.\n\nOtra manera de presentar matrices de correlación es mediante gráficos. Veamos un ejemplo con la función corrplot de la librería corrplot sobre nuestra matriz M ya creada.\n\ndiag(M) &lt;- NA\ncorrplot::corrplot(M,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"#0D0887\"))(12),\n                   bg = \"white\",\n                   na.label = \"-\")",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#baterías-e-índices",
    "href": "assignment/04-practico.html#baterías-e-índices",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.4 Baterías e índices",
    "text": "3.4 Baterías e índices\nEn la literatura sobre percepción de conflictos se suele utilizar un índice sumativo o promedio entre los distintos indicadores sobre conflictos percibidos: conflict_rp,conflict_wcmc,conflict_mw,conflict_tb.\nEntonces, para poder responder nuestras preguntas de investigación, primero generaremos una matriz de correlaciones entre estos indicadores, luego evaluaremos su consistencia y generaremos el índice psci. Finalmente, realizaremos un test de correlación para examinar la asociación entre psci y perc_ineq.\n\nM_psci &lt;- proc_issp %&gt;% \n  dplyr::select(starts_with(\"conflict\"))\n\nsjPlot::tab_corr(M_psci, \n                 na.deletion = \"listwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n \nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nConflictos: ricos - pobres\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n0.495***\n0.448***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n0.666***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLos ítems se correlacionan de manera positiva y con tamaños de efecto moderados y altos para las ciencias sociales. Con ello, podemos pasar a evaluar sus relaciones tienen consistencia interna.\n\nalpha_psci &lt;- psych::alpha(M_psci)\nalpha_psci$total$raw_alpha\n\n[1] 0.8043218\n\n\nDe acuerdo con este resultado, el alpha de Cronbach reflejado en el raw_alpha del output es superior al estandar de 0.6 en ciencias sociales, por lo que se sostiene su consistencia.\nAhora, generemos el índice psci\n\nproc_issp &lt;- cbind(proc_issp, \"psci\" = rowMeans(proc_issp %&gt;% select(starts_with(\"conflict\")), na.rm=TRUE))\n\nsjmisc::descr(proc_issp$psci, show = c(\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\")) %&gt;%\n  kable(.,\"markdown\")\n\n\n\n\nvar\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\ndd\n1021\n0\n2.584966\n0.6986975\n3 (1-4)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#video-de-la-sesión",
    "href": "assignment/04-practico.html#video-de-la-sesión",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "Video de la sesión",
    "text": "Video de la sesión\n\n\nAcá link directo a youtube.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/02-practico.html",
    "href": "assignment/02-practico.html",
    "title": "Práctico 2: Test de hipótesis",
    "section": "",
    "text": "Sesión del miércoles, 27 de agosto de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#recursos-de-la-práctica",
    "href": "assignment/02-practico.html#recursos-de-la-práctica",
    "title": "Práctico 2: Test de hipótesis",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 2022. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "href": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "title": "Práctico 2: Test de hipótesis",
    "section": "Cinco pasos para la inferencia estadística",
    "text": "Cinco pasos para la inferencia estadística\n\nEn inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/01-practico.html",
    "href": "assignment/01-practico.html",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "Sesión del miércoles, 20 de agosto de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#revisión-básica-de-r-y-rstudio",
    "href": "assignment/01-practico.html#revisión-básica-de-r-y-rstudio",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Revisión básica de R y RStudio",
    "text": "Revisión básica de R y RStudio\nAntes de comenzar, repasemos algunos puntos clave:\n\n\n\nEstructura de RStudio\n\n\n\nConsola: aquí se pueden escribir y ejecutar comandos de manera directa.\n\nArchivo de código (.R o .qmd): permite guardar el código, comentarios y reproducir el análisis.\n\nEjecutar código:\n\nSelecciona la línea y presiona Ctrl + Enter (Windows/Linux) o Cmd + Enter (Mac).\n\nTambién puedes ejecutar un bloque completo con el botón Run.\n\n\nComentarios: se escriben con #. Todo lo que sigue en la línea después de # no se ejecuta.\n\nAtajos útiles:\n\nCtrl + Shift + C: comentar o descomentar líneas seleccionadas.\n\nCtrl + Shift + J: Añade pipe %&gt;%\nCtrl + L: limpiar la consola.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#librerías",
    "href": "assignment/01-practico.html#librerías",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Librerías",
    "text": "Librerías\nCargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\npacman::p_load permite instalarlas automáticamente si no las tienes.\n\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instalar pacman\n\nLoading required package: pacman\n\npacman::p_load(dplyr, # para sintaxis\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo\n\n\n\n\n\n\n\n¿Qué es un vector en R?\n\n\n\nEn R, un vector es la estructura de datos más básica:\n\nEs una colección ordenada de valores del mismo tipo (números, caracteres o lógicos).\nPor ejemplo, una columna en una base de datos",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "href": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "2.1. Cálculo de probabilidades con puntaje Z",
    "text": "2.1. Cálculo de probabilidades con puntaje Z\n\n# Estandarizar el vector\nz_scores &lt;- scale(vector)\n\n# Comparar valores originales y estandarizados\nhead(data.frame(Valor=vector, Z=z_scores), 10)\n\n      Valor           Z\n1  3.879049 -0.71304802\n2  4.539645 -0.35120270\n3  8.117417  1.60854170\n4  5.141017 -0.02179795\n5  5.258575  0.04259548\n6  8.430130  1.77983218\n7  5.921832  0.40589817\n8  2.469878 -1.48492941\n9  3.626294 -0.85149566\n10 4.108676 -0.58726835\n\n\nLos valores estandarizados o puntajes Z además nos permiten conocer probabilidades.\nCon R es posible generar un conjunto de datos simulados con una distribución normal.\n\nx_values &lt;- seq(-4,4,length=1000)\ny_values &lt;- dnorm(x_values)\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\n\n\n\n\n\n\n\n\nPodemos preguntar qué parte de la curva cae por debajo de un valor particular. Por ejemplo, preguntaremos sobre el valor 0 antes de ejecutar el código. Piense ¿cuál debería ser la respuesta?\n\n# Probabilidades acumuladas\npnorm(0)       # P(Z &lt;= 0)\n\n[1] 0.5\n\n\nAhora probemos los valores Z de +1,96 y -1,96.\nSabemos que estos valores aproximados marcan el 2,5% superior e inferior de la distribución normal estándar. Esto corresponde a un alfa típico \\(\\alpha = 0,05\\) para una prueba de hipótesis de dos colas.\n\npnorm(1.96)    # P(Z &lt;= 1.96)\n\n[1] 0.9750021\n\npnorm(-1.96)   # P(Z &lt;= -1.96)\n\n[1] 0.0249979\n\n\nLa respuesta nos dice lo que ya sabemos: el 97,5% de la distribución normal ocurre por debajo del valor z de 1,96.\ny si lo visualizamos:\n\nplot(x_values, y_values, type=\"l\", lty=1, xlab=\"Z value\", ylab=\"Probability\", main=\"Normal Distribution\") +\nabline(v = 1.96)\n\n\n\n\n\n\n\n\ninteger(0)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza-para-medias",
    "href": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza-para-medias",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Cálculo de intervalos de confianza para medias",
    "text": "3.1. Cálculo de intervalos de confianza para medias\nEn el caso de nuestro vector aleatorio, un intervalo de confianza para la media se puede calcular de dos maneras:\nPrimero, con la función t.test que, por defecto, estima el intervalo de confianza del 95%\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1] 4.818567 5.543057\nattr(,\"conf.level\")\n[1] 0.95\n\n\nOtra opción es con la función ci.mean del paquete Publish. Con esta función también podemos especificar si queremos estimar los CI al 95% (alpha = 0.05) o al 99% (alpha = 0.05)\n\nPublish::ci.mean(vector, alpha = 0.05)\n\n mean CI-95%     \n 5.18 [4.82;5.54]\n\n\nContamos con una media 5.18 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre 4.82 y 5.54.\n\nPublish::ci.mean(vector, alpha = 0.01)\n\n mean CI-99%     \n 5.18 [4.70;5.66]\n\n\nContamos con una media 5.18 como estimación puntual. Pero también podemos decir que con un 99% de confianza el parámetro poblacional se encontrará entre 4.70 y 5.66.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#instrucciones",
    "href": "assignment/01-practico.html#instrucciones",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Instrucciones",
    "text": "Instrucciones\n\nGenere un vector de datos simulados\n\n\nCree un vector con 500 observaciones distribuidas normalmente\nDebe tener \\(\\mu = 10\\) y \\(\\sigma = 5\\)\n\n\nset.seed(123) # Fijar la semilla para reproducibilidad\nvector2 &lt;- rnorm(500, mean = 10, sd = 5) # cambiamos a vector2 para no confundir con el otro\n\n\nCalcule y describa la distribución\n\n\nObtenga la media y desviación estándar de su vector.\n\n\nmedia &lt;- mean(vector2)\ndesv_estandar &lt;- sd(vector2)\n\ncat(\"Media:\", media, \"\\n\")\n\nMedia: 10.17295 \n\ncat(\"Desviación Estándar:\", desv_estandar, \"\\n\")\n\nDesviación Estándar: 4.863847 \n\n\n\nVisualice la distribución en un histograma\n\n\nhist(vector2,main=\"Histograma del Vector\",xlab=\"Valor\",ylab=\"Frecuencia\",col=\"cyan4\",border=\"black\")\n\n\n\n\n\n\n\n\n\nEstandarice los datos (puntajes Z)\n\n\nTransforme tu vector a puntajes Z usando scale().\n\n\nz_scores2 &lt;- scale(vector2)\n\n\nMuestre los primeros 10 valores (head()).\n\n\n# Comparar valores originales y estandarizados\nhead(data.frame(Valor=vector2, Z=z_scores2), 10)\n\n       Valor           Z\n1   7.197622 -0.61172371\n2   8.849113 -0.27217955\n3  17.793542  1.56678232\n4  10.352542  0.03692339\n5  10.646439  0.09734814\n6  18.575325  1.72751586\n7  12.304581  0.43825984\n8   3.674694 -1.33603268\n9   6.565736 -0.74163858\n10  7.771690 -0.49369607\n\n\n\nMuestre también los últimos 10 valores (tail()).\n\n\n# Comparar valores originales y estandarizados\ntail(data.frame(Valor=vector2, Z=z_scores2), 10)\n\n        Valor          Z\n491  9.471079 -0.1443041\n492 17.020251  1.4077949\n493 16.470420  1.2947503\n494  4.550041 -1.1560626\n495  5.634645 -0.9330695\n496  3.209605 -1.4316543\n497 10.909236  0.1513789\n498 10.824204  0.1338965\n499 11.820573  0.3387486\n500 12.760789  0.5320555\n\n\n\n¿Cuál es el máximo puntaje Z y el mínimo puntaje Z?\n\n\nmax_z &lt;- max(z_scores2)\nmin_z &lt;- min(z_scores2)\n\n\nVerifique la media y sd\n\n\nmean(z_scores2) # Debe ser 0\n\n[1] -1.457272e-16\n\nsd(z_scores2)    # Debe ser 1\n\n[1] 1\n\n\n\nCalcule el intervalo de confianza (IC 95%) para la media\n\n\nEstime el IC para un 95% de confianza\n\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector2)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1]  9.745589 10.600316\nattr(,\"conf.level\")\n[1] 0.95",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/03-practico.html",
    "href": "assignment/03-practico.html",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "",
    "text": "Sesión del miércoles, 1 de octubre de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/03-practico.html#recursos-de-la-práctica",
    "href": "assignment/03-practico.html#recursos-de-la-práctica",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con los datos del Estudio Longitudinal Social de Chile (ELSOC) del año 2021, elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ELSOC 2021. Desde allí, se puede descargar el archivo que contiene la base de datos ELSOC 2021.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/05-practico.html",
    "href": "assignment/05-practico.html",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "",
    "text": "Sesión del lunes, 13 de octubre de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#correlación-para-variables-nominales",
    "href": "assignment/05-practico.html#correlación-para-variables-nominales",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.1 Correlación para variables nominales",
    "text": "3.1 Correlación para variables nominales\nAl igual que otros coeficientes de correlación, las correlaciones entre categóricas:\n\nOscila entre -1 y 1.\nIndica la dirección y fuerza de asociación entre variables.\nSu tamaño de efecto se puede interpretar a partir de ciertos estándares.\nSe interpreta de la misma forma que otros coeficientes de correlación.\n\n\n3.1.1 Correlación punto biserial\nLa correlación punto biserial se utiliza para calcular la correlación entre una variable categórica dicotómica y una variable continua.\nVeamos la frecuencia de sexo y la media de ingresos y1.\n\nsjmisc::frq(proc_casen$sexo)\n\nSexo (x) &lt;numeric&gt; \n# total N=3000 valid N=3000 mean=1.53 sd=0.50\n\nValue |     Label |    N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n    1 | 1. Hombre | 1404 | 46.80 |   46.80 |  46.80\n    2 |  2. Mujer | 1596 | 53.20 |   53.20 | 100.00\n &lt;NA&gt; |      &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nmean(proc_casen$y1, na.rm = T)\n\n[1] 619435.3\n\n\nObtengamos la correlación punto biserial entre sexo e ingresos.\n\ncor.test(proc_casen$sexo, proc_casen$y1)\n\n\n    Pearson's product-moment correlation\n\ndata:  proc_casen$sexo and proc_casen$y1\nt = -4.0718, df = 912, p-value = 0.00005069\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.19676351 -0.06937883\nsample estimates:\n       cor \n-0.1336231 \n\n\n\n\n3.1.2 Correlación tetracorica\nLa correlación tetracórica se utiliza para calcular la correlación entre dos variables binarias categóricas, es decir, variables nominales dicómoticas (solo dos posibles valores).\nVeamos las frecuencias de sexo y disc_fisica.\n\nsjmisc::frq(proc_casen$sexo)\n\nSexo (x) &lt;numeric&gt; \n# total N=3000 valid N=3000 mean=1.53 sd=0.50\n\nValue |     Label |    N | Raw % | Valid % | Cum. %\n---------------------------------------------------\n    1 | 1. Hombre | 1404 | 46.80 |   46.80 |  46.80\n    2 |  2. Mujer | 1596 | 53.20 |   53.20 | 100.00\n &lt;NA&gt; |      &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_casen$disc_fisica)\n\nDiscriminado por su apariencia física (x) &lt;numeric&gt; \n# total N=3000 valid N=3000 mean=1.03 sd=0.17\n\nValue |    N | Raw % | Valid % | Cum. %\n---------------------------------------\n    1 | 2916 | 97.20 |   97.20 |  97.20\n    2 |   84 |  2.80 |    2.80 | 100.00\n &lt;NA&gt; |    0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nObtengamos la correlación tetrácorica entre sexo y discriminación por apariencia física.\n\nmatriz &lt;- proc_casen %&gt;% select(sexo, disc_fisica) # creamos matriz con var de interes\n\npsych::tetrachoric(matriz, na.rm = T)\n\nCall: psych::tetrachoric(x = matriz, na.rm = T)\ntetrachoric correlation \n            sexo  dsc_f\nsexo         1.00      \ndisc_fisica -0.05  1.00\n\n with tau of \n       sexo disc_fisica \n      -0.08        1.91 \n\n\n\n\n3.1.3. Correlación Policórica\nLa correlación policórica se utiliza para calcular la correlación entre dos variables ordinales categóricas, es decir, variables ordinales cuyos posibles valores siguen un orden (por ejemplo, variables tipo Likert).\nVeamos las frecuencias de ayuda_moverse y ayuda_thogar.\n\nsjmisc::frq(proc_casen$ayuda_moverse)\n\ns33c. Últ. 30 días, ayuda de otra persona para: Moverse dentro de la casa (x) &lt;numeric&gt; \n# total N=3000 valid N=68 mean=3.21 sd=1.49\n\nValue |            Label |    N | Raw % | Valid % | Cum. %\n----------------------------------------------------------\n  -99 |      No responde |    0 |  0.00 |    0.00 |   0.00\n  -88 |          No sabe |    0 |  0.00 |    0.00 |   0.00\n    1 |         1. Nunca |   13 |  0.43 |   19.12 |  19.12\n    2 |    2. Casi nunca |    9 |  0.30 |   13.24 |  32.35\n    3 | 3. Algunas veces |   18 |  0.60 |   26.47 |  58.82\n    4 |  4. Muchas veces |    7 |  0.23 |   10.29 |  69.12\n    5 |       5. Siempre |   21 |  0.70 |   30.88 | 100.00\n &lt;NA&gt; |             &lt;NA&gt; | 2932 | 97.73 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_casen$ayuda_thogar)\n\ns33h. Últ. 30 días, ayuda de otra persona para: Realizar sus tareas del hogar (x) &lt;numeric&gt; \n# total N=3000 valid N=80 mean=3.80 sd=1.39\n\nValue |            Label |    N | Raw % | Valid % | Cum. %\n----------------------------------------------------------\n  -99 |      No responde |    0 |  0.00 |    0.00 |   0.00\n  -88 |          No sabe |    0 |  0.00 |    0.00 |   0.00\n    1 |         1. Nunca |   10 |  0.33 |   12.50 |  12.50\n    2 |    2. Casi nunca |    3 |  0.10 |    3.75 |  16.25\n    3 | 3. Algunas veces |   17 |  0.57 |   21.25 |  37.50\n    4 |  4. Muchas veces |   13 |  0.43 |   16.25 |  53.75\n    5 |       5. Siempre |   37 |  1.23 |   46.25 | 100.00\n &lt;NA&gt; |             &lt;NA&gt; | 2920 | 97.33 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nObtengamos la correlación policórica entre si la persona necesitó ayuda para moverse dentro de la casa y si necesitó ayuda para realizar tareas dentro del hogar, en los últimos 30 días.\n\nmatriz &lt;- proc_casen %&gt;% select(ayuda_moverse, ayuda_thogar) # creamos matriz con var de interes\n\npsych::polychoric(matriz, na.rm = T)\n\nCall: psych::polychoric(x = matriz, na.rm = T)\nPolychoric correlations \n              ayd_m ayd_t\nayuda_moverse 1.00       \nayuda_thogar  0.82  1.00 \n\n with tau of \n                  1     2     3     4\nayuda_moverse -0.87 -0.46  0.22 0.499\nayuda_thogar  -1.15 -0.98 -0.32 0.094",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#tablas-de-contingencia",
    "href": "assignment/05-practico.html#tablas-de-contingencia",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.2 Tablas de contingencia",
    "text": "3.2 Tablas de contingencia\nUna tabla de contingencia es una de las maneras más simples y útiles para representar el cruce entre dos variables categóricas.\nCon ella, podemos obtener en las celdas las frecuencias conjuntas entre ambas variables, es decir, cuántos casos de una determinada categoría de la variable Y ocurren conjuntamente con una determinada categoría de la variable X.\nAdemás, podemos presentar los totales de cada fila y columna al exterior de la tabla, también conocidas como frecuencias marginales.\nVeamos un ejemplo con ss_salud y universitaria:\n\nsjPlot::sjt.xtab(var.row = proc_casen$ss_salud, var.col = proc_casen$universitaria, \n                 show.summary = F, emph.total = T)\n\n\n\n\n\n\n\n\n\n\ns13. ¿A qué sistema\nprevisional de salud\npertenece?\nEducación superior\nalcanzada (si/no)\nTotal\n\n\nNo\nSí\n\n\n1. Sistema Público\nFONASA\n2027\n524\n2551\n\n\n2. Isapre\n111\n167\n278\n\n\n3. FF.AA. y del\nOrden\n37\n22\n59\n\n\n4. Ninguno\n(particular)\n61\n15\n76\n\n\nTotal\n2236\n728\n2964\n\n\n\n\n\nVeamos cómo incorporar el porcentaje fila y columna en la tabla.\n\nsjPlot::sjt.xtab(var.row = proc_casen$ss_salud, \n                 var.col = proc_casen$universitaria, \n                 show.summary = F, \n                 emph.total = T, \n                 show.row.prc = T, # porcentaje fila\n                 show.col.prc = T # porcentaje columna\n                 )\n\n\n\n\n\n\n\n\n\n\ns13. ¿A qué sistema\nprevisional de salud\npertenece?\nEducación superior\nalcanzada (si/no)\nTotal\n\n\nNo\nSí\n\n\n1. Sistema Público\nFONASA\n2027\n79.5 %\n90.7 %\n524\n20.5 %\n72 %\n2551\n100 %\n86.1 %\n\n\n2. Isapre\n111\n39.9 %\n5 %\n167\n60.1 %\n22.9 %\n278\n100 %\n9.4 %\n\n\n3. FF.AA. y del\nOrden\n37\n62.7 %\n1.7 %\n22\n37.3 %\n3 %\n59\n100 %\n2 %\n\n\n4. Ninguno\n(particular)\n61\n80.3 %\n2.7 %\n15\n19.7 %\n2.1 %\n76\n100 %\n2.6 %\n\n\nTotal\n2236\n75.4 %\n100 %\n728\n24.6 %\n100 %\n2964\n100 %\n100 %\n\n\n\n\n\nAquí, los porcentajes fila aparecen en azul y los porcentajes columna en verde.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#prueba-de-hipótesis-con-chi-cuadrado-x2",
    "href": "assignment/05-practico.html#prueba-de-hipótesis-con-chi-cuadrado-x2",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.3. Prueba de hipótesis con Chi cuadrado (\\(X^2\\))",
    "text": "3.3. Prueba de hipótesis con Chi cuadrado (\\(X^2\\))\nPara determinar si existe una asociación significativa entre dos variables categóricas se utiliza la prueba de Chi-cudrado (\\(X^2\\)). Esta se basa en un test de diferencia, donde se compara nuestra tabla de contingencia y una tabla donde no existe asociación entre variables (\\(H_0\\)), que representa la hipótesis nula. La lógica detrás es que si nuestra tabla es significativamente distinta de una tabla sin asociación, entonces podemos rechazar la hipóteis nula.\n\n\n\n\n\n\nPrueba de Chi-cuadrado\n\n\n\nContrastamos la hipótesis nula (o de trabajo) de que las variables son independientes entre ellas: \\[  H_{0}: \\pi_{fc} =  \\pi_{f}\\pi_{c} \\]\nEn relación a una hipótesis alternativa sobre que las variables están relacionadas: \\[  H_{A}:  \\pi_{fc} \\neq  \\pi_{f}\\pi_{c} \\]\n\n\nVeamos un ejemplo con nuestros datos. Evaluemos si el nivel educacional se relaciona con el tipo de sistema de salud al que pertenecen las personas en Chile durante el 2022.\nEn R, utilizamos la función chisq.test():\n\nchi_results &lt;- chisq.test(table(proc_casen$ss_salud, proc_casen$universitaria))\n\nchi_results\n\n\n    Pearson's Chi-squared test\n\ndata:  table(proc_casen$ss_salud, proc_casen$universitaria)\nX-squared = 217.56, df = 3, p-value &lt; 0.00000000000000022\n\n\nObtuvimos nuestro resultado, pero no es muy amigable a la vista. Generemos una tabla de calidad para que sea reportable.\n\nstats.table &lt;- tidy(chi_results, conf_int = T)\nnice_table(stats.table)\n\n\n\nTabla 1\n\n\n\nstatisticpparameterMethod217.56&lt; .001***3Pearson's Chi-squared test\n\n\n\n\n\nVisualicemos la distribución de esta prueba y su zona de rechazo.\n\nggchisqtest(chi_results)\n\n\n\n\n\n\n\n\nA partir de estos resultados, podemos reportar lo siguiente:\n\nA raíz de la prueba de \\(X^2\\), vemos que existe evidencia para rechazar la hipótesis nula sobre no asociación. Por ende, la asociación entre el nivel educacional y el tipo de sistema de salud al que pertenecen las personas en Chile es estadísticamente significativa (\\(X^2\\) = 217, p &lt; 0.05)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#tamaño-de-efecto-con-phi-y-v-de-cramer",
    "href": "assignment/05-practico.html#tamaño-de-efecto-con-phi-y-v-de-cramer",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.4. Tamaño de efecto con Phi y V de Cramer",
    "text": "3.4. Tamaño de efecto con Phi y V de Cramer\n\nEstadístico Phi (Φ)\nEl estadístico Phi mide la asociación entre dos variables categóricas en una tabla de contingencia de 2x2. La fórmula es:\n\\[\n\\Phi = \\sqrt{\\frac{\\chi^2}{n}}\n\\]\ndonde:\n\n\\(\\chi^2\\) es el valor del estadístico chi-cuadrado,\n\\(n\\) es el tamaño total de la muestra.\n\nEl valor de \\(\\Phi\\) varía entre -1 y 1. Un valor de 0 indica ausencia de asociación, mientras que valores cercanos a -1 o 1 indican una asociación más fuerte.\n\n\nV de Cramer\nEl V de Cramer es una extensión del estadístico Phi para tablas de contingencia mayores de 2x2. Su fórmula es:\n\\[\nV = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\n\\]\ndonde:\n\n\\(\\chi^2\\) es el valor del chi-cuadrado,\n\\(n\\) es el tamaño de la muestra,\n\\(k\\) es el número de filas o columnas, el que sea menor.\n\nLos valores de \\(V\\) también varían entre 0 y 1, donde 0 indica ausencia de asociación, y valores cercanos a 1 indican una asociación más fuerte.\nEn nuestro ejemplo, nuestra tabla de contingencia es de 4x2, por ende, debemos usar el estadístico V de Cramer. En R lo podemos calcular directamente siguiendo la formula:\n\n# Guardar el test de chi cuadrado\nchi_result &lt;- chisq.test(table(proc_casen$ss_salud, proc_casen$universitaria))\nn &lt;- na.omit(proc_casen %&gt;% select(ss_salud, universitaria)) %&gt;% nrow()\n\n# Cálculo de V de Cramer\ncramer &lt;- sqrt(chi_result$statistic / n*(2-1))\ncramer\n\nX-squared \n0.2709275 \n\n\no directamente con sjstats\n\nsjstats::cramer(table(proc_casen$ss_salud, proc_casen$universitaria))\n\n[1] 0.2709275\n\n\nCon un valor de 0.271, vemos que la magnitud de la asociación entre las variables es moderada.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#video-de-la-sesión",
    "href": "assignment/05-practico.html#video-de-la-sesión",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "Video de la sesión",
    "text": "Video de la sesión\n\n\nAcá link directo a youtube.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/07-practico.html",
    "href": "assignment/07-practico.html",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "",
    "text": "Sesión del lunes, 18 de noviembre de 2024"
  },
  {
    "objectID": "assignment/07-practico.html#recursos-de-la-práctica",
    "href": "assignment/07-practico.html#recursos-de-la-práctica",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018."
  },
  {
    "objectID": "assignment/07-practico.html#crear-un-documento-quarto",
    "href": "assignment/07-practico.html#crear-un-documento-quarto",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "Crear un documento Quarto",
    "text": "Crear un documento Quarto\nPara recordar cómo generar un archivo en Quarto, visitar el práctico 6 del curso."
  },
  {
    "objectID": "assignment/index.html#descripción",
    "href": "assignment/index.html#descripción",
    "title": "Prácticos",
    "section": "Descripción",
    "text": "Descripción\nLas clases se acompañan de guías de trabajo con énfasis en la aplicación práctica mediante el uso de software estadístico.\nLas guías se encontrarán disponibles en esta página (link a la izquierda). Habrá dos guías para la Unidad 1 (Inferencia), y 2 para la Unidad 2 (Asociación). La unidad 3 será eminentemente práctica y de aplicación.\nLas guías son desarrolladas de manera autónoma, y cada dos semanas los días martes habrá un espacio práctico de revisión de las guías y de consultas. Para ello se espera que quienes puedan traigan su computador a la sala, y quienes no tienen lo podrán hacer simultáneamente en la sala de computación 345.\nEn las prácticas vamos a trabajar con el software R, Versión 4.4.1.",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#trabajo-con-software-r",
    "href": "assignment/index.html#trabajo-con-software-r",
    "title": "Prácticos",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "href": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "title": "Prácticos",
    "section": "Sobre errores y consultas sobre problemas con R y ejecución de código",
    "text": "Sobre errores y consultas sobre problemas con R y ejecución de código\nEn caso de preguntas sobre las clases hacerlas en Foro prácticos\n\nInstalación de R & RStudio\nPara esta versión del curso vamos a trabajar con el programa R Version 4.4.1 y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://rstudio.com/products/rstudio/ y bajar/instalar RStudio desktop, Open Source License (libre).\nEn caso de dudas se puede revisar el siguiente video tutorial de instalación de R & RStudio, preparado por Julio Iturra (apoyo docente) del curso Estadística Multivariada 2020:\n\n\n\n\n\nSi por alguna razón se prefiere trabajar sin descargar, también se puede utilizar RCloud, abajo un tutorial preparado por Valentina Andrade para el curso de Estadística Multivariada:\n\n\n\n\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File &gt; New File &gt; R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File &gt; Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Presentación",
    "section": "",
    "text": "Sesión del lunes, 4 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nForo\nEn caso de preguntas sobre las clases hacerlas en Foro Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Introducción"
    ]
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Inferencia 2: Curva normal y error estándar",
    "section": "",
    "text": "Sesión del lunes, 11 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 2"
    ]
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Inferencia 4 - Test de hipótesis",
    "section": "",
    "text": "Sesión del lunes, 18 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 4"
    ]
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Sesión del lunes, 8 de septiembre de 2025",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "content/07-content.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "href": "content/07-content.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "A. Estimación del promedio de salarios (de la población)",
    "text": "A. Estimación del promedio de salarios (de la población)\n\nTengo que el promedio de salarios de la muestra es: 900.000\nPromedio de salarios de la población: \\(X\\)?\n\nNo podemos dar un valor certero para el promedio poblacional, pero si un rango probable de valores.\n\nTest de hipótesis a realizar\n¿Qué tipo de aproximación de test de hipótesis corresponde en este caso? Recordemos las dos aproximaciones principales para test de hipótesis: a) contraste con valor crítico, y b) generación de intervalo de confianza. En general se pueden aplicar siempre las dos, pero su pertinencia es distinta según lo que se esté estimando:\n\nen este caso (estimación del promedio) se podría realizar la alternativa de contraste con valor crítico, que nos permitiría rechazar (o no) la hipótesis nula de que el promedio es cero en la población.\nya que la alternativa anterior no es muy informativa en este caso, en la estimación puntual de parámetros (como el promedio) se prefiere utilizar un rango de probabilidad, expresado en un intervalo de confianza.\n\nPor lo tanto, en este caso lo que es más pertinente es la alternativa b: estimación de un intervalo de confianza\n\n\nConstrucción de intervalo y 5 pasos de la inferencia\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n1. Formular hipótesis\nContrastamos la hipótesis nula (el promedio es igual a 0 en la población):\n\\[H_{0}: \\bar{X}_{salarios}=0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salarios} \\neq 0\\]\n\n\n2.Obtener error estándar y estadístico de prueba empírico correspondiente (ej: Z o t)\nEl error estándar (SE, por Standard Error) del promedio es:\n\\[SE_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\nReemplazando:\n\\[SE_{\\bar{X}}=\\frac{300000}{\\sqrt{900}}=\\frac{300000}{30}=10000\\]\n\n\nCódigo\nerror_estandar &lt;- desviacion_estandar_salarios / sqrt(n)\nerror_estandar\n\n\n[1] 10000\n\n\n\n\n3. Establecer la probabilidad de error α y valor crítico (teórico) de la prueba correspondiente\nEsta informació fue proporcionada en el enunciado: \\(\\alpha=5%\\), valor crítico= 1,96\n\n\n4. Cálculo de intervalo de confianza\nRecordar fórmula del intervalo de 95% de confianza para el promedio:\n\\[\\begin{align*}\n\\bar{x} &\\pm Z_{\\alpha/2}*SE_{\\bar{x}} \\\\\\\\\n850000 &\\pm 1.96*10000 \\\\\\\\\n850000 &\\pm 19600 \\\\\\\\\nCI[830400&;869600]\n\\end{align*}\\]\nEn R:\n\n\nCódigo\n# Calcular el intervalo de confianza al 95%\nz_95 &lt;- 1.96  # Valor z para el 95% de confianza\nlimite_inferior &lt;- promedio_salarios - z_95 * error_estandar\nlimite_superior &lt;- promedio_salarios + z_95 * error_estandar\n\n# Mostrar los resultados\ncat(\"Intervalo de confianza al 95%: [\", round(limite_inferior, 2), \", \", round(limite_superior, 2), \"]\\n\")\n\n\nIntervalo de confianza al 95%: [ 830400 ,  869600 ]\n\n\n\n\n5. Interpretación\nUtilizando una muestra de 900 individuos, se estimó el promedio de ingresos en $850,000 con una desviación estándar de $300,000. El error estándar para esta estimación es $10,000, y el intervalo de confianza al 95%, calculado con estos parámetros, se extiende de $830,400 a $869,600. Este intervalo refleja que, con un 95% de confianza, se puede afirmar que el promedio verdadero de ingresos en la población se encuentra dentro de este rango, asumiendo una distribución normal de los ingresos.",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "content/07-content.html#estimación-de-diferencia-de-medias",
    "href": "content/07-content.html#estimación-de-diferencia-de-medias",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "2. Estimación de diferencia de medias",
    "text": "2. Estimación de diferencia de medias\nPara este ejercicio consideramos la siguiente información proporcionada arriba:\n\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96\nerror estándar de la diferencia de medias= 15000\n\nCon esta información ya podemos calcular la diferencia de promedios de la muestra:\n\\(\\bar{X}_{salario-universitario}-\\bar{X}_{salario-técnico}=1500000-1200000=300000\\)\nLa pregunta ahora es: ¿existe esta diferencia de promedios en la población?\n\nTest de hipótesis a realizar\nPara el caso anterior de la estimación del promedio hablamos de dos aproximaciones: a) contraste con valor crítico, y b) intervalo de confianza. En este caso (estimación de diferencias de promedio) tradicionalmente se utiliza el contraste con valor crítico, ya que lo central es poder establecer si existen o no diferencias en la población. Complementariamente, también se puede entregar información del intervalo de confianza.\nPor lo tanto, en este caso lo que es más pertinente es la alternativa a: contraste con valor crítico, pero también es recomendable agregar la información del intervalo de confianza.\n\n\nContraste con valor crítico y 5 pasos de la inferencia\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n1. Formular hipótesis\nContrastamos la hipótesis nula (no hay diferencias de promedios entre grupos):\n\\[H_{0}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto}= 0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto} \\neq 0\\]\n\n\n2. Obtener error estándar y estadístico de prueba empírico correspondiente (ej: Z o t)\nEl error estándar de la diferencias de promedios es:\n\\[SE=\\sqrt{\\frac{\\sigma_{diff}}{n_a}+\\frac{\\sigma_{diff}}{n_b}}\\]\nLa información sobre el resultado de este cálculo se nos entrega inicialmente y es igual a 15000\nCon esto podemos calcular el valor del t empírico:\n\\(t=\\frac{diferenciamedias}{se_{diferenciamedias}} \\frac{(\\bar{x}_1-\\bar{x}_2)}{se_{(\\bar{x}_1-\\bar{x}_2)}}\\)\nCon nuestros datos:\n\\(t=\\frac{300000}{15000}=20\\)\n\n\n3. Establecer la probabilidad de error α y valor crítico (teórico) de la prueba correspondiente\n\nProporcionado en el enunciado\n\n\n\n4. Contraste valores empírico/crítico (e intervalo de confianza)\nt empírico= 20 &gt; t critico=1,96\nIntervalo al 95% de confianza:\n\\[\\begin{align*}\n\\bar{x}_1-\\bar{x}_2 &\\pm t_{\\alpha/2}*SE_{\\bar{x_1}-\\bar{x_2}} \\\\\\\\\n300000 &\\pm 1.96*15000 \\\\\\\\\n300000 &\\pm 29400 \\\\\\\\\nCI[270600&\\ ;329400]\n\\end{align*}\\]\n\n\n5. Interpretación\nSe llevó a cabo una prueba t para evaluar las diferencias salariales entre graduados de institutos técnicos-profesionales y universidades, utilizando un tamaño de muestra de 900 para cada grupo. La diferencia de medias observada fue de $750,000, con un error estándar fijo de $15,000 para esta diferencia. El análisis resultó en un valor t de 50.00, indicando una diferencia estadísticamente significativa entre los dos grupos (p &lt; .01). Este valor t refleja que los graduados universitarios tienen un ingreso promedio significativamente mayor en comparación con los graduados de institutos técnicos-profesionales. Estos resultados sugieren una marcada disparidad salarial en función del nivel educativo alcanzado, subrayando la importancia de las decisiones educativas en las trayectorias de ingresos de los individuos.",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Inferencia en correlación y magnitud del coeficiente",
    "section": "",
    "text": "Sesión del miércoles, 10 de septiembre de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 2"
    ]
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Asociación con categóricas 1",
    "section": "",
    "text": "Sesión del lunes, 29 de septiembre de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 4"
    ]
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Documentos dinámicos",
    "section": "",
    "text": "Sesión del lunes, 11 de noviembre de 2024\n\n\n\n\n\nDocumento de presentación"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección se encuentran disponibles los documentos de presentación que sirven de base a cada clase, en el menú de la izquierda Presentaciones. Los documentos son en formato html (no son ppt), producidos con Xaringan. Para verlos en pantalla completa presionar F sobre el documento, y para una vista general de todas las slides presionar O.\nTambién a la izquierda hay un link al Foro para hacer preguntas relacionadas con las clases.\nCada clase tiene como referencia lecturas que deben completarse antes de la sesión correspondiente.",
    "crumbs": [
      "Clases",
      "Descripción"
    ]
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html",
    "href": "evaluations/plantilla_reporte/reporte.html",
    "title": "Título del trabajo grupal",
    "section": "",
    "text": "Definición de la problemática a abordar, su relevancia y principales conceptos.\nEn este apartado es importante considerar:\n\nRelevancia del tema de investigación.\nProblematización: señalar problema de investigación y principales antecedentes\nPrecisar los conceptos centrales a investigar: Ejemplo “vamos a analizar la participación informal, entendiendo por ello la frecuencia de participación en actividades como marchas, boycotts y en redes sociales” [cita que apoye la definición].\nMencionar el principal objetivo del trabajo y las hipótesis de investigación en el párrafo final de esta sección (ej: se espera que el nivel educacional sea mayor en zonas urbanas en relación a zonas rurales). Mencionar al menos tres hipótesis.\n\nEsta sección debe estar respaldada por al menos 5 referencias bibliográficas."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#datos",
    "href": "evaluations/plantilla_reporte/reporte.html#datos",
    "title": "Título del trabajo grupal",
    "section": "2.1 Datos",
    "text": "2.1 Datos\nDescripción detallada de los datos a utilizar. Acá también se puede insertar el chunk para llamar los datos que se van a analizar:"
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#variables",
    "href": "evaluations/plantilla_reporte/reporte.html#variables",
    "title": "Título del trabajo grupal",
    "section": "2.2 Variables",
    "text": "2.2 Variables\nDescripción de cada una de las variables, su operacionalización y medición. Esta sección también incluye una tabla de descriptivos básicos.\n\n\n\n\n\n\nNota\n\n\n\nAtención sobre recodificación de variables\nEs importante que las variables sean recodificadas en el sentido del atributo que se está midiendo de menos a más, es decir, que el mayor valor exprese la mayor presencia del atributo.\n\nEjemplo 1: si lo que se está midiendo es apoyo al aborto libre en una escala donde 5 es totalmente en desacuerdo y 1 totalmente de acuerdo, se deben recodificar los valores para que un mayor puntaje exprese mayor apoyo al aborto libre. En concreto: 1=5, 2=4, 4=2, 5=1.\nEjemplo 2: variable dicotómica 0: si vota, 1: no vota, debe ser recodificada a 1: si vota, 0: no vota."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#métodos",
    "href": "evaluations/plantilla_reporte/reporte.html#métodos",
    "title": "Título del trabajo grupal",
    "section": "2.3 Métodos",
    "text": "2.3 Métodos\nMencionar los métodos estadísticos a utilizar para el contraste de hipótesis y cálculo del tamaño de efecto."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#análisis-descriptivo",
    "href": "evaluations/plantilla_reporte/reporte.html#análisis-descriptivo",
    "title": "Título del trabajo grupal",
    "section": "3.1 Análisis descriptivo",
    "text": "3.1 Análisis descriptivo\nTablas y/o gráficos comentados, univariados y bivariados según sea más pertinente. Para esto considere medidas de tendencia central, dispersión y frecuencias, siempre considerando el nivel de medición de sus variables. En los casos que sea atingente, incluya los intervalos de confianza al 95 %."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#análisis-estadístico-bivariado",
    "href": "evaluations/plantilla_reporte/reporte.html#análisis-estadístico-bivariado",
    "title": "Título del trabajo grupal",
    "section": "3.2 Análisis estadístico bivariado",
    "text": "3.2 Análisis estadístico bivariado\nConsiderar la estimación de coeficientes de correlación y también medidas de asociación para variables categóricas. Esta parte del análisis se relaciona directamente con las hipótesis planteadas. Para esto realizar pruebas de hipótesis estadísticas, estadísticos de tamaño del efecto y tablas de contingencia / cruzadas, siempre considerando el nivel de medición de sus variables.\nAl final de esta sección también se realiza la discusión de resultados en relación a las hipótesis planteadas"
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#compliance-and-treatment-effects",
    "href": "example/cace.html#compliance-and-treatment-effects",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets &lt;- read_csv(\"data/bed_nets_observed.csv\") %&gt;%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine &lt;- read_csv(\"data/bed_nets_time_machine.csv\") %&gt;%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model &lt;- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT &lt;- tidy(itt_model) %&gt;%\n  filter(term == \"treatmentTreatment\") %&gt;%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %&gt;%\n  group_by(treatment, bed_net) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   &lt;chr&gt;     &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c &lt;- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE &lt;- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls &lt;- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html",
    "href": "files/reporte_notas/reporte_notas.html",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "pacman::p_load(tidyverse, sjmisc, sjPlot, kableExtra, sjlabelled, readxl, here)\n\n\n\n [1] \"Nº\"          \"Persona\"     \"1a\"          \"1b\"          \"1c\"         \n [6] \"2a\"          \"2b\"          \"2c\"          \"Puntos\"      \"Nota\"       \n[11] \"Asistida\"    \"Justificada\" \"asist_total\"\n\n\n\n\n\n\n# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Intervalo de Confianza\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Error tipo II\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistida &lt;- set_label(x = prueba1$asistida, \n                         label = \"Asistencia Efectiva\")\nprueba1$asist_total &lt;- set_label(x = prueba1$asist_total, \n                         label = \"Asistencia Registrada\")\n\n\n\n\n\nprueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n4\np1a\nIntervalo de Confianza\n70\n0.55\n0.30\n1 (0-1)\n\n\n5\np1b\nError tipo II\n70\n0.31\n0.45\n1 (0-1)\n\n\n6\np1c\nRechazo H0 valor p\n70\n0.81\n0.70\n2 (0-2)\n\n\n7\np2a\nFormulación hipótesis\n70\n1.47\n0.69\n2 (0-2)\n\n\n8\np2b\nContraste de prueba t\n70\n2.59\n1.32\n4 (0-4)\n\n\n9\np2c\nIntervalo confianza de prueba t\n70\n1.26\n0.74\n2 (0-2)\n\n\n3\nnota\nNota final\n70\n4.50\n1.43\n6 (1-7)\n\n\n2\nasistida\nAsistencia Efectiva\n70\n10.16\n1.86\n8 (4-12)\n\n\n1\nasist_total\nAsistencia Registrada\n70\n10.24\n1.81\n8 (4-12)\n\n\n\n\n\n\n\n\n\nhist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n25\n35.71\n35.71\n35.71\n\n\n\n4.0-5.0\n14\n20.00\n20.00\n55.71\n\n\n\n5.0-6.0\n24\n34.29\n34.29\n90.00\n\n\n\n6.0-7.0\n7\n10.00\n10.00\n100.00\n\n\n\ntotal N=70 · valid N=63 · x̄=2.19 · σ=1.04\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)\n\n\n\n\n\ntab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nIntervalo de Confianza\nError tipo II\nRechazo H0 valor p\nFormulación hipótesis\nContraste de prueba t\nIntervalo confianza de prueba t\nNota final\nAsistencia Efectiva\nAsistencia Registrada\n\n\nIntervalo de Confianza\n \n \n \n \n \n \n \n \n \n\n\nError tipo II\n0.337**\n \n \n \n \n \n \n \n \n\n\nRechazo H0 valor p\n0.271*\n0.399***\n \n \n \n \n \n \n \n\n\nFormulación hipótesis\n0.180\n0.202\n0.014\n \n \n \n \n \n \n\n\nContraste de prueba t\n0.243*\n0.244*\n0.214\n0.485***\n \n \n \n \n \n\n\nIntervalo confianza de prueba t\n0.275*\n0.280*\n0.405***\n0.281*\n0.590***\n \n \n \n \n\n\nNota final\n0.453***\n0.525***\n0.544***\n0.592***\n0.849***\n0.772***\n \n \n \n\n\nAsistencia Efectiva\n0.278*\n-0.048\n0.117\n0.355**\n0.352**\n0.382**\n0.398***\n \n \n\n\nAsistencia Registrada\n0.316**\n0.006\n0.106\n0.380**\n0.382**\n0.377**\n0.427***\n0.980***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nggplot(prueba1, aes(x = asist_total, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 4) + \n  labs(title = \"Relación entre asistencia y notas en Evaluación 1 (r=0.43)\") + \n  labs(x = \"Asistencia\", y = \"Nota\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(1, 12, by = 1), limits = c(1, 12)) +   # Ajuste del eje de asistencia\n  scale_y_continuous(breaks = seq(1, 7, by = 1), limits = c(1, 7))       # Ajuste del eje de notas de 1 a 7\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(asist_total_cat=cut(asist_total, breaks=c(-Inf,7,8,9,10,11,Inf), labels=c(\"Menos de 8\",\"8\",\"9\",\"10\",\"11\",\"12\")))\n\nfrq(prueba1$asist_total_cat, out=\"browser\", show.na = FALSE, title = \"Asistencia\")\n\n\nAsistencia\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenos de 8\n6\n8.57\n8.57\n8.57\n\n\n\n8\n4\n5.71\n5.71\n14.29\n\n\n\n9\n10\n14.29\n14.29\n28.57\n\n\n\n10\n11\n15.71\n15.71\n44.29\n\n\n\n11\n19\n27.14\n27.14\n71.43\n\n\n\n12\n20\n28.57\n28.57\n100.00\n\n\n\ntotal N=70 · valid N=50 · x̄=4.33 · σ=1.58\n\n\n\n\nprueba1 %&gt;% # se especifica la base de datos\n  dplyr::select(asist_total_cat, nota)  %&gt;% # se seleccionan las variables\n  dplyr::group_by(Asistencia=sjlabelled::as_label(asist_total_cat)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=round(mean(nota),2),SD=round(sd(nota),2)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nAsistencia\nObs.\nPromedio\nSD\n\n\n\n\nMenos de 8\n6\n2.98\n1.63\n\n\n8\n4\n3.40\n0.20\n\n\n9\n10\n4.33\n1.46\n\n\n10\n11\n4.46\n1.56\n\n\n11\n19\n4.62\n1.44\n\n\n12\n20\n5.16\n0.98\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-asist_total_cat)\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 8\nSample units: 70\nalpha: 0.753"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "href": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "pacman::p_load(tidyverse, sjmisc, sjPlot, kableExtra, sjlabelled, readxl, here)\n\n\n\n [1] \"Nº\"          \"Persona\"     \"1a\"          \"1b\"          \"1c\"         \n [6] \"2a\"          \"2b\"          \"2c\"          \"Puntos\"      \"Nota\"       \n[11] \"Asistida\"    \"Justificada\" \"asist_total\""
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#etiquetados",
    "href": "files/reporte_notas/reporte_notas.html#etiquetados",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Intervalo de Confianza\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Error tipo II\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistida &lt;- set_label(x = prueba1$asistida, \n                         label = \"Asistencia Efectiva\")\nprueba1$asist_total &lt;- set_label(x = prueba1$asist_total, \n                         label = \"Asistencia Registrada\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "href": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "prueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n4\np1a\nIntervalo de Confianza\n70\n0.55\n0.30\n1 (0-1)\n\n\n5\np1b\nError tipo II\n70\n0.31\n0.45\n1 (0-1)\n\n\n6\np1c\nRechazo H0 valor p\n70\n0.81\n0.70\n2 (0-2)\n\n\n7\np2a\nFormulación hipótesis\n70\n1.47\n0.69\n2 (0-2)\n\n\n8\np2b\nContraste de prueba t\n70\n2.59\n1.32\n4 (0-4)\n\n\n9\np2c\nIntervalo confianza de prueba t\n70\n1.26\n0.74\n2 (0-2)\n\n\n3\nnota\nNota final\n70\n4.50\n1.43\n6 (1-7)\n\n\n2\nasistida\nAsistencia Efectiva\n70\n10.16\n1.86\n8 (4-12)\n\n\n1\nasist_total\nAsistencia Registrada\n70\n10.24\n1.81\n8 (4-12)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "href": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "hist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n25\n35.71\n35.71\n35.71\n\n\n\n4.0-5.0\n14\n20.00\n20.00\n55.71\n\n\n\n5.0-6.0\n24\n34.29\n34.29\n90.00\n\n\n\n6.0-7.0\n7\n10.00\n10.00\n100.00\n\n\n\ntotal N=70 · valid N=63 · x̄=2.19 · σ=1.04\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "href": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "tab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nIntervalo de Confianza\nError tipo II\nRechazo H0 valor p\nFormulación hipótesis\nContraste de prueba t\nIntervalo confianza de prueba t\nNota final\nAsistencia Efectiva\nAsistencia Registrada\n\n\nIntervalo de Confianza\n \n \n \n \n \n \n \n \n \n\n\nError tipo II\n0.337**\n \n \n \n \n \n \n \n \n\n\nRechazo H0 valor p\n0.271*\n0.399***\n \n \n \n \n \n \n \n\n\nFormulación hipótesis\n0.180\n0.202\n0.014\n \n \n \n \n \n \n\n\nContraste de prueba t\n0.243*\n0.244*\n0.214\n0.485***\n \n \n \n \n \n\n\nIntervalo confianza de prueba t\n0.275*\n0.280*\n0.405***\n0.281*\n0.590***\n \n \n \n \n\n\nNota final\n0.453***\n0.525***\n0.544***\n0.592***\n0.849***\n0.772***\n \n \n \n\n\nAsistencia Efectiva\n0.278*\n-0.048\n0.117\n0.355**\n0.352**\n0.382**\n0.398***\n \n \n\n\nAsistencia Registrada\n0.316**\n0.006\n0.106\n0.380**\n0.382**\n0.377**\n0.427***\n0.980***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nggplot(prueba1, aes(x = asist_total, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 4) + \n  labs(title = \"Relación entre asistencia y notas en Evaluación 1 (r=0.43)\") + \n  labs(x = \"Asistencia\", y = \"Nota\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(1, 12, by = 1), limits = c(1, 12)) +   # Ajuste del eje de asistencia\n  scale_y_continuous(breaks = seq(1, 7, by = 1), limits = c(1, 7))       # Ajuste del eje de notas de 1 a 7\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(asist_total_cat=cut(asist_total, breaks=c(-Inf,7,8,9,10,11,Inf), labels=c(\"Menos de 8\",\"8\",\"9\",\"10\",\"11\",\"12\")))\n\nfrq(prueba1$asist_total_cat, out=\"browser\", show.na = FALSE, title = \"Asistencia\")\n\n\nAsistencia\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenos de 8\n6\n8.57\n8.57\n8.57\n\n\n\n8\n4\n5.71\n5.71\n14.29\n\n\n\n9\n10\n14.29\n14.29\n28.57\n\n\n\n10\n11\n15.71\n15.71\n44.29\n\n\n\n11\n19\n27.14\n27.14\n71.43\n\n\n\n12\n20\n28.57\n28.57\n100.00\n\n\n\ntotal N=70 · valid N=50 · x̄=4.33 · σ=1.58\n\n\n\n\nprueba1 %&gt;% # se especifica la base de datos\n  dplyr::select(asist_total_cat, nota)  %&gt;% # se seleccionan las variables\n  dplyr::group_by(Asistencia=sjlabelled::as_label(asist_total_cat)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=round(mean(nota),2),SD=round(sd(nota),2)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nAsistencia\nObs.\nPromedio\nSD\n\n\n\n\nMenos de 8\n6\n2.98\n1.63\n\n\n8\n4\n3.40\n0.20\n\n\n9\n10\n4.33\n1.46\n\n\n10\n11\n4.46\n1.56\n\n\n11\n19\n4.62\n1.44\n\n\n12\n20\n5.16\n0.98\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-asist_total_cat)\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 8\nSample units: 70\nalpha: 0.753"
  },
  {
    "objectID": "news/2025-08-04_inicio.html",
    "href": "news/2025-08-04_inicio.html",
    "title": "Informaciones por acá",
    "section": "",
    "text": "← News\n\n\n\n\nEstimad_s estudiantes, acá en esta pestaña quedará registro de las informaciones y actualizaciones del curso. De todas maneras se enviará link por correo a UCursos cuando haya noticias relevantes."
  },
  {
    "objectID": "news/2025-08-19_practicos.html",
    "href": "news/2025-08-19_practicos.html",
    "title": "Inicio practicos",
    "section": "",
    "text": "← News\n\n\n\n\n\nEl día Miércoles 20 de agosto vamos a comenzar con la realización de los talleres prácticos de R.\nLos talleres prácticos consisten en guías de trabajo con énfasis en la aplicación práctica de los contenidos mediante el uso de R.\nLa estructura de la sesión será la siguiente:\n\n8:30 en la sala B1 comenzamos con la revisión del taller práctico correspondiente (30min aprox.)\n9:00 tendremos una sección de trabajo autónomo donde podrán aplicar los contenidos vistos en el taller. Para esto, es necesario que cada estudiante asista con su computador personal:\n\nSi asiste con su propio computador, deben traer instalado R (versión 4.5.1), RStudio (versión 2025.05.1+513) y las librerías pacman, dplyr y Publish.\nSi no pueden asistir con su propio computador, tenemos 30 cupos disponibles en la sala 45 del edificio antiguo de FACSO. Para asistir a esta sala deben inscribirse en el siguiente formulario: https://forms.gle/jsFdiWNkjLmCAP5D6"
  },
  {
    "objectID": "news/2025-10-14_prep_evaluacion2.html",
    "href": "news/2025-10-14_prep_evaluacion2.html",
    "title": "Preparación Evaluación 2",
    "section": "",
    "text": "← News\nMañana miércoles 15 en lugar de clases regulares vamos a realizar una sesión de preparación de la Evaluación 2 (próximo lunes 20). En la sesión de mañana no se tomará asistencia y la actividad será de carácter voluntario para quienes consideren que requieren preparación.\nComo se puede ver en la página del programa del curso, la Evaluación de la Unidad 2 vale un 40% de la nota del curso."
  },
  {
    "objectID": "news/2025-10-14_prep_evaluacion2.html#consideraciones",
    "href": "news/2025-10-14_prep_evaluacion2.html#consideraciones",
    "title": "Preparación Evaluación 2",
    "section": "Consideraciones:",
    "text": "Consideraciones:\n\nLa prueba será frente al computador, para así poder realizar las preguntas de análisis de datos.\nLas preguntas conceptuales también se responderán en el computador\nLas respuestas tanto de análisis como conceptuales se responderán en un formulario habilitado en UCursos"
  },
  {
    "objectID": "news/2025-10-14_prep_evaluacion2.html#cómo-será-la-evaluación",
    "href": "news/2025-10-14_prep_evaluacion2.html#cómo-será-la-evaluación",
    "title": "Preparación Evaluación 2",
    "section": "¿Cómo será la evaluación?",
    "text": "¿Cómo será la evaluación?\n\nHabrá preguntas en tres temas:\n\ncorrelación\nmatrices de correlación y casos perdidos\nasociación en tablas de contingencia\n\nSerán preguntas puntuales de análisis e interpretación, y se calcula que cada pregunta requiere una dedicación de no más de 20 min, por lo que la prueba se puede contestar en aproximadamente una hora. De todas maneras, quienes requieran tiempo adicional, la prueba se podrá entregar hasta las 10:00\nCada tema tiene 4 puntos, 1 punto será por análisis de datos, y 3 por temas conceptuales/interpretación\nSe permitirá acceso a apuntes y a la página del curso online, no se permite el uso de otras plataformas como whatsapp o IA."
  },
  {
    "objectID": "news/2025-10-14_prep_evaluacion2.html#cómo-prepararse",
    "href": "news/2025-10-14_prep_evaluacion2.html#cómo-prepararse",
    "title": "Preparación Evaluación 2",
    "section": "¿Cómo prepararse?",
    "text": "¿Cómo prepararse?\n\nEn los prácticos de la Unidad 2 hay una sección de ejercicio autónomo, el realizar estos ejercicios y luego corregirlos (aparecen también desarrollados en la misma página) es la mejor forma de prepararse, tanto en términos de análisis como de interpretación\nEstán también arriba los videos de los últimos dos prácticos\nRevisar el material de las presentaciones y lecturas sugeridas\nAsistir a la sesión de preparación/ensayo de la prueba miércoles 15 (es voluntario)\nSoftware: revisar que los ejercicios de los prácticos los puedan desarrollar bien en el computador que traerán a la evaluación. Quienes no pueden traer computador podrán realizar la evaluación en la sala de computación."
  },
  {
    "objectID": "resource/glosario.html",
    "href": "resource/glosario.html",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "resource/glosario.html#glosario-de-conceptos",
    "href": "resource/glosario.html#glosario-de-conceptos",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "R, librerías y versiones",
    "section": "",
    "text": "Trabajar con el software de programación R y el entorno de desarrollo integrado (IDE) RStudio requiere, la mayor parte del tiempo, estar al tanto de actualizaciones tanto de R como de las librerías que utilizamos para el procesamiento y análisis de datos.\nR y sus librerías tienen distintas versiones. No estar al tanto de esto puede generar problemas cuando, por ejemplo, queremos correr algún código que encontramos en internet, no podemos ejecutar el código de un colega o cuando queremos utilizar librerías o herramientas nuevas que nos ofrece la comunidad de R.\nPor tanto, cuando estemos desarrollando una evaluación práctica en RStudio es de suma importancia contar con una versión actualizada de R y de las librerías necesarias que se utilizan en las sesiones prácticas del curso.\nEn esta guía de recursos te dejaremos algunas buenas prácticas para conocer:\n\nCon qué versión de R y librerías estoy trabajando\nCómo reportar las versiones que utilizo a otras personas\nActualizar mi versión de R y librerías necesarias para este curso",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#actualizar-r",
    "href": "resource/install.html#actualizar-r",
    "title": "R, librerías y versiones",
    "section": "Actualizar R",
    "text": "Actualizar R\nEl método más eficiente es descargar una nueva versión de R desde sitio web de R &gt; CRAN.\n\n\n\n\n\n\n\n\n\nEl CRAN que utilizamos es el de la Universidad de Chile. Debes descargar e instalar la versión de R correspondiente a tu sistema operativo. Luego, reinicia tu RStudio. La nueva versión de R se cargará automáticamente.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa nueva versión de R aparece justo después de instalar R y reiniciar RStudio.",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#actualizar-librerías",
    "href": "resource/install.html#actualizar-librerías",
    "title": "R, librerías y versiones",
    "section": "Actualizar librerías",
    "text": "Actualizar librerías\nLuego de realizar el paso anterior, para installar y llamar a las librerías que utilizamos en el curso usaremos la función p_load() del paquete pacman. Lo genial de esta función es que instala y llama librerías en un solo movimiento, es decir:\n\nsi incluyo una librería que no tengo instalada previamante, p_load() la instala y llama\nsi incluyo una librería que ya tengo instala previamente, p_load() la reconoce y sólo la llama\n\nEn este curso hemos utilizado diversas librerías y las fundamentales para la evaluación 2 son:\n\ntidyverse\nsjPlot\nsjmisc\nkableExtra\npsych\ncorrplot\nbroom\ncar\n\nAlgunos otros paquetes adicionales muy útiles son:\n\ngginference\nggplot2\nhaven\n\nVeamos cómo instalar estas librerías claves para la evaluación 2 y desarrollo del curso.\n\npacman::p_load(tidyverse, # Manipulacion de datos\n               car, # Recodificar\n               sjPlot, # Tablas y graficos\n               sjmisc, # Descriptivos\n               kableExtra, # Tablas\n               psych, # Bivariados\n               corrplot, # Graficos correlacioj\n               broom) # Varios\n\nComprobemos si se instalaron las librerías y qué versiones con sessionInfo()\n\nutils::sessionInfo()\n\nR version 4.3.2 (2023-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 26100)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=Spanish_Chile.utf8  LC_CTYPE=Spanish_Chile.utf8   \n[3] LC_MONETARY=Spanish_Chile.utf8 LC_NUMERIC=C                  \n[5] LC_TIME=Spanish_Chile.utf8    \n\ntime zone: America/Santiago\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] broom_1.0.5      corrplot_0.92    psych_2.3.9      kableExtra_1.4.0\n [5] sjmisc_2.8.9     sjPlot_2.8.16    car_3.1-2        carData_3.0-5   \n [9] lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n[13] purrr_1.0.2      readr_2.1.4      tidyr_1.3.0      tibble_3.2.1    \n[17] ggplot2_3.5.1    tidyverse_2.0.0  pacman_0.5.1     knitr_1.45      \n\nloaded via a namespace (and not attached):\n [1] sjlabelled_1.2.0   tidyselect_1.2.0   viridisLite_0.4.2  farver_2.1.2      \n [5] fastmap_1.2.0      TH.data_1.1-2      bayestestR_0.16.0  sjstats_0.18.2    \n [9] digest_0.6.33      estimability_1.4.1 timechange_0.2.0   lifecycle_1.0.4   \n[13] survival_3.5-7     magrittr_2.0.3     compiler_4.3.2     rlang_1.1.2       \n[17] tools_4.3.2        yaml_2.3.7         htmlwidgets_1.6.4  mnormt_2.1.1      \n[21] xml2_1.3.5         RColorBrewer_1.1-3 multcomp_1.4-25    abind_1.4-5       \n[25] withr_3.0.2        grid_4.3.2         xtable_1.8-4       emmeans_1.10.6    \n[29] scales_1.4.0       MASS_7.3-60        dichromat_2.0-0.1  insight_1.3.0     \n[33] cli_3.6.1          mvtnorm_1.2-3      rmarkdown_2.28     generics_0.1.3    \n[37] rstudioapi_0.17.1  performance_0.14.0 modelr_0.1.11      tzdb_0.4.0        \n[41] minqa_1.2.6        splines_4.3.2      parallel_4.3.2     vctrs_0.6.4       \n[45] boot_1.3-28.1      Matrix_1.6-3       sandwich_3.1-0     jsonlite_1.8.7    \n[49] hms_1.1.3          systemfonts_1.0.5  glue_1.6.2         nloptr_2.0.3      \n[53] codetools_0.2-19   stringi_1.8.2      gtable_0.3.6       ggeffects_1.3.2   \n[57] lme4_1.1-35.1      pillar_1.11.0      htmltools_0.5.8.1  R6_2.6.1          \n[61] evaluate_1.0.4     lattice_0.21-9     backports_1.4.1    Rcpp_1.0.11       \n[65] svglite_2.1.2      coda_0.19-4        nlme_3.1-163       xfun_0.43         \n[69] zoo_1.8-12         pkgconfig_2.0.3",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#opción-vía-rstudio",
    "href": "resource/install.html#opción-vía-rstudio",
    "title": "R, librerías y versiones",
    "section": "Opción vía Rstudio",
    "text": "Opción vía Rstudio\nSi queremos actualizar una librería en R, lo que podemos hacer es dirigirnos al panel inferior derecho y dar click en la pestaña de “Packages”. Allí, les aparecerá un listado de las librerías que tienen en su computador, una descripción y su versión.\n\n\n\n\n\n\n\n\n\nPara actualizar una librería, podemos seleccionarla y darle click al botón de “Update” y luego “Install Update” a la librería correspondiente. Veamos un ejemplo",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#opción-vía-código",
    "href": "resource/install.html#opción-vía-código",
    "title": "R, librerías y versiones",
    "section": "Opción vía código",
    "text": "Opción vía código\nBien, pero ¿hay otra alternativa? Sí, como todo en R. Una forma sencilla de actualizar una librería o varias es con la función install.packages pero identificando argumentos adicionales. La estructura del código es así: install.packages(\"package_name\", dependencies = TRUE, update = TRUE). Supongamos que queremos actualizar a la versión más de nueva de corrplot:\n\ninstall.packages(\"corrplot\", dependencies = TRUE, update = TRUE)\n\nCon esto, actualizamos manualmente vía código una librería. Para verificarlo podemos, nuevamente, usar sessionInfo() o de las otras maneras que hemos aprendido.",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#recursos-adicionales",
    "href": "resource/install.html#recursos-adicionales",
    "title": "R, librerías y versiones",
    "section": "Recursos adicionales",
    "text": "Recursos adicionales\nPara más informaciones, sobre R y Rstudio, revisar link de práctico de estadística descriptiva –&gt; link",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMiércoles 27\n\nPráctico Inferencia 2\n\n\n\n Septiembre \n\n\n\n\n\nLunes 1\nRepaso Unidad 1\n\n\n\n\nMiércoles 03\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 22\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMiércoles 24\n\nPráctico. Bivariada 1\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n Octubre \n\n\n\n\n\nMiércoles 01\n\nPráctico: Bivariada 2\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 3\n\n\n\nLunes 13\nRepaso Unidad 2\n\n\n\n\nMiércoles 15\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\nLunes 20\nSeminario encuestas\n\n\n\n\nMiércoles 22\n\nDefinición de grupos y temas\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule.html#forma-general-de-funcionamiento",
    "href": "schedule.html#forma-general-de-funcionamiento",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMiércoles 27\n\nPráctico Inferencia 2\n\n\n\n Septiembre \n\n\n\n\n\nLunes 1\nRepaso Unidad 1\n\n\n\n\nMiércoles 03\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 22\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMiércoles 24\n\nPráctico. Bivariada 1\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n Octubre \n\n\n\n\n\nMiércoles 01\n\nPráctico: Bivariada 2\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 3\n\n\n\nLunes 13\nRepaso Unidad 2\n\n\n\n\nMiércoles 15\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\nLunes 20\nSeminario encuestas\n\n\n\n\nMiércoles 22\n\nDefinición de grupos y temas\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule.html#exámenes-finales-orales",
    "href": "schedule.html#exámenes-finales-orales",
    "title": "Planificación",
    "section": "Exámenes finales (orales)",
    "text": "Exámenes finales (orales)\nVer requisitos de aprobación y eximición\n\nExamen de primera oportunidad: Miércoles 11 Diciembre desde las 9:30\nExamen de segunda oportunidad: Lunes 16 Diciembre desde las 10:15"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Prof. Juan Carlos Castillo\n   325 Sociología FACSO, Universidad de Chile\n   juancastillov@uchile.cl\n   Agendar reunión\n\n\n\n\n\n   Lunes y Miércoles\n   04 Agosto al 26 de Noviembre - 2025\n   08:30-10:00 (Lunes) y 8:30-10:00 (Miércoles)\n   Lunes - Aulario C6, Miércoles - Aulario B1 & FACSO 345\n   Slack"
  },
  {
    "objectID": "syllabus.html#sobre-el-sentido-general-del-curso",
    "href": "syllabus.html#sobre-el-sentido-general-del-curso",
    "title": "Programa",
    "section": "Sobre el sentido general del curso",
    "text": "Sobre el sentido general del curso\nEn este curso vamos a aprender tres cosas principales:\n\ninferencia: los resultados que encontramos en nuestra muestra, ¿se encuentran también en la población de la cual proviene la muestra?\nmedidas de asociación entre variables: tamaño y significación estadística\nreporte y reproducibilidad de los análisis estadísticos: nuestros análisis se reflejan en productos como tablas y gráficos. No basta con entenderlos e interpretarlos, sino también es fundamental una buena comunicación."
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico inferencial. Se espera que los estudiantes sean capaces de:\n\nelaborar de manera pertinente hipótesis estadísticas\naplicar estadísticos de asociación bivariada, a partir de los cuáles puedan desarrollar análisis de problemas sociales\ncorroborar el cumplimiento de las condiciones de aplicación de cada estadístico\nutilizar software de análisis estadístico\ncontrastar hipótesis de investigación\nelaborar conclusiones integrando fundamentos teóricos con herramientas de análisis estadístico de resultados.\n\nComplementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias",
    "href": "syllabus.html#competencias",
    "title": "Programa",
    "section": "Competencias",
    "text": "Competencias\n1a. Delimitar, conceptualizar y analizar diversos objetos de investigación social, con especial énfasis en aquellos relacionados con los procesos de transformación del país y Latinoamérica\n1b. Manejar diversas estrategias metodológicas de las ciencias sociales\n1c. Manejar un conjunto de herramientas para el procesamiento y análisis de información\n1d. Transmitir los conocimientos derivados de la práctica investigativa, así como aquellos adquiridos durante el proceso formativo."
  },
  {
    "objectID": "syllabus.html#subcompetencias",
    "href": "syllabus.html#subcompetencias",
    "title": "Programa",
    "section": "Subcompetencias",
    "text": "Subcompetencias\n\n1.4 Contribuir a generar conocimiento sociológico en el marco de estudios y/o procesos de investigación donde se articulen creativamente las dimensiones teórica, metodológica y práctica.\n1.5 Comunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#resultados-del-aprendizaje",
    "href": "syllabus.html#resultados-del-aprendizaje",
    "title": "Programa",
    "section": "Resultados del aprendizaje",
    "text": "Resultados del aprendizaje\n\nComprende, domina y es capaz de explicar los elementos conceptuales subyacentes a la determinación de la asociación poblacional entre dos variables a partir del análisis de una muestra, y es capaz de traducir hipótesis derivadas de la teoría sociológica en hipótesis estadísticas posibles de contrastar empíricamente con los datos.\nEs capaz de seleccionar y usar herramientas estadísticas adecuadas para evaluar la asociación entre dos variables considerando las características de los datos y las condiciones de aplicación de cada técnica.\nLogra interpretar desde un punto de vista estadístico y sociológico los resultados derivados de pruebas estadísticas para analizar la relación entre dos variables.\nEs capaz de reportar y comunicar adecuada y eficientemente los resultados de los análisis estadísticos"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / Contenidos",
    "text": "Saberes / Contenidos\n\nUnidad I: Inferencia\n\nDatos, variables y probabilidad\nCurva normal y error estándar\nIntervalos de confianza\nTest de hipótesis - Pruebas t y Z\nHipótesis no direccionales y para proporciones\n\n\n\nUnidad II: Asociación\n\nAsociación y covarianza\nCorrelación de Pearson\nCorrelación con variables ordinales\nMatrices y tamaños de efecto en correlación\nAsociación con variables categóricas\n\n\n\nUnidad III: Reporte\n\nResponder problemas de investigación de lógica bivariada con datos reales\nEscritura de reportes de investigación\nVisualización de datos\nPresentación de resultados"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\n\nSesiones de clases lectivas presenciales semanales, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana.\nPrácticos: los temas del curso se acompañan de guías prácticas de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma, y también habrá espacio de revisión y consultas en el espacio de clases.\nTrabajos: se desarrollarán trabajos de investigación que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados por ayudantes que se asignarán a cada grupo.\n\nEl semestre comienza con clases lectivas, y posteriormente se integran progresivamente elementos prácticos y de aplicación.\n\nLas clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Clases, y están desarrollados con base en Rmarkdown/Xaringan. Estos documentos no son:\n\n“la clase”\nautoexplicativos (ni aspiran a serlo)\n“el ppt” (ni menos “la ppt”)"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nEl curso tendrá tres instancias de evaluación :\n\nEvaluación 1: Inferencia (30%, teórico)\nEvaluación 2: Asociación (40% = 30% teórico + 10% práctico)\nEvaluación 3: Reporte de aplicación - trabajo grupal (30%= 25% reporte escrito + 5% presentación/cápsula)\n\nLa nota ponderada de las evaluaciones equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\nLas evaluaciones se distribuyen en el semestre de la siguiente manera:\n\n\n\n\n\n\n\nATENCIÓN\n\n\n\nLas fechas de evaluación no se cambian por respeto a la planificación de los tiempos de tod_s quienes participan en el curso y el cumplimiento apropiado de los objetivos de aprendizaje.\n\n\n\n\n\n\n\n\nSobre las pruebas\n\n\n\n\nLas evaluaciones de las unidades 1 y 2 son en la sala de clases y se realizan de manera individual.\nHay preguntas sobre conceptos, y principalmente cálculos e interpretación\nEntra toda la materia de la unidad, lo visto en clase y los textos obligatorios.\nTodo lo que se requiere para realizar los ejercicios de la prueba está en la prueba, no requiere aprenderse las fórmulas de memoria ni tampoco valores específicos (ej: valores críticos de rechazo)\nLa prueba comenzará puntual, no se puede ingresar ni salir de la sala una vez comenzada la evaluación.\nSi alguien tiene alguna emergencia y necesita salir podrá contar con la compañía y apoyo de algun_ de l_s ayudantes en sala."
  },
  {
    "objectID": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "href": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "title": "Programa",
    "section": "Inasistencias y atraso en entregas",
    "text": "Inasistencias y atraso en entregas\nLos justificativos por ausencia o atraso se realizan en la secretaría de carrera. Lo que la carrera informe como justificado, es lo que se va a considerar en el curso. No enviar justificativos a equipo docente y a ayudantes directamente, no es necesario ni apropiado para l_s estudiantes tener que exponer situaciones personales.\nEn caso de faltar a alguna de las evaluaciones existirá una única fecha para evaluaciones recuperativas. Si en esa fecha no es posible asistir por motivos justificados, entonces pasará directo a examen.\nEn el caso de los trabajos, en caso de atraso se descontará 0.5 por día adicional. Si el trabajo no se entrega luego del tercer día de atraso será calificado con nota 1.0"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\nRequisitos de eximición a examen:\n\ncontar con un promedio ponderado igual o superior a 5.5\nno tener nota bajo 4.0 en ninguna de las evaluaciones\n\nRequisitos para presentación a examen:\n\nPodrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\nEl examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0."
  },
  {
    "objectID": "syllabus.html#sobre-asistencia-participación-y-comunicación",
    "href": "syllabus.html#sobre-asistencia-participación-y-comunicación",
    "title": "Programa",
    "section": "Sobre asistencia, participación y comunicación",
    "text": "Sobre asistencia, participación y comunicación\n\nAsistencia mínima: 75%, se controlará a la entrada de la clase con código QR (8:30 - tope 8:45). Si no se cumple con asistencia, se pasa directo a examen de primera oportunidad.\nInformar flexibilidades académicas al principio del semestre (en caso que la jefatura de carrera no lo haga de manera centralizada). Las flexibilidades académicas no aplican para cambios de fechas de evaluaciones grupales.\nSe espera y enfatiza la participación activa por distintos canales disponibles. Estos son:\n\ncontacto por correo con equipo docente del curso (profesor y apoyos docentes)\nespacio para resolver dudas individualmente al final de la clase\nreuniones con equipo docente, para lo cual se deben inscribir previamente en la página inicial de este sitio\nforos, disponibles tanto para las clases como para los prácticos.\nmentorías con ayudantes asignados\n\nTambién se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”, que si bien puede intentar transmitir cercanía finalmente expresan un trato paternalista y peyorativo de la contraparte. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo están siendo, se solicita reportar para solucionar la situación.\nNo se responderán mensajes fuera del horario laboral (incluyendo por supuesto fines de semana)."
  },
  {
    "objectID": "syllabus.html#bibliografía-obligatoria",
    "href": "syllabus.html#bibliografía-obligatoria",
    "title": "Programa",
    "section": "Bibliografía Obligatoria",
    "text": "Bibliografía Obligatoria\nCapítulos correspondientes a cada sesión de los siguientes textos principales:\n\nRitchey, F. (2008) Estadística para las ciencias sociales. McGraw-Hill: México.\nMoore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch.\nPardo, Ruiz y San Martín (2015). Análisis de Datos en Ciencias Sociales y de la Salud I. Editorial Síntesis: Madrid."
  },
  {
    "objectID": "syllabus.html#bibliografía-complementaria",
    "href": "syllabus.html#bibliografía-complementaria",
    "title": "Programa",
    "section": "Bibliografía Complementaria",
    "text": "Bibliografía Complementaria\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly.\nField, A., Milles, J., & Field, Z. (2012). Discovering statistics using R. London: Sage.\nSalkind, N. J. (Ed.). (2010). Encyclopedia of research design (Vol. 1). Sage.\nLevin, J. & Levin, W. (1997). Fundamentos de Estadística en la Investigación Social (Vol.2). Oxford University Press."
  },
  {
    "objectID": "syllabus.html#programación-de-sesiones",
    "href": "syllabus.html#programación-de-sesiones",
    "title": "Programa",
    "section": "Programación de sesiones",
    "text": "Programación de sesiones\nVisitar la página de Planificación."
  },
  {
    "objectID": "news/2025-10-21_info_evaluacion2.html",
    "href": "news/2025-10-21_info_evaluacion2.html",
    "title": "Informaciones Evaluación 2",
    "section": "",
    "text": "← News\nMañana miércoles 22 tendremos la segunda prueba del curso, al respecto, algunas informaciones relevantes:"
  },
  {
    "objectID": "news/2025-10-21_info_evaluacion2.html#consideraciones",
    "href": "news/2025-10-21_info_evaluacion2.html#consideraciones",
    "title": "Informaciones Evaluación 2",
    "section": "Consideraciones:",
    "text": "Consideraciones:\n\nComo se puede ver en la página del programa del curso, la Evaluación de la Unidad 2 vale un 40% de la nota del curso.\nLa prueba combina aspectos prácticos de análisis en R y también interpretación de resultados.\nLa prueba será frente al computador vía test de u-cursos, para así poder realizar las preguntas de análisis de datos.\nLas preguntas conceptuales también se responderán en el computador.\nRecomendamos que cada estudiante asista con su propio computador, ya que esto permite una mayor personalización y familiarización con sus espacios de trabajo. Sobre todo, en lo que respecta a la configuración de RStudio y la carga de paquetes en R.\nSi no puede asistir con su propio computador, debe inscribirse en el siguiente enlace (cupos limitados): https://forms.gle/tvwmrc4CRvMhPrV76 este formulario estará habilitado hasta hoy a las 17:00 ya que eventualmente necesitaremos reservar una segunda sala"
  },
  {
    "objectID": "news/2025-10-21_info_evaluacion2.html#recomendaciones",
    "href": "news/2025-10-21_info_evaluacion2.html#recomendaciones",
    "title": "Informaciones Evaluación 2",
    "section": "Recomendaciones",
    "text": "Recomendaciones\n\nRecomendamos llegar unos minutos antes del inicio de la prueba (8:30) para prender su computador, abrir Rstudio, u-cursos, etc. y así aprovechar al máximo el tiempo disponible para la prueba.\nSe sugiere responder las preguntas de la prueba en un archivo de código de R, y al final cortar y pegar las respuestas en este mismo formulario.\nSe sugiere guardar sus respuestas en un documento aparte para tenerlo como respaldo."
  },
  {
    "objectID": "news/2025-10-21_info_evaluacion2.html#cómo-será-la-evaluación",
    "href": "news/2025-10-21_info_evaluacion2.html#cómo-será-la-evaluación",
    "title": "Informaciones Evaluación 2",
    "section": "¿Cómo será la evaluación?",
    "text": "¿Cómo será la evaluación?\n\nHabrá preguntas en tres temas:\n\ncorrelación\nmatrices de correlación y casos perdidos\nasociación en tablas de contingencia\n\nSerán preguntas puntuales de análisis e interpretación, y se calcula que cada pregunta requiere una dedicación de no más de 20 min, por lo que la prueba se puede contestar en aproximadamente una hora. De todas maneras, quienes requieran tiempo adicional, la prueba se podrá entregar hasta las 10:00.\nRecuerde que la prueba se cerrará automáticamente a las 10:00 y no se podrá agregar información adicional.\nCada tema tiene 4 puntos, 1 punto será por análisis de datos, y 3 por temas conceptuales/interpretación.\nPueden utilizar apuntes de clases, los recursos de la página del curso o cualquier otro material que estimen conveniente. No se pueden utilizar plataformas de comunicación (WhatsApp, redes sociales, Telegram, etc.) ni inteligencia artificial (ChatGPT, Gemini AI, etc.)."
  },
  {
    "objectID": "news/2025-10-21_info_evaluacion2.html#cómo-prepararse",
    "href": "news/2025-10-21_info_evaluacion2.html#cómo-prepararse",
    "title": "Informaciones Evaluación 2",
    "section": "¿Cómo prepararse?",
    "text": "¿Cómo prepararse?\n\nEn los prácticos de la Unidad 2 hay una sección de ejercicio autónomo, el realizar estos ejercicios y luego corregirlos (aparecen también desarrollados en la misma página) es la mejor forma de prepararse, tanto en términos de análisis como de interpretación\nEstán también arriba los videos de los últimos dos prácticos realizados durante la reciente movilización y también la resolución del ejercicio autónomo del práctico de resumen realizado el lunes 20 de octubre.\nRevisar el material de las presentaciones y lecturas sugeridas\nSoftware: revisar que los ejercicios de los prácticos los puedan desarrollar bien en el computador que traerán a la evaluación. Quienes no pueden traer computador podrán realizar la evaluación en la sala de computación."
  }
]