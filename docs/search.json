[
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados. Estas instancias serán conducidas guiadas por los apoyos docentes del curso.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentras a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 12\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nMartes 13\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 19\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMartes 20\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 26\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMartes 27\n\nPráctico: Inferencia 1\n\n\n\n Septiembre \n\n\n\n\n\nLunes 2\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMartes 3\n\nPráctico Inferencia 2\n\n\n\nLunes 9\nRepaso Unidad 1\n\n\n\n\nMartes 10\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 23\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMartes 24\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 30\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMartes 1\n\nPráctico. Bivariada 1\n\n\n\nLunes 7\nAsociación con categóricas 1\n\n\n\n\nMartes 8\n\nPráctico: Bivariada 2\n\n\n\nLunes 14\nAsociación con categóricas 2\n\n\n\n\nMartes 15\n\nPráctico: Bivariada 3\n\n\n\nLunes 21\nRepaso Unidad 2\n\n\n\n\nMartes 22\nEvaluación 2\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMartes 29\nSemana receso\n\n\n\n\n\n\n\n\n\n\nLunes 4\nSeminario encuestas\n\n\n\n\nMartes 5\n\nDefinición de grupos y temas\n\n\n\nLunes 11\nEscritura y reportes dinámicos\n\n\n\n\nMartes 12\n\nVisualización1: tablas\n\n\n\nLunes 18\nVisualización 2: Gráficos / Poster\n\n\n\n\nMartes 19\n\nAsesoría final grupos\n\n\n\nLunes 25\nPresentación de poster de investigación\n\n\n\n\nMartes 26\nPruebas recuperativas\n\n\n\n\nViernes 29\nEntrega de trabajo final grupal"
  },
  {
    "objectID": "schedule.html#forma-general-de-funcionamiento",
    "href": "schedule.html#forma-general-de-funcionamiento",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados. Estas instancias serán conducidas guiadas por los apoyos docentes del curso.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentras a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 12\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nMartes 13\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 19\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMartes 20\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 26\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMartes 27\n\nPráctico: Inferencia 1\n\n\n\n Septiembre \n\n\n\n\n\nLunes 2\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMartes 3\n\nPráctico Inferencia 2\n\n\n\nLunes 9\nRepaso Unidad 1\n\n\n\n\nMartes 10\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 23\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMartes 24\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 30\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMartes 1\n\nPráctico. Bivariada 1\n\n\n\nLunes 7\nAsociación con categóricas 1\n\n\n\n\nMartes 8\n\nPráctico: Bivariada 2\n\n\n\nLunes 14\nAsociación con categóricas 2\n\n\n\n\nMartes 15\n\nPráctico: Bivariada 3\n\n\n\nLunes 21\nRepaso Unidad 2\n\n\n\n\nMartes 22\nEvaluación 2\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMartes 29\nSemana receso\n\n\n\n\n\n\n\n\n\n\nLunes 4\nSeminario encuestas\n\n\n\n\nMartes 5\n\nDefinición de grupos y temas\n\n\n\nLunes 11\nEscritura y reportes dinámicos\n\n\n\n\nMartes 12\n\nVisualización1: tablas\n\n\n\nLunes 18\nVisualización 2: Gráficos / Poster\n\n\n\n\nMartes 19\n\nAsesoría final grupos\n\n\n\nLunes 25\nPresentación de poster de investigación\n\n\n\n\nMartes 26\nPruebas recuperativas\n\n\n\n\nViernes 29\nEntrega de trabajo final grupal"
  },
  {
    "objectID": "schedule.html#exámenes-finales-escritos-en-sala",
    "href": "schedule.html#exámenes-finales-escritos-en-sala",
    "title": "Planificación",
    "section": "Exámenes finales (escritos, en sala)",
    "text": "Exámenes finales (escritos, en sala)\nVer requisitos de aprobación y eximición\n\nExamen de primera oportunidad: Lunes 9 Diciembre 10:15\nExamen de segunda oportunidad: Lunes 16 Diciembre 10:15"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "",
    "text": "Inferencia, asociación y reporte\n        \n        \n            SOC01019 • Segundo Semestre 2024Departamento de Sociología, Facultad de Ciencias SocialesUniversidad de Chile"
  },
  {
    "objectID": "index.html#últimas-informaciones",
    "href": "index.html#últimas-informaciones",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Últimas informaciones",
    "text": "Últimas informaciones\n\n\n\n\n\n\n\n\n\n\nTrabajo final\n\n\n\n\n\n\n\n\n\nNov 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVideos Tutoriales\n\n\n\n\n\n\n\n\n\nOct 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nInformaciones evaluación 2\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTaller Centro Idea 2\n\n\n\n\n\n\n\n\n\nOct 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuevo sistema de asesorías grupales\n\n\n\n\n\n\n\n\n\nOct 10, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesarrollo Ejercicio autónomo Práctico 3\n\n\n\n\n\n\n\n\n\nOct 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nReporte Evaluación 1\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTaller Centro IDEA\n\n\n\n\n\n\n\n\n\nSep 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCambios en evaluación 1\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEquipo docente y ayudantes\n\n\n\n\n\n\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsignación asesorías ayudantes\n\n\n\n\n\n\n\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión práctica martes 27 de agosto\n\n\n\n\n\n\n\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrácticos parten próxima semana (Martes 27)\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformaciones por acá\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n-&gt; ir a la página de Informaciones del sitio."
  },
  {
    "objectID": "index.html#versiones-previas-del-curso",
    "href": "index.html#versiones-previas-del-curso",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Versiones previas del curso:",
    "text": "Versiones previas del curso:\n\n2023"
  },
  {
    "objectID": "assignment/04-practico.html",
    "href": "assignment/04-practico.html",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer maneras de reportar coeficientes de correlación y otras medidas de correlación para variables ordinales. Además, nos introduciremos en el tratamiento de valores perdidos y generación de índices. Todo ello a partir de una pregunta de investigación empírica.\nEn detalle, aprenderemos a:\n\nEstimar e interpretar coeficientes de correlación de Spearman y Kendall\nGenerar y reportar matrices de correlación\nTratamiento de casos perdidos\nAnalizar baterías de indicadores y generar índices\n\nEn esta guía utilizaremos un ejemplo que desarrollaremos progresivamente para exponer los contenidos. Al final de esta guía se proporciona un ejercicio autónomo que deberá resolver de manera individual o grupal tomando como referencia el ejemplo aquí expuesto.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#recursos-de-la-práctica",
    "href": "assignment/04-practico.html#recursos-de-la-práctica",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuesta del Módulo de Desigualdad Social de la International Social Survey Programme (ISSP) para Chile del año 2009. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ISSP Chile 2009. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ISSP 2009 para Chile.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "href": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.1 Correlación para variables ordinales",
    "text": "3.1 Correlación para variables ordinales\n\n3.1.1 Coeficiente de correlación de Spearman\nCuando queremos conocer la asociación entre variables que son ordinales y/o cuando nuestras variables no cumplen con los supuestos de distribución normal, podemos utilizar la correlación de Spearman.\n\nEmplea rangos en lugar de valores numéricos para evaluar la relación.\nEs alta cuando las observaciones tienen un ranking similar.\n\nEn R calcularlo es sencillo, pero debemos tener en cuenta que las variables que relacionemos tengan un orden de rango similar: por ejemplo, que el valor más bajo sea el rango más bajo y que el valor más alto sea el rango más alto.\nObservemos las frecuencias de las variables conflict_rp (conflictos ricos-pobres) y perc_ineq (percepción desigualdad)\n\nsjmisc::frq(proc_issp$conflict_rp)\n\nConflictos: ricos - pobres (x) &lt;numeric&gt; \n# total N=1505 valid N=1438 mean=2.61 sd=0.87\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 161 | 10.70 |   11.20 |  11.20\n    2 | 442 | 29.37 |   30.74 |  41.93\n    3 | 627 | 41.66 |   43.60 |  85.54\n    4 | 208 | 13.82 |   14.46 | 100.00\n &lt;NA&gt; |  67 |  4.45 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_issp$perc_ineq)\n\nPercepción desigualdad (x) &lt;numeric&gt; \n# total N=1505 valid N=1492 mean=4.19 sd=0.83\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  16 |  1.06 |    1.07 |   1.07\n    2 |  65 |  4.32 |    4.36 |   5.43\n    3 | 105 |  6.98 |    7.04 |  12.47\n    4 | 742 | 49.30 |   49.73 |  62.20\n    5 | 564 | 37.48 |   37.80 | 100.00\n &lt;NA&gt; |  13 |  0.86 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nAhora, calculemos el coeficiente de correlación de Spearman con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"spearman\") #especificamos metodo spearman\n\n\n    Spearman's rank correlation rho\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nS = 430911455, p-value = 0.000008055\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1176912 \n\n\nAhora conocemos el valor del coeficiente de Spearman mediante al argumento rho, que es igual a 0.12, siendo positivo y pequeño según los criterios de Cohen (1988).\n\n\n3.1.2 Coeficiente de correlación Tau de Kendall\nRecomendado cuando hay un set de datos pequeños y/o cuando hay mucha repetición de observaciones en el mismo ranking. Se basa en una comparación de pares de observaciones concordantes y discordantes.\nAhora, calculemos el coeficiente de correlación Tau de Kendall con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"kendall\") #especificamos metodo kendall\n\n\n    Kendall's rank correlation tau\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nz = 4.4558, p-value = 0.000008358\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.1043735 \n\n\nEl valor del coeficiente de Kendall mediante al argumento tau, es igual a 0.1, siendo positivo y muy pequeño según los criterios de Cohen (1988).\n¿PERO QUÉ HACER CON LOS CASOS PÉRDIDOS?",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "href": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.2 Tratamiento de casos perdidos",
    "text": "3.2 Tratamiento de casos perdidos\nTrabajar con datos a menudo implica enfrentar valores perdidos (NA), lo que puede ser un gran desafío. Estos valores indican la ausencia de un valor en una base de datos. Los valores perdidos pueden originarse por diversas razones, como el sesgo de no respuesta en encuestas, errores en la entrada de datos o simplemente la falta de información para ciertas variables.\n\n\n\n\n\n\nX1\nX2\nX3\nX4\n\n\n\n\nNA\n4\n1\nHola\n\n\n7\n1\n4\nNo soy un NA\n\n\n8\nNA\n2\nNA\n\n\n9\nNA\n9\nAmo R\n\n\n3\n3\n6\nNA\n\n\n\n\n\n\n\n\nLa presencia de valores perdidos puede tener un impacto considerable en la precisión y confiabilidad de los análisis estadísticos, lo que a su vez puede conducir a resultados sesgados y conclusiones incorrectas.\nExisten varias formas de tratar valores perdidos, que van desde enfoques simples hasta métodos más complejos, como la imputación. En esta ocasión, nos centraremos en las dos estrategias más comunes:\n\ntrabajar exclusivamente con casos completos (listwise) o\nretener los casos con valores perdidos, pero excluyéndolos al calcular estadísticas (pairwise).\n\n\n3.2.1 Analísis con casos completos: listwise deletion\nEste enfoque es uno de los más conocidos: implica remover completamente las observaciones que tienen valores perdidos en cualquier variable de interés. En otras palabras, si una fila/caso en un conjunto de datos tiene al menos un valor faltante en alguna de las variables que estás considerando, se eliminará por completo.\nEn R, esto podemos hacerlo con la función na.omit. Para hacer esto, sigamos estos pasos:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos)\ncontamos el número de casos con el comando dim.\ncontamos cuántos y en dónde tenemos casos perdidos.\nborramos los casos perdidos con na.omit.\ncontamos nuevamente con dim para asegurarnos que se borraron.\n\n\nproc_issp_original &lt;- proc_issp\ndim(proc_issp)\n\n[1] 1505    7\n\n\n\nsum(is.na(proc_issp))\n\n[1] 730\n\n\n\ncolSums(is.na(proc_issp))\n\n      educyrs        income     perc_ineq   conflict_rp conflict_wcmc \n           54           359            13            67            79 \n  conflict_mw   conflict_tb \n           78            80 \n\n\n\nproc_issp &lt;- na.omit(proc_issp)\ndim(proc_issp)\n\n[1] 1025    7\n\n\nAhora nos quedamos con 1021 observaciones sin casos perdidos.\nAunque simple de implementar, con este enfoque podemos perder información importante, especialmente si los valores perdidos no se distribuyen aleatoriamente.\n\nSiempre hay que intentar rescatar la mayor cantidad de casos posibles. Por lo tanto, si un listwise genera más de un 10% de casos perdidos se debe detectar qué variables esta produciendo esta pérdida e intentar recuperar datos. Puedes revisar un ejemplo aquí.\n\n\n\n3.2.2 Retener pero excluir: pairwise deletion\nA diferencia del anterior, este es un enfoque en el que las observaciones se utilizan para el análisis siempre que tengan datos disponibles para las variables específicas que se están analizando. En lugar de eliminar toda una fila si falta un valor, se eliminan solo los valores faltantes en las variables que se están analizando en ese momento.\nPara hacer esto en R debemos siempre verificar e indicar en nuestro código si queremos (o no) remover los NA para realizar los análisis.\n\nmean(proc_issp_original$conflict_rp); mean(proc_issp_original$perc_ineq)\n\n[1] NA\n\n\n[1] NA\n\nmean(proc_issp_original$conflict_rp, na.rm = TRUE); mean(proc_issp_original$perc_ineq, na.rm = TRUE)\n\n[1] 2.613352\n\n\n[1] 4.188338\n\n\nCon el primer código no obtuvimos información sustantiva en ciertas variables, pero con el segundo sí al remover los NA solo de dicha variable para un cálculo determinado.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#matrices-de-correlación",
    "href": "assignment/04-practico.html#matrices-de-correlación",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.3 Matrices de correlación",
    "text": "3.3 Matrices de correlación\nLa correlación es una estimación de asociación de dos variables. Sin embargo, en los análisis de bases de datos usualmente se exploran asociaciones entre múltiples pares de variables, lo que genera una matriz de correlación. En una matriz, las variables se presentan en las filas y las columnas, y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a la base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\n\nM &lt;- cor(proc_issp_original, use = \"complete.obs\") \nM\n\n                   educyrs       income   perc_ineq conflict_rp conflict_wcmc\neducyrs        1.000000000  0.432514770  0.05504904 -0.08841474   -0.13352776\nincome         0.432514770  1.000000000  0.05477385 -0.06418553   -0.12973731\nperc_ineq      0.055049043  0.054773853  1.00000000  0.06824227   -0.02485978\nconflict_rp   -0.088414736 -0.064185525  0.06824227  1.00000000    0.50032361\nconflict_wcmc -0.133527759 -0.129737308 -0.02485978  0.50032361    1.00000000\nconflict_mw   -0.002602596 -0.009135604  0.09567990  0.49448964    0.44732312\nconflict_tb   -0.021292335 -0.008221726  0.09164984  0.66745078    0.41433338\n               conflict_mw  conflict_tb\neducyrs       -0.002602596 -0.021292335\nincome        -0.009135604 -0.008221726\nperc_ineq      0.095679896  0.091649843\nconflict_rp    0.494489639  0.667450775\nconflict_wcmc  0.447323122  0.414333385\nconflict_mw    1.000000000  0.524006738\nconflict_tb    0.524006738  1.000000000\n\n\nEste es el reporte simple, pero no muy amigable a la vista. Para una versión más reportable, utilizamos la funcion tab_corr.\n\nsjPlot::tab_corr(proc_issp_original, \n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nNivel educativo\nDecil ingreso\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nNivel educativo\n \n \n \n \n \n \n \n\n\nDecil ingreso\n0.433***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n0.055\n0.055\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.088**\n-0.064*\n0.068*\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n-0.134***\n-0.130***\n-0.025\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.003\n-0.009\n0.096**\n0.494***\n0.447***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.021\n-0.008\n0.092**\n0.667***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLa distinción entre listwise y pairwise es relevante al momento de estimar matricies de correlación, donde esta decisión debe estar claramente explicitada y fundamentada. En ejemplo de tabla anterior usamos listwise que es el argumento por defecto (y nos lo indica al final de la tabla).\nVeamos como hacerlo con pairwise:\n\nsjPlot::tab_corr(proc_issp_original, \n                 na.deletion = \"pairwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nNivel educativo\nDecil ingreso\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nNivel educativo\n \n \n \n \n \n \n \n\n\nDecil ingreso\n0.429***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n0.057*\n0.041\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.068*\n-0.057\n0.087***\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n-0.139***\n-0.122***\n-0.025\n0.518***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.016\n-0.005\n0.100***\n0.499***\n0.438***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.037\n0.007\n0.089***\n0.651***\n0.441***\n0.527***\n \n\n\nComputed correlation used pearson-method with pairwise-deletion.\n\n\n\n\n\nCon esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n\nEn esta matriz las variables están representadas en las filas y en las columnas.\nCada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de educyrs y income es 0.43.\nLa información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno. Por convención en general se omiten las correlaciones redundantes sobre la diagonal, por eso aparece en blanco.\nEn la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva.\n\nOtra manera de presentar matrices de correlación es mediante gráficos. Veamos un ejemplo con la función corrplot de la librería corrplot sobre nuestra matriz M ya creada.\n\ndiag(M) &lt;- NA\ncorrplot::corrplot(M,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"#0D0887\"))(12),\n                   bg = \"white\",\n                   na.label = \"-\")",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#baterías-e-índices",
    "href": "assignment/04-practico.html#baterías-e-índices",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.4 Baterías e índices",
    "text": "3.4 Baterías e índices\nEn la literatura sobre percepción de conflictos se suele utilizar un índice sumativo o promedio entre los distintos indicadores sobre conflictos percibidos: conflict_rp,conflict_wcmc,conflict_mw,conflict_tb.\nEntonces, para poder responder nuestras preguntas de investigación, primero generaremos una matriz de correlaciones entre estos indicadores, luego evaluaremos su consistencia y generaremos el índice psci. Finalmente, realizaremos un test de correlación para examinar la asociación entre psci y perc_ineq.\n\nM_psci &lt;- proc_issp %&gt;% \n  dplyr::select(starts_with(\"conflict\"))\n\nsjPlot::tab_corr(M_psci, \n                 na.deletion = \"listwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n \nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nConflictos: ricos - pobres\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n0.494***\n0.447***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n0.667***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLos ítems se correlacionan de manera positiva y con tamaños de efecto moderados y altos para las ciencias sociales. Con ello, podemos pasar a evaluar sus relaciones tienen consistencia interna.\n\nalpha_psci &lt;- psych::alpha(M_psci)\nalpha_psci$total$raw_alpha\n\n[1] 0.8044404\n\n\nDe acuerdo con este resultado, el alpha de Cronbach reflejado en el raw_alpha del output es superior al estandar de 0.6 en ciencias sociales, por lo que se sostiene su consistencia.\nAhora, generemos el índice psci\n\nproc_issp &lt;- cbind(proc_issp, \"psci\" = rowMeans(proc_issp %&gt;% select(starts_with(\"conflict\")), na.rm=TRUE))\n\nsjmisc::descr(proc_issp$psci, show = c(\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\")) %&gt;%\n  kable(.,\"markdown\")\n\n\n\n\nvar\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\ndd\n1025\n0\n2.585122\n0.6986039\n3 (1-4)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/02-practico.html",
    "href": "assignment/02-practico.html",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "El objetivo de esta guía práctica es realizar una serie de ejercicios de inferencia estadística, tomando como base todos los contenidos de la Unidad 1. En particular, se abordan pruebas de hipótesis para diferencias de medias y direccionales utilizando la prueba t\nLa guía tiene 3 ejercicios. El primero de ellos es un ejemplo, y los ejercicios 2 y 3 se desarrollan de manera autónoma en la sala (también puede ser en grupo).\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.\n\n\n\n\nEn inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#recursos-de-la-práctica",
    "href": "assignment/02-practico.html#recursos-de-la-práctica",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "href": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#formulación-de-hipótesis",
    "href": "assignment/02-practico.html#formulación-de-hipótesis",
    "title": "Práctico 2: Intentando rechazar",
    "section": "1. Formulación de hipótesis",
    "text": "1. Formulación de hipótesis\nEl primer paso es traducir nuestra pregunta a una hipótesis estadística contrastable. Para ello: a) elija el tipo de hipótesis a plantear ¿direccional o no direccional? y b) especifique la hipótesis nula (\\(H_0\\)) e hipótesis alternativa (\\(H_A\\)).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "href": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "title": "Práctico 2: Intentando rechazar",
    "section": "Pasos 2, 3 y 4 de una vez con R",
    "text": "Pasos 2, 3 y 4 de una vez con R\nSiguiendo el ejemplo del Ejercicio 1, utilice el software para generar los estadísticos correspondientes. Contraste sus hipótesis considerando un 95% de confianza y un 99% de confianza. Comente las diferencias en el paso 5.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "resource/glosario.html",
    "href": "resource/glosario.html",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "resource/glosario.html#glosario-de-conceptos",
    "href": "resource/glosario.html#glosario-de-conceptos",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Documentos dinámicos",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Documentos dinámicos"
    ]
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Asociación con categóricas 1",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 4"
    ]
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Inferencia en correlación y magnitud del coeficiente",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 2"
    ]
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Ordinales y matrices",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 3"
    ]
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Asociación con categóricas 2: Chi 2",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 5"
    ]
  },
  {
    "objectID": "evaluations/index.html",
    "href": "evaluations/index.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "evaluations/index.html#descripción",
    "href": "evaluations/index.html#descripción",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "resource/varios.html",
    "href": "resource/varios.html",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#reporte",
    "href": "resource/varios.html#reporte",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#estadística-descriptiva",
    "href": "resource/varios.html#estadística-descriptiva",
    "title": "Varios",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#uso-de-r",
    "href": "resource/varios.html#uso-de-r",
    "title": "Varios",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#inferencia",
    "href": "resource/varios.html#inferencia",
    "title": "Varios",
    "section": "Inferencia",
    "text": "Inferencia\n\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#visualización",
    "href": "resource/varios.html#visualización",
    "title": "Varios",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#bases-de-datos",
    "href": "resource/varios.html#bases-de-datos",
    "title": "Varios",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "evaluations/prueba2.html",
    "href": "evaluations/prueba2.html",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "",
    "text": "Usted es parte de un equipo de investigación en un centro de estudios que se encuentra analizando cómo ciertos factores sociales se asocian con actitudes políticas. El centro realizó una encuesta y cuenta con una base de datos con las siguientes variables:\nLa base de datos se encuentra aquí: link"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "href": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?",
    "text": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?\n1.1 Estime la asociación entre ambas variables utilizando R y genere un diagrama de dispersión (nube de puntos/scatterplot). Corte y pegue el código en el recuadro de abajo. (1p)\n1.2 Interprete el coeficiente de correlación (considerando inferencia estadística, magnitud y sentido del efecto). (3p)"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?",
    "text": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?\n2.1 Estime y reporte la matriz de correlaciones de las variables de nivel educacional, autoritarismo y los ingresos. (1p)\n2.2 Tomando en cuenta la Tabla 1 comente sobre el tratamiento de casos perdidos en el cálculo de las correlaciones, así como también del tipo de correlación calculada entre ingresos y educación. (3p)\n\n\n\n\nTabla 1: Distribución de casos perdidos por variable\n\n\n\n\n\n\n\nVariable\nEtiqueta\nn casos perdidos\n% casos perdidos\n\n\n\n\neduc_rec\nNivel educacional\n0\n0%\n\n\ningresos\nIngresos\n150\n15%\n\n\nautoritarismo\nAutoritarismo\n10\n1%"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?",
    "text": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?\nUtilizando la versión categórica de ingresos:\n3.1 Reporte tabla de contigencia y el calculo de Chi2 (corte y pegue el código). (1p)\n3.2 Interprete el Chi2 en términos de inferencia y magnitud del efecto. (3p)"
  },
  {
    "objectID": "assignment/01-practico.html",
    "href": "assignment/01-practico.html",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en la inferencia estadística, revisando los conceptos y aplicaciones de la curva normal y las probabilidades bajo esta con puntajes Z, además del cálculo de intervalos de confianza.\nEn detalle, aprenderemos y recordaremos:\n\nLos conceptos de promedio y desviación estándar\nQué es la probabilidad y su aplicación para estadística\nQué es la distribución normal\nCómo calcular e interpretar intervalos de confianza\n\n\n\nCargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\nlibrary(pacman)\npacman::p_load(tidyverse, # para sintaxis\n               ggplot2,   # para gráficos\n               car,       # para recodificar\n               psych,     # para analizar datos\n               sjmisc,    # para analizar datos\n               srvyr,     # para estimación de IC y ponderadores\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpar el entonrno de trabajo",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#librerías",
    "href": "assignment/01-practico.html#librerías",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "Cargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\nlibrary(pacman)\npacman::p_load(tidyverse, # para sintaxis\n               ggplot2,   # para gráficos\n               car,       # para recodificar\n               psych,     # para analizar datos\n               sjmisc,    # para analizar datos\n               srvyr,     # para estimación de IC y ponderadores\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpar el entonrno de trabajo",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#curvas-de-distribución",
    "href": "assignment/01-practico.html#curvas-de-distribución",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Curvas de distribución",
    "text": "3.1. Curvas de distribución\nPor distribución nos referimos al conjunto de todos los valores posibles de una variable y las frecuencias (o probabilidades) con las que se producen.\nExisten distribuciones empíricas y distribuciones teóricas, en donde:\n\nlas primeras reflejan la distribución de los valores que asume la variable en un grupo concreto a partir de una observación.\nlas segundas son una función matématica que expresan la distribución de un conjunto de números mediante su probabilidad de ocurencia.\n\nEstas últimas son también llamadas curvas de distribución.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-1",
    "href": "assignment/01-practico.html#distribución-normal-1",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.2. Distribución Normal",
    "text": "3.2. Distribución Normal\nEs una distribución teórica que corresponde a una curva que representa la distribución de los casos de la población en torno al promedio y con una varianza conocida.\n\nSimétricas y con un solo punto de elevación\nLa pendiente es más fuerte cerca del centro, y se suaviza hacia los extremos\nCoinciden al centro el promedio, la mediana y la moda\nLa desviación estandar expresa su dispersión.\nEstablece áreas o proporciones bajo la curva en base a desviaciones estándar del promedio.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-estándar",
    "href": "assignment/01-practico.html#distribución-normal-estándar",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.3. Distribución Normal Estándar",
    "text": "3.3. Distribución Normal Estándar\nLa distribución normal estándar es una distribución normal con una media de 0 y una desviación estándar de 1.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "href": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.4. Puntaje Z y estandarización de variables",
    "text": "3.4. Puntaje Z y estandarización de variables\nAl estandarizar las variables (como en la Curva Normal Estándar) lo que hacemos es expresar el valor de una distribución en términos de desviaciones estándar basados en la distribución normal. Esto nos permite comparar distribuciones distintas.\nAl valor estandarizado lo llamamos puntaje Z, y corresponde a la cantidad de desviaciones estándar que nos alejamos del promedio (para cada variable con la que trabajemos).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "href": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.5. Cálculo de probabilidades con puntaje z",
    "text": "3.5. Cálculo de probabilidades con puntaje z\nLos valores estandarizados o puntajes Z además nos permiten conocer probabilidades.\nCon R es posible generar un conjunto de datos simulados con una distribución normal.\n\nx_values &lt;- seq(-4,4,length=1000)\ny_values &lt;- dnorm(x_values)\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\n\n\n\n\n\n\n\n\nPodemos preguntar qué parte de la curva cae por debajo de un valor particular. Por ejemplo, preguntaremos sobre el valor 0 antes de ejecutar el código. Piense ¿cuál debería ser la respuesta?\n\npnorm(q = 0)\n\n[1] 0.5\n\n\nPor tanto, la probabilidad (en una curva normal estándar) de obtener un valor igual o menor a 0 es de 0.5, es decir, del 50%, pero ¿por qué?\n\nPorque como la distribución normal estándar es simétrica al rededor de cero, la probabilidad de que sea menor o igual a cero es 0.5, es decir, el 50% de la distribución está por debajo de cero y el otro 50% está por encima de cero.\n\nEso lo podemos ver en el gráfico:\n\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\nabline(v=0)\n\n\n\n\n\n\n\n\nAhora probemos los valores Z de +1,96 y -1,96.\nSabemos que estos valores aproximados marcan el 2,5% superior e inferior de la distribución normal estándar. Esto corresponde a un alfa típico \\(\\alpha = 0,05\\) para una prueba de hipótesis de dos colas.\n\npnorm(q = 1.96, lower.tail=TRUE)\n\n[1] 0.9750021\n\n\nLa respuesta nos dice lo que ya sabemos: el 97,5% de la distribución normal ocurre por debajo del valor z de 1,96.\nPodemos agregar una línea al gráfico para mostrar dónde se usaría abline.\nEl 97,5% de la distribución queda por debajo de esta línea.\n\nplot(x_values, y_values, type=\"l\", lty=1, xlab=\"Z value\", ylab=\"Probability\", main=\"Normal Distribution\") +\nabline(v = 1.96)\n\n\n\n\n\n\n\n\ninteger(0)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "href": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "4.1. Cálculo de intervalos de confianza",
    "text": "4.1. Cálculo de intervalos de confianza\nEn el caso de nuestro vector aleatorio, un intervalo de confianza para la media se puede calcular de la siguiente manera:\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1] 4.818567 5.543057\nattr(,\"conf.level\")\n[1] 0.95\n\n\nTambién podemos calcular intervalos de confianza para casos reales. Carguemos la base de datos que utilizaremos, que corresponde a un subset de la Encuesta Suplementaria de ingresos ESI para ocupados:\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/esi-2021-ocupados.rdata\"))\n\n\n\n\n\n\n\nNota\n\n\n\nRecordemos que podemos contar con bases de datos que tengan factor de expansión (ponderador) o no. Esta distinción se presenta cuando trabajamos con muestras simples o complejas. Al trabajar con muestras complejas debemos identificar cuál es la variable del ponderador e incorporarla en nuestro cálculo.\nEn esta guía practicaa trabajaremos sin factores de expansión o ponderadores.\n\n\n\nIC para Medias\nCalculemos un intervalo de confianza para la media de ingresos de personas ocupadas:\n\npsych::describe(esi$ing_t_p)\n\n   vars     n     mean       sd   median  trimmed      mad min      max\nX1    1 37124 586360.4 697362.9 405347.7 474473.1 255411.6   0 38206253\n      range skew kurtosis      se\nX1 38206253   12   402.32 3619.36\n\n\n\nPublish::ci.mean(esi$ing_t_p, alpha = 0.05)\n\n mean      CI-95%               \n 586360.41 [579266.37;593454.45]\n\n\nContamos con una media de ingresos de $586.360 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre $579.266 y $593.454.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección se encuentran disponibles los documentos de presentación que sirven de base a cada clase, en el menú de la izquierda Presentaciones. Los documentos son en formato html (no son ppt), producidos con Xaringan. Para verlos en pantalla completa presionar F sobre el documento, y para una vista general de todas las slides presionar O.\nTambién a la izquierda hay un link al Foro para hacer preguntas relacionadas con las clases.\nCada clase tiene como referencia lecturas que deben completarse antes de la sesión correspondiente.",
    "crumbs": [
      "Clases",
      "Descripción"
    ]
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Bivariada 1 - Asociación y covarianza",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 1"
    ]
  }
]