[
  {
    "objectID": "files/reporte_notas/reporte_notas.html",
    "href": "files/reporte_notas/reporte_notas.html",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "pacman::p_load(googlesheets4, dplyr, sjmisc,sjPlot, kableExtra, sjlabelled )\n\n\n\n [1] \"N\"            \"Persona\"      \"p1-a\"         \"p1-b\"         \"p2\"          \n [6] \"p3\"           \"p4\"           \"p5\"           \"pje\"          \"Nota 60%\"    \n[11] \"corrector/a\"  \"decimas\"      \"nota_final\"   \"Recorrección\" \"...15\"       \n[16] \"...16\"       \n\n\n\nload(\"prueba1.Rdata\")\n\n\n\n\n\n# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Cálculo Pearson\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Interpretación Pearson\")\nprueba1$p2 &lt;- set_label(x = prueba1$p2, \n                         label = \"Limitación Pearson\")\nprueba1$p3 &lt;- set_label(x = prueba1$p3, \n                         label = \"Coeficiente determinación\")\nprueba1$p4 &lt;- set_label(x = prueba1$p4, \n                         label = \"Spearman\")\nprueba1$p5 &lt;- set_label(x = prueba1$p5, \n                         label = \"Perdidos matrices\")\n\n\n\n\n\nprueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n2\np1a\nCálculo Pearson\n79\n1.78\n1.29\n3 (0-3)\n\n\n3\np1b\nInterpretación Pearson\n79\n1.66\n0.78\n3 (0-3)\n\n\n4\np2\nLimitación Pearson\n79\n1.53\n0.69\n2 (0-2)\n\n\n5\np3\nCoeficiente determinación\n79\n1.50\n0.64\n2 (0-2)\n\n\n6\np4\nSpearman\n79\n1.39\n0.81\n2 (0-2)\n\n\n7\np5\nPerdidos matrices\n79\n0.99\n0.89\n2 (0-2)\n\n\n1\nnota_final\nnota_final\n79\n4.54\n1.40\n6 (1-7)\n\n\n\n\n\n\n\n\n\nhist(prueba1$nota_final)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota_final,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota_final, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat)\n\nx &lt;categorical&gt; \n# total N=88 valid N=79 mean=2.23 sd=1.13\n\nValue       |  N | Raw % | Valid % | Cum. %\n-------------------------------------------\nMenor a 4.0 | 30 | 34.09 |   37.97 |  37.97\n4.0-5.0     | 14 | 15.91 |   17.72 |  55.70\n5.0-6.0     | 22 | 25.00 |   27.85 |  83.54\n6.0-7.0     | 13 | 14.77 |   16.46 | 100.00\n&lt;NA&gt;        |  9 | 10.23 |    &lt;NA&gt; |   &lt;NA&gt;\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)\n\n\n\n\n\ntab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nCálculo Pearson\nInterpretación Pearson\nLimitación Pearson\nCoeficiente determinación\nSpearman\nPerdidos matrices\nnota_final\n\n\nCálculo Pearson\n \n \n \n \n \n \n \n\n\nInterpretación Pearson\n0.405***\n \n \n \n \n \n \n\n\nLimitación Pearson\n0.211\n0.153\n \n \n \n \n \n\n\nCoeficiente determinación\n0.271*\n0.407***\n0.267*\n \n \n \n \n\n\nSpearman\n0.229*\n0.203\n0.375***\n0.197\n \n \n \n\n\nPerdidos matrices\n0.063\n0.127\n0.435***\n0.095\n0.277*\n \n \n\n\nnota_final\n0.696***\n0.627***\n0.619***\n0.524***\n0.583***\n0.539***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nplot_scatter(prueba1, p1a, p1b)\n\n\n\n\n\n\n\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota_final)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 6\nSample units: 79\nalpha: 0.634"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "href": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "pacman::p_load(googlesheets4, dplyr, sjmisc,sjPlot, kableExtra, sjlabelled )\n\n\n\n [1] \"N\"            \"Persona\"      \"p1-a\"         \"p1-b\"         \"p2\"          \n [6] \"p3\"           \"p4\"           \"p5\"           \"pje\"          \"Nota 60%\"    \n[11] \"corrector/a\"  \"decimas\"      \"nota_final\"   \"Recorrección\" \"...15\"       \n[16] \"...16\"       \n\n\n\nload(\"prueba1.Rdata\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#etiquetados",
    "href": "files/reporte_notas/reporte_notas.html#etiquetados",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Cálculo Pearson\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Interpretación Pearson\")\nprueba1$p2 &lt;- set_label(x = prueba1$p2, \n                         label = \"Limitación Pearson\")\nprueba1$p3 &lt;- set_label(x = prueba1$p3, \n                         label = \"Coeficiente determinación\")\nprueba1$p4 &lt;- set_label(x = prueba1$p4, \n                         label = \"Spearman\")\nprueba1$p5 &lt;- set_label(x = prueba1$p5, \n                         label = \"Perdidos matrices\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "href": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "prueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n2\np1a\nCálculo Pearson\n79\n1.78\n1.29\n3 (0-3)\n\n\n3\np1b\nInterpretación Pearson\n79\n1.66\n0.78\n3 (0-3)\n\n\n4\np2\nLimitación Pearson\n79\n1.53\n0.69\n2 (0-2)\n\n\n5\np3\nCoeficiente determinación\n79\n1.50\n0.64\n2 (0-2)\n\n\n6\np4\nSpearman\n79\n1.39\n0.81\n2 (0-2)\n\n\n7\np5\nPerdidos matrices\n79\n0.99\n0.89\n2 (0-2)\n\n\n1\nnota_final\nnota_final\n79\n4.54\n1.40\n6 (1-7)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "href": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "hist(prueba1$nota_final)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota_final,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota_final, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat)\n\nx &lt;categorical&gt; \n# total N=88 valid N=79 mean=2.23 sd=1.13\n\nValue       |  N | Raw % | Valid % | Cum. %\n-------------------------------------------\nMenor a 4.0 | 30 | 34.09 |   37.97 |  37.97\n4.0-5.0     | 14 | 15.91 |   17.72 |  55.70\n5.0-6.0     | 22 | 25.00 |   27.85 |  83.54\n6.0-7.0     | 13 | 14.77 |   16.46 | 100.00\n&lt;NA&gt;        |  9 | 10.23 |    &lt;NA&gt; |   &lt;NA&gt;\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "href": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "",
    "text": "tab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nCálculo Pearson\nInterpretación Pearson\nLimitación Pearson\nCoeficiente determinación\nSpearman\nPerdidos matrices\nnota_final\n\n\nCálculo Pearson\n \n \n \n \n \n \n \n\n\nInterpretación Pearson\n0.405***\n \n \n \n \n \n \n\n\nLimitación Pearson\n0.211\n0.153\n \n \n \n \n \n\n\nCoeficiente determinación\n0.271*\n0.407***\n0.267*\n \n \n \n \n\n\nSpearman\n0.229*\n0.203\n0.375***\n0.197\n \n \n \n\n\nPerdidos matrices\n0.063\n0.127\n0.435***\n0.095\n0.277*\n \n \n\n\nnota_final\n0.696***\n0.627***\n0.619***\n0.524***\n0.583***\n0.539***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nplot_scatter(prueba1, p1a, p1b)\n\n\n\n\n\n\n\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota_final)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 6\nSample units: 79\nalpha: 0.634"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#datos",
    "href": "files/reporte_notas/reporte_notas.html#datos",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Datos",
    "text": "Datos\n\nload(\"prueba2.Rdata\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#adecuación-preguntas",
    "href": "files/reporte_notas/reporte_notas.html#adecuación-preguntas",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Adecuación preguntas",
    "text": "Adecuación preguntas\nLa prueba tiene dos formas: A y B, la única diferencia es en el orden de las preguntas, la forma A parte por la pregunta sobre identificación con la izquierda, mientras que en la forma B la primera pregunta es la de CASEN. Para poder realizar un correcto análisis de las preguntas vamos a adaptar la forma B a la A.\n\nfrq(prueba2$forma)\n\nx &lt;character&gt; \n# total N=87 valid N=72 mean=1.50 sd=0.50\n\nValue |  N | Raw % | Valid % | Cum. %\n-------------------------------------\nA     | 36 | 41.38 |      50 |     50\nB     | 36 | 41.38 |      50 |    100\n&lt;NA&gt;  | 15 | 17.24 |    &lt;NA&gt; |   &lt;NA&gt;\n\nA &lt;- subset(prueba2, subset = prueba2$forma==\"A\")\nB &lt;- subset(prueba2, subset = prueba2$forma==\"B\")\ndim(A)\n\n[1] 36  8\n\ndim(B)\n\n[1] 36  8\n\ndescr(B, show = \"mean\")\n\n\n## Basic descriptive statistics\n\n        var mean\n        p1a 1.33\n        p1b 1.36\n        p1c 1.31\n        p2a 1.39\n        p2b 1.28\n        p2c 1.32\n nota_final 4.58\n\nB &lt;- B %&gt;% rename(\"p1a\"=\"p2a\", \n                  \"p1b\"=\"p2b\",\n                  \"p1c\"=\"p2c\",\n                  \"p2a\"=\"p1a\",\n                  \"p2b\"=\"p1b\",\n                  \"p2c\"=\"p1c\")\n\ndescr(B, show = \"mean\")\n\n\n## Basic descriptive statistics\n\n        var mean\n        p2a 1.33\n        p2b 1.36\n        p2c 1.31\n        p1a 1.39\n        p1b 1.28\n        p1c 1.32\n nota_final 4.58\n\nprueba2 &lt;- rbind(A,B)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#etiquetados-1",
    "href": "files/reporte_notas/reporte_notas.html#etiquetados-1",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Etiquetados",
    "text": "Etiquetados\n\n# Label variables\n\nprueba2$p1a &lt;- set_label(x = prueba2$p1a, \n                         label = \"H1 promedio direccional\")\nprueba2$p1b &lt;- set_label(x = prueba2$p1b, \n                         label = \"Prueba promedios\")\nprueba2$p1c &lt;- set_label(x = prueba2$p1c, \n                         label = \"Rechazo H0\")\nprueba2$p2a &lt;- set_label(x = prueba2$p2a, \n                         label = \"H1 proporcion no direccional\")\nprueba2$p2b &lt;- set_label(x = prueba2$p2b, \n                         label = \"Error tipo 1\")\nprueba2$p2c &lt;- set_label(x = prueba2$p2c, \n                         label = \"Intervalo confianza\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#tabla-descriptiva-1",
    "href": "files/reporte_notas/reporte_notas.html#tabla-descriptiva-1",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Tabla descriptiva",
    "text": "Tabla descriptiva\n\nprueba2 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n2\np1a\nH1 promedio direccional\n72\n1.36\n0.63\n2 (0-2)\n\n\n3\np1b\nPrueba promedios\n72\n1.24\n0.86\n2 (0-2)\n\n\n4\np1c\nRechazo H0\n72\n1.27\n0.70\n2 (0-2)\n\n\n5\np2a\nH1 proporcion no direccional\n72\n1.26\n0.68\n2 (0-2)\n\n\n6\np2b\nError tipo 1\n72\n1.27\n0.79\n2 (0-2)\n\n\n7\np2c\nIntervalo confianza\n72\n1.14\n0.72\n2 (0-2)\n\n\n1\nnota_final\nnota_final\n72\n4.37\n1.23\n5.6 (1.4-7)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos-1",
    "href": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos-1",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Gráficos descriptivos",
    "text": "Gráficos descriptivos\n\nhist(prueba2$nota_final)\n\n\n\n\n\n\n\nplot_frq(data = prueba2$nota_final,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba2 &lt;- prueba2 %&gt;%  mutate(notas_cat=cut(nota_final, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba2$notas_cat)\n\nx &lt;categorical&gt; \n# total N=72 valid N=72 mean=2.06 sd=1.02\n\nValue       |  N | Raw % | Valid % | Cum. %\n-------------------------------------------\nMenor a 4.0 | 28 | 38.89 |   38.89 |  38.89\n4.0-5.0     | 19 | 26.39 |   26.39 |  65.28\n5.0-6.0     | 18 | 25.00 |   25.00 |  90.28\n6.0-7.0     |  7 |  9.72 |    9.72 | 100.00\n&lt;NA&gt;        |  0 |  0.00 |    &lt;NA&gt; |   &lt;NA&gt;\n\nprueba2 &lt;- prueba2 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones-1",
    "href": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones-1",
    "title": "Reporte Notas - Estadística Correlacional 2023",
    "section": "Preguntas y asociaciones",
    "text": "Preguntas y asociaciones\n\nprueba2 &lt;- prueba2 %&gt;% dplyr::select(-forma)\ntab_corr(prueba2,\n         triangle = \"lower\")\n\n\n\n\n \nH1 promedio direccional\nPrueba promedios\nRechazo H0\nH1 proporcion no direccional\nError tipo 1\nIntervalo confianza\nnota_final\n\n\nH1 promedio direccional\n \n \n \n \n \n \n \n\n\nPrueba promedios\n0.295*\n \n \n \n \n \n \n\n\nRechazo H0\n0.397***\n0.488***\n \n \n \n \n \n\n\nH1 proporcion no direccional\n0.108\n0.094\n-0.060\n \n \n \n \n\n\nError tipo 1\n-0.204\n0.039\n0.031\n-0.039\n \n \n \n\n\nIntervalo confianza\n0.047\n0.206\n0.308**\n0.169\n0.351**\n \n \n\n\nnota_final\n0.469***\n0.677***\n0.650***\n0.370**\n0.404***\n0.631***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba2 %&gt;% dplyr::select(-nota_final)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 6\nSample units: 72\nalpha: 0.513"
  },
  {
    "objectID": "assignment/02-practico.html",
    "href": "assignment/02-practico.html",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "El objetivo de esta guía práctica es realizar una serie de ejercicios de inferencia estadística, tomando como base todos los contenidos de la Unidad 1. En particular, se abordan pruebas de hipótesis para diferencias de medias y direccionales utilizando la prueba t\nLa guía tiene 3 ejercicios. El primero de ellos es un ejemplo, y los ejercicios 2 y 3 se desarrollan de manera autónoma en la sala (también puede ser en grupo).\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.\n\n\n\n\nEn inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#recursos-de-la-práctica",
    "href": "assignment/02-practico.html#recursos-de-la-práctica",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "href": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#formulación-de-hipótesis",
    "href": "assignment/02-practico.html#formulación-de-hipótesis",
    "title": "Práctico 2: Intentando rechazar",
    "section": "1. Formulación de hipótesis",
    "text": "1. Formulación de hipótesis\nEl primer paso es traducir nuestra pregunta a una hipótesis estadística contrastable. Para ello: a) elija el tipo de hipótesis a plantear ¿direccional o no direccional? y b) especifique la hipótesis nula (\\(H_0\\)) e hipótesis alternativa (\\(H_A\\)).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "href": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "title": "Práctico 2: Intentando rechazar",
    "section": "Pasos 2, 3 y 4 de una vez con R",
    "text": "Pasos 2, 3 y 4 de una vez con R\nSiguiendo el ejemplo del Ejercicio 1, utilice el software para generar los estadísticos correspondientes. Contraste sus hipótesis considerando un 95% de confianza y un 99% de confianza. Comente las diferencias en el paso 5.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "content/07-content-b.html",
    "href": "content/07-content-b.html",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "A Ud. se le ha solicitado estimar el promedio de salarios en la población, así como también si existen diferencias salariales entre quienes han completado la educación superior en institutos técnico-profesionales (IP) y quienes lo han hecho en instituciones universitarias. Para ello se le ha proporcionado la siguiente información:\n\nDatos: Encuesta de Ingresos, muestra aleatoria N=900 casos\nPromedio salarios: 850.000, desviación estándar 300.000\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\n\nAdemás de esto, se le han proporcionado los siguientes valores para realizar inferencia estadística:\n\nvalor crítico z para el promedio con un \\(\\alpha\\) de 5% (0,05)= 1,96, y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96; y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nError estándar del promedio:\n\n\\[\\sigma_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\n\nError estándar de la diferencia de medias salariales para esta muestra= 15000\n\n\n\nCódigo\n# Generación de los datos\noptions(scipen = 999)\n\n# Establecer la semilla para garantizar la reproducibilidad\nset.seed(281217)  \n\n# Parámetros actualizados\nn &lt;- 900  # Tamaño de la muestra\npromedio_salarios &lt;- 850000;desviacion_estandar_salarios &lt;- 300000  # Desviación estándar de los salarios\n\n# Generar la muestra con la nueva semilla y parámetros\ningresos &lt;- rnorm(n, mean = promedio_salarios, sd = desviacion_estandar_salarios)\n\n\n\n\n\nTengo que el promedio de salarios de la muestra es: 900.000\nPromedio de salarios de la población: \\(X\\)?\n\nNo podemos dar un valor certero para el promedio poblacional, pero si un rango probable de valores.\n\n\n¿Qué tipo de aproximación de test de hipótesis corresponde en este caso? Recordemos las dos aproximaciones principales para test de hipótesis: a) contraste con valor crítico, y b) generación de intervalo de confianza. En general se pueden aplicar siempre las dos, pero su pertinencia es distinta según lo que se esté estimando:\n\nen este caso (estimación del promedio) se podría realizar la alternativa de contraste con valor crítico, que nos permitiría rechazar (o no) la hipótesis nula de que el promedio es cero en la población.\nya que la alternativa anterior no es muy informativa en este caso, en la estimación puntual de parámetros (como el promedio) se prefiere utilizar un rango de probabilidad, expresado en un intervalo de confianza.\n\nPor lo tanto, en este caso lo que es más pertinente es la alternativa b: estimación de un intervalo de confianza\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (el promedio es igual a 0 en la población):\n\\[H_{0}: \\bar{X}_{salarios}=0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salarios} \\neq 0\\]\n\n\n\nEl error estándar (SE, por Standard Error) del promedio es:\n\\[SE_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\nReemplazando:\n\\[SE_{\\bar{X}}=\\frac{300000}{\\sqrt{900}}=\\frac{300000}{30}=10000\\]\n\n\nCódigo\nerror_estandar &lt;- desviacion_estandar_salarios / sqrt(n)\nerror_estandar\n\n\n[1] 10000\n\n\n\n\n\nEsta informació fue proporcionada en el enunciado: \\(\\alpha=5%\\), valor crítico= 1,96\n\n\n\nRecordar fórmula del intervalo de 95% de confianza para el promedio:\n\\[\\begin{align*}\n\\bar{x} &\\pm Z_{\\alpha/2}*SE_{\\bar{x}} \\\\\\\\\n850000 &\\pm 1.96*10000 \\\\\\\\\n850000 &\\pm 19600 \\\\\\\\\nCI[830400&;869600]\n\\end{align*}\\]\nEn R:\n\n\nCódigo\n# Calcular el intervalo de confianza al 95%\nz_95 &lt;- 1.96  # Valor z para el 95% de confianza\nlimite_inferior &lt;- promedio_salarios - z_95 * error_estandar\nlimite_superior &lt;- promedio_salarios + z_95 * error_estandar\n\n# Mostrar los resultados\ncat(\"Intervalo de confianza al 95%: [\", round(limite_inferior, 2), \", \", round(limite_superior, 2), \"]\\n\")\n\n\nIntervalo de confianza al 95%: [ 830400 ,  869600 ]\n\n\n\n\n\nUtilizando una muestra de 900 individuos, se estimó el promedio de ingresos en $850,000 con una desviación estándar de $300,000. El error estándar para esta estimación es $10,000, y el intervalo de confianza al 95%, calculado con estos parámetros, se extiende de $830,400 a $869,600. Este intervalo refleja que, con un 95% de confianza, se puede afirmar que el promedio verdadero de ingresos en la población se encuentra dentro de este rango, asumiendo una distribución normal de los ingresos.\n\n\n\n\n\nPara este ejercicio consideramos la siguiente información proporcionada arriba:\n\nN de cada grupo: 900\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96\nerror estándar de la diferencia de medias= 15000\n\nCon esta información ya podemos calcular la diferencia de promedios de la muestra:\n\\(\\bar{X}_{salario-universitario}-\\bar{X}_{salario-tecnico}=1500000-1200000=300000\\)\nLa pregunta ahora es: ¿existe esta diferencia de promedios en la población?\n\n\nPara el caso anterior de la estimación del promedio hablamos de dos aproximaciones: a) contraste con valor crítico, y b) intervalo de confianza. En este caso (estimación de diferencias de promedio) tradicionalmente se utiliza el contraste con valor crítico, ya que lo central es poder establecer si existen o no diferencias en la población. Complementariamente, también se puede entregar información del intervalo de confianza.\nPor lo tanto, en este caso lo que es más pertinente es la alternativa a: contraste con valor crítico, pero también es recomendable agregar la información del intervalo de confianza.\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (no hay diferencias de promedios entre grupos):\n\\[H_{0}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto}= 0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto} \\neq 0\\]\n\n\n\nEl error estándar de la diferencias de promedios es:\n\\[SE=\\sqrt{\\frac{\\sigma_{diff}}{n_a}+\\frac{\\sigma_{diff}}{n_b}}\\]\nLa información sobre el resultado de este cálculo se nos entrega inicialmente y es igual a 15000\nCon esto podemos calcular el valor del t empírico:\n\\(t=\\frac{diferenciamedias}{se_{diferenciamedias}} \\frac{(\\bar{x}_1-\\bar{x}_2)}{se_{(\\bar{x}_1-\\bar{x}_2)}}\\)\nCon nuestros datos:\n\\(t=\\frac{300000}{15000}=20\\)\n\n\n\n\nProporcionado en el enunciado\n\n\n\n\nt empírico= 20 &gt; t critico=1,96\nIntervalo al 95% de confianza:\n\\[\\begin{align*}\n\\bar{x}_1-\\bar{x}_2 &\\pm t_{\\alpha/2}*SE_{\\bar{x_1}-\\bar{x_2}} \\\\\\\\\n300000 &\\pm 1.96*15000 \\\\\\\\\n300000 &\\pm 29400 \\\\\\\\\nCI[270600&\\ ;329400]\n\\end{align*}\\]\n\n\n\nSe llevó a cabo una prueba t para evaluar las diferencias salariales entre graduados de institutos técnicos-profesionales y universidades, utilizando un tamaño de muestra de 900 para cada grupo. La diferencia de medias observada fue de $750,000, con un error estándar fijo de $15,000 para esta diferencia. El análisis resultó en un valor t de 50.00, indicando una diferencia estadísticamente significativa entre los dos grupos (p &lt; .01). Este valor t refleja que los graduados universitarios tienen un ingreso promedio significativamente mayor en comparación con los graduados de institutos técnicos-profesionales. Estos resultados sugieren una marcada disparidad salarial en función del nivel educativo alcanzado, subrayando la importancia de las decisiones educativas en las trayectorias de ingresos de los individuos."
  },
  {
    "objectID": "content/07-content-b.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "href": "content/07-content-b.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Tengo que el promedio de salarios de la muestra es: 900.000\nPromedio de salarios de la población: \\(X\\)?\n\nNo podemos dar un valor certero para el promedio poblacional, pero si un rango probable de valores.\n\n\n¿Qué tipo de aproximación de test de hipótesis corresponde en este caso? Recordemos las dos aproximaciones principales para test de hipótesis: a) contraste con valor crítico, y b) generación de intervalo de confianza. En general se pueden aplicar siempre las dos, pero su pertinencia es distinta según lo que se esté estimando:\n\nen este caso (estimación del promedio) se podría realizar la alternativa de contraste con valor crítico, que nos permitiría rechazar (o no) la hipótesis nula de que el promedio es cero en la población.\nya que la alternativa anterior no es muy informativa en este caso, en la estimación puntual de parámetros (como el promedio) se prefiere utilizar un rango de probabilidad, expresado en un intervalo de confianza.\n\nPor lo tanto, en este caso lo que es más pertinente es la alternativa b: estimación de un intervalo de confianza\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (el promedio es igual a 0 en la población):\n\\[H_{0}: \\bar{X}_{salarios}=0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salarios} \\neq 0\\]\n\n\n\nEl error estándar (SE, por Standard Error) del promedio es:\n\\[SE_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\nReemplazando:\n\\[SE_{\\bar{X}}=\\frac{300000}{\\sqrt{900}}=\\frac{300000}{30}=10000\\]\n\n\nCódigo\nerror_estandar &lt;- desviacion_estandar_salarios / sqrt(n)\nerror_estandar\n\n\n[1] 10000\n\n\n\n\n\nEsta informació fue proporcionada en el enunciado: \\(\\alpha=5%\\), valor crítico= 1,96\n\n\n\nRecordar fórmula del intervalo de 95% de confianza para el promedio:\n\\[\\begin{align*}\n\\bar{x} &\\pm Z_{\\alpha/2}*SE_{\\bar{x}} \\\\\\\\\n850000 &\\pm 1.96*10000 \\\\\\\\\n850000 &\\pm 19600 \\\\\\\\\nCI[830400&;869600]\n\\end{align*}\\]\nEn R:\n\n\nCódigo\n# Calcular el intervalo de confianza al 95%\nz_95 &lt;- 1.96  # Valor z para el 95% de confianza\nlimite_inferior &lt;- promedio_salarios - z_95 * error_estandar\nlimite_superior &lt;- promedio_salarios + z_95 * error_estandar\n\n# Mostrar los resultados\ncat(\"Intervalo de confianza al 95%: [\", round(limite_inferior, 2), \", \", round(limite_superior, 2), \"]\\n\")\n\n\nIntervalo de confianza al 95%: [ 830400 ,  869600 ]\n\n\n\n\n\nUtilizando una muestra de 900 individuos, se estimó el promedio de ingresos en $850,000 con una desviación estándar de $300,000. El error estándar para esta estimación es $10,000, y el intervalo de confianza al 95%, calculado con estos parámetros, se extiende de $830,400 a $869,600. Este intervalo refleja que, con un 95% de confianza, se puede afirmar que el promedio verdadero de ingresos en la población se encuentra dentro de este rango, asumiendo una distribución normal de los ingresos."
  },
  {
    "objectID": "content/07-content-b.html#estimación-de-diferencia-de-medias",
    "href": "content/07-content-b.html#estimación-de-diferencia-de-medias",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Para este ejercicio consideramos la siguiente información proporcionada arriba:\n\nN de cada grupo: 900\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96\nerror estándar de la diferencia de medias= 15000\n\nCon esta información ya podemos calcular la diferencia de promedios de la muestra:\n\\(\\bar{X}_{salario-universitario}-\\bar{X}_{salario-tecnico}=1500000-1200000=300000\\)\nLa pregunta ahora es: ¿existe esta diferencia de promedios en la población?\n\n\nPara el caso anterior de la estimación del promedio hablamos de dos aproximaciones: a) contraste con valor crítico, y b) intervalo de confianza. En este caso (estimación de diferencias de promedio) tradicionalmente se utiliza el contraste con valor crítico, ya que lo central es poder establecer si existen o no diferencias en la población. Complementariamente, también se puede entregar información del intervalo de confianza.\nPor lo tanto, en este caso lo que es más pertinente es la alternativa a: contraste con valor crítico, pero también es recomendable agregar la información del intervalo de confianza.\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (no hay diferencias de promedios entre grupos):\n\\[H_{0}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto}= 0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto} \\neq 0\\]\n\n\n\nEl error estándar de la diferencias de promedios es:\n\\[SE=\\sqrt{\\frac{\\sigma_{diff}}{n_a}+\\frac{\\sigma_{diff}}{n_b}}\\]\nLa información sobre el resultado de este cálculo se nos entrega inicialmente y es igual a 15000\nCon esto podemos calcular el valor del t empírico:\n\\(t=\\frac{diferenciamedias}{se_{diferenciamedias}} \\frac{(\\bar{x}_1-\\bar{x}_2)}{se_{(\\bar{x}_1-\\bar{x}_2)}}\\)\nCon nuestros datos:\n\\(t=\\frac{300000}{15000}=20\\)\n\n\n\n\nProporcionado en el enunciado\n\n\n\n\nt empírico= 20 &gt; t critico=1,96\nIntervalo al 95% de confianza:\n\\[\\begin{align*}\n\\bar{x}_1-\\bar{x}_2 &\\pm t_{\\alpha/2}*SE_{\\bar{x_1}-\\bar{x_2}} \\\\\\\\\n300000 &\\pm 1.96*15000 \\\\\\\\\n300000 &\\pm 29400 \\\\\\\\\nCI[270600&\\ ;329400]\n\\end{align*}\\]\n\n\n\nSe llevó a cabo una prueba t para evaluar las diferencias salariales entre graduados de institutos técnicos-profesionales y universidades, utilizando un tamaño de muestra de 900 para cada grupo. La diferencia de medias observada fue de $750,000, con un error estándar fijo de $15,000 para esta diferencia. El análisis resultó en un valor t de 50.00, indicando una diferencia estadísticamente significativa entre los dos grupos (p &lt; .01). Este valor t refleja que los graduados universitarios tienen un ingreso promedio significativamente mayor en comparación con los graduados de institutos técnicos-profesionales. Estos resultados sugieren una marcada disparidad salarial en función del nivel educativo alcanzado, subrayando la importancia de las decisiones educativas en las trayectorias de ingresos de los individuos."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "",
    "text": "Inferencia, asociación y reporte\n        \n        \n            SOC01019 • Segundo Semestre 2024Departamento de Sociología, Facultad de Ciencias SocialesUniversidad de Chile"
  },
  {
    "objectID": "index.html#últimas-informaciones",
    "href": "index.html#últimas-informaciones",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Últimas informaciones",
    "text": "Últimas informaciones\n\n\n\n\n\n\n\n\n\n\nTaller Centro IDEA\n\n\n\n\n\n\n\n\n\nSep 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCambios en evaluación 1\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEquipo docente y ayudantes\n\n\n\n\n\n\n\n\n\nSep 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsignación asesorías ayudantes\n\n\n\n\n\n\n\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión práctica martes 27 de agosto\n\n\n\n\n\n\n\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrácticos parten próxima semana (Martes 27)\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformaciones por acá\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n\n-&gt; ir a la página de Informaciones del sitio."
  },
  {
    "objectID": "index.html#versiones-previas-del-curso",
    "href": "index.html#versiones-previas-del-curso",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Versiones previas del curso:",
    "text": "Versiones previas del curso:\n\n2023"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados. Estas instancias serán conducidas guiadas por los apoyos docentes del curso.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentras a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 12\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nMartes 13\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 19\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMartes 20\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 26\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMartes 27\n\nPráctico: Inferencia 1\n\n\n\n Septiembre \n\n\n\n\n\nLunes 2\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMartes 3\n\nPráctico Inferencia 2\n\n\n\nLunes 9\nRepaso Unidad 1\n\n\n\n\nMartes 10\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 23\nAsociación y covarianza\n\n\n\n\nMartes 24\nInferencia en correlación de Pearson\n\n\n\n\nLunes 30\nCorrelación con ordinales\n\n\n\n\nMartes 1\n\nPráctico. Guía 1 Bivariada\n\n\n\nLunes 7\nMatrices y tamaños de efecto en correlación\n\n\n\n\nMartes 8\nAsociación con categóricas 1\n\n\n\n\nLunes 14\nAsociación con categóricas 2\n\n\n\n\nMartes 15\n\nPráctico: Guía 2 Bivariada\n\n\n\nLunes 21\nEvaluación 2\n\n\n\n\nMartes 22\nEvaluación 2\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMartes 29\nSemana receso\n\n\n\n\n\n\n\n\n\n\nLunes 4\nSeminario encuestas\n\n\n\n\nMartes 5\n\nDefinición de grupos y temas\n\n\n\nLunes 11\nEscritura de reportes de investigación\n\n\n\n\nMartes 12\n\nReportes dinámicos y\nPlantilla trabajo final\n\n\n\nLunes 18\nVisualización de datos 1\n\n\n\n\nMartes 19\n\nVisualización 1\n\n\n\nLunes 25\nVisualización de datos 2\n\n\n\n\nMartes 26\n\nVisualización 2 y elaboración de poster\n\n\n\nLunes 25\nPresentación de poster de investigación\n\n\n\n\nMartes 26\nPruebas recuperativas\n\n\n\n\nViernes 29\nEntrega de trabajo final grupal"
  },
  {
    "objectID": "schedule.html#forma-general-de-funcionamiento",
    "href": "schedule.html#forma-general-de-funcionamiento",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados. Estas instancias serán conducidas guiadas por los apoyos docentes del curso.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentras a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 12\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nMartes 13\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 19\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMartes 20\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 26\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMartes 27\n\nPráctico: Inferencia 1\n\n\n\n Septiembre \n\n\n\n\n\nLunes 2\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMartes 3\n\nPráctico Inferencia 2\n\n\n\nLunes 9\nRepaso Unidad 1\n\n\n\n\nMartes 10\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 23\nAsociación y covarianza\n\n\n\n\nMartes 24\nInferencia en correlación de Pearson\n\n\n\n\nLunes 30\nCorrelación con ordinales\n\n\n\n\nMartes 1\n\nPráctico. Guía 1 Bivariada\n\n\n\nLunes 7\nMatrices y tamaños de efecto en correlación\n\n\n\n\nMartes 8\nAsociación con categóricas 1\n\n\n\n\nLunes 14\nAsociación con categóricas 2\n\n\n\n\nMartes 15\n\nPráctico: Guía 2 Bivariada\n\n\n\nLunes 21\nEvaluación 2\n\n\n\n\nMartes 22\nEvaluación 2\n\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMartes 29\nSemana receso\n\n\n\n\n\n\n\n\n\n\nLunes 4\nSeminario encuestas\n\n\n\n\nMartes 5\n\nDefinición de grupos y temas\n\n\n\nLunes 11\nEscritura de reportes de investigación\n\n\n\n\nMartes 12\n\nReportes dinámicos y\nPlantilla trabajo final\n\n\n\nLunes 18\nVisualización de datos 1\n\n\n\n\nMartes 19\n\nVisualización 1\n\n\n\nLunes 25\nVisualización de datos 2\n\n\n\n\nMartes 26\n\nVisualización 2 y elaboración de poster\n\n\n\nLunes 25\nPresentación de poster de investigación\n\n\n\n\nMartes 26\nPruebas recuperativas\n\n\n\n\nViernes 29\nEntrega de trabajo final grupal"
  },
  {
    "objectID": "schedule.html#exámenes-finales-escritos-en-sala",
    "href": "schedule.html#exámenes-finales-escritos-en-sala",
    "title": "Planificación",
    "section": "Exámenes finales (escritos, en sala)",
    "text": "Exámenes finales (escritos, en sala)\nVer requisitos de aprobación y eximición\n\nExamen de primera oportunidad: Lunes 9 Diciembre 10:15\nExamen de segunda oportunidad: Lunes 16 Diciembre 10:15"
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Informaciones",
    "section": "",
    "text": "Acá las principales informaciones y actualizaciones del curso.\n\n\n   \n     \n     \n       Ordenar por\n       Por defecto\n         \n          Fecha - Menos reciente\n        \n         \n          Fecha - Más reciente\n        \n         \n          Título\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nFecha\n\n\nTítulo\n\n\nCategorías\n\n\n\n\n\n\nmiércoles septiembre 4, 2024 at 1:00 AM\n\n\nTaller Centro IDEA\n\n\ninfo, mail-UCursos\n\n\n\n\nmartes septiembre 3, 2024 at 1:00 AM\n\n\nCambios en evaluación 1\n\n\ninfo, mail-UCursos\n\n\n\n\nlunes septiembre 2, 2024 at 1:00 AM\n\n\nEquipo docente y ayudantes\n\n\ninfo, mail-UCursos\n\n\n\n\njueves agosto 29, 2024 at 1:00 AM\n\n\nAsignación asesorías ayudantes\n\n\ninfo, mail-UCursos\n\n\n\n\nviernes agosto 23, 2024 at 1:00 AM\n\n\nSesión práctica martes 27 de agosto\n\n\ninfo, mail-UCursos\n\n\n\n\nlunes agosto 19, 2024 at 1:00 AM\n\n\nPrácticos parten próxima semana (Martes 27)\n\n\ninfo\n\n\n\n\nlunes agosto 19, 2024 at 1:00 AM\n\n\nInformaciones por acá\n\n\ninfo\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes.\n\n\n\n\n\n RSS"
  },
  {
    "objectID": "news/2024-09-04_taller_centro_idea.html",
    "href": "news/2024-09-04_taller_centro_idea.html",
    "title": "Taller Centro IDEA",
    "section": "",
    "text": "← News\n\n\n\n\nEl centro IDEA está ofreciendo una instancia de tutorías específica para la Unidad I (Inferencia) este viernes 6 de septiembre a las 12:00:"
  },
  {
    "objectID": "news/2024-09-02_equipo docente y ayudantes.html",
    "href": "news/2024-09-02_equipo docente y ayudantes.html",
    "title": "Equipo docente y ayudantes",
    "section": "",
    "text": "← News\n\n\n\n\n2 actualizaciones respecto del equipo a cargo del curso:\n\ncomo se informó por UCursos, la apoyo docente Daniela Olivares no seguirá en su rol a partir de este mes de Septiembre, y se suma al equipo Martín Venegas como nuevo apoyo docente. Martín también es sociólogo UChile y actualmente trabaja en el INE. Bienvenido!\nse completa el equipo de ayudantes luego de la segunda ronda de postulaciones, son 11 en total y pueden ver sus nombres en la página inicial del curso."
  },
  {
    "objectID": "news/2024-08-19_inicio.html",
    "href": "news/2024-08-19_inicio.html",
    "title": "Informaciones por acá",
    "section": "",
    "text": "← News\n\n\n\n\nEstimad_s estudiantes, acá en esta pestaña quedará registro de las informaciones y actualizaciones del curso. De todas maneras se enviará link por correo a UCursos cuando haya noticias relevantes."
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "content/foro-clases.html",
    "href": "content/foro-clases.html",
    "title": "Foro clases",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre los contenidos del curso vistos en clases. Para poder participar en el foro hay que abir una cuenta en Github",
    "crumbs": [
      "Clases",
      "Foro Clases"
    ]
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Asociación con variables categóricas",
    "section": "",
    "text": "Documento de presentación"
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Inferencia 5 - Prueba t + hipótesis direccionales",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 5"
    ]
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Inferencia 3 - Intervalos de confianza",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 3"
    ]
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Inferencia 1: Datos, probabilidad y distribuciones muestrales",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 1"
    ]
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Prácticos",
    "section": "",
    "text": "Las clases se acompañan de guías de trabajo con énfasis en la aplicación práctica mediante el uso de software estadístico.\nLas guías se encontrarán disponibles en esta página (link a la izquierda). Habrá dos guías para la Unidad 1 (Inferencia), y 2 para la Unidad 2 (Asociación). La unidad 3 será eminentemente práctica y de aplicación.\nLas guías son desarrolladas de manera autónoma, y cada dos semanas los días martes habrá un espacio práctico de revisión de las guías y de consultas. Para ello se espera que quienes puedan traigan su computador a la sala, y quienes no tienen lo podrán hacer simultáneamente en la sala de computación 345.\nEn las prácticas vamos a trabajar con el software R, Versión 4.4.1.",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#descripción",
    "href": "assignment/index.html#descripción",
    "title": "Prácticos",
    "section": "",
    "text": "Las clases se acompañan de guías de trabajo con énfasis en la aplicación práctica mediante el uso de software estadístico.\nLas guías se encontrarán disponibles en esta página (link a la izquierda). Habrá dos guías para la Unidad 1 (Inferencia), y 2 para la Unidad 2 (Asociación). La unidad 3 será eminentemente práctica y de aplicación.\nLas guías son desarrolladas de manera autónoma, y cada dos semanas los días martes habrá un espacio práctico de revisión de las guías y de consultas. Para ello se espera que quienes puedan traigan su computador a la sala, y quienes no tienen lo podrán hacer simultáneamente en la sala de computación 345.\nEn las prácticas vamos a trabajar con el software R, Versión 4.4.1.",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#trabajo-con-software-r",
    "href": "assignment/index.html#trabajo-con-software-r",
    "title": "Prácticos",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "href": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "title": "Prácticos",
    "section": "Sobre errores y consultas sobre problemas con R y ejecución de código",
    "text": "Sobre errores y consultas sobre problemas con R y ejecución de código\nEn caso de preguntas sobre las clases hacerlas en Foro prácticos\n\nInstalación de R & RStudio\nPara esta versión del curso vamos a trabajar con el programa R Version 4.4.1 y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://rstudio.com/products/rstudio/ y bajar/instalar RStudio desktop, Open Source License (libre).\nEn caso de dudas se puede revisar el siguiente video tutorial de instalación de R & RStudio, preparado por Julio Iturra (apoyo docente) del curso Estadística Multivariada 2020:\n\n\n\n\n\nSi por alguna razón se prefiere trabajar sin descargar, también se puede utilizar RCloud, abajo un tutorial preparado por Valentina Andrade para el curso de Estadística Multivariada:\n\n\n\n\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File &gt; New File &gt; R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File &gt; Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/foro-practicos.html",
    "href": "assignment/foro-practicos.html",
    "title": "Foro prácticos",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre llas guías prácticas. Para poder participar en el foro hay que abir una cuenta en Github\n\n¿Cuándo usar este foro?\n\n\n\n\n\nMuchas veces sucede que los códigos de análisis no resultan, lo que puede deberse a errores menores en la escritura de código, otras a versiones de librerías, y la mayoría a que R es algo mañoso.\nCuando hay un error o el código no corre lo importante es evitar que la frustración lleve a desmotivarse o tirar el computador por la ventana. Por eso se sugiere:\n\nintentar resolverlo por no más de 10 minutos: en este tiempo revisar bien el material disponible y lo que hay en la web. Un lugar clásico donde se discuten problemas de código es Stack overflow.\nsi no se logra solucionar entonces se sugiere encarecidamente usar el foro al final de esta página, ya que nos sirve para dejar la respuesta disponible para otr_s compañer_s que pueden tener la misma duda (generalmente es así)\n\n\n\n¿Cómo preguntar?\n\nDesripción general del problema, código y error que ocurre\nSi con esta información no basta para solucionar el problema, entonces se le podrá solicitar información adicionales, tales como el archivo de código y la información de la versión de las librerías que aparece al ejecutar el comando sessionInfo()\n\n\n\nForo prácticos",
    "crumbs": [
      "Prácticos",
      "Foro Prácticos"
    ]
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Presentación",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nForo\nEn caso de preguntas sobre las clases hacerlas en Foro Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Introducción"
    ]
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Inferencia 2: Curva normal y error estándar",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 2"
    ]
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Inferencia 4 - Test de hipótesis",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 4"
    ]
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Inferencia 4 - Hipótesis direccionales y proporciones",
    "section": "",
    "text": "Documento de presentación"
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Cierre",
    "section": "",
    "text": "Documento de presentación"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección se encuentran disponibles los documentos de presentación que sirven de base a cada clase, en el menú de la izquierda Presentaciones. Los documentos son en formato html (no son ppt), producidos con Xaringan. Para verlos en pantalla completa presionar F sobre el documento, y para una vista general de todas las slides presionar O.\nTambién a la izquierda hay un link al Foro para hacer preguntas relacionadas con las clases.\nCada clase tiene como referencia lecturas que deben completarse antes de la sesión correspondiente.",
    "crumbs": [
      "Clases",
      "Descripción"
    ]
  },
  {
    "objectID": "news/2024-08-19_cambio-practico.html",
    "href": "news/2024-08-19_cambio-practico.html",
    "title": "Prácticos parten próxima semana (Martes 27)",
    "section": "",
    "text": "← News\n\n\n\n\nInicialmente en el programa estaba contemplado que esta semana el martes 20 comenzaba la primera sesión de prácticos, para lo cual debían traer sus computadores. Esto se modifica, el práctico es el próximo martes 27."
  },
  {
    "objectID": "news/2024-08-23_primera-practica.html",
    "href": "news/2024-08-23_primera-practica.html",
    "title": "Sesión práctica martes 27 de agosto",
    "section": "",
    "text": "← News\n\n\n\n\nAlgunas informaciones importantes:\n-El próximo martes 27 de agosto tendremos nuestra primera sesión práctica del curso.\n-En esta instancia contaremos con el equipo docente completo y ayudantes.\n-Aquellas personas que, por diversos motivos, no puedan contar con un computador personal para las sesiones del curso, les pedimos encarecidamente que rellenen este formulario: https://forms.gle/iGVJjAWRGYh9GGpZ8 Esta información nos permitirá ir organizando el uso de computadores de la sala de computación.\n-Nos dividiremos en dos grupos: una parte del curso en las salas C7 y C8 del aulario C (idealmente quienes dispongan de computador) y otra parte en la sala 345 de computación del edificio nuevo de Facso (para quienes no puedan contar con un computador).\n-Dentro de la próxima semana les enviaremos un correo respecto a la asignación de ayudantes para el asesoramiento en las unidades 1 y 2 del curso."
  },
  {
    "objectID": "news/2024-09-03_cambios evaluacion 1.html",
    "href": "news/2024-09-03_cambios evaluacion 1.html",
    "title": "Cambios en evaluación 1",
    "section": "",
    "text": "← News\n\n\n\n\nEn el plan original la Evaluación 1 y la Evaluación 2 se componían de dos partes cada una: teórica (30%) y práctica (5%) (ver sección de evaluación en el programa del curso). Dado que en esta primera unidad ha sido principalmente teórica y tendremos solo dos instancias prácticas, vamos a traspasar el 5% de la evaluación práctica a la evaluación 2, que tendrá por lo tanto un 10% de evaluación práctica además del 30% de evaluación teórica.\nLa evaluación 1 se llevará a cabo el día Martes 10 de Septiembre a las 8:30. El día lunes 9 vamos a realizar un repaso general de la Unidad 1 y ejercicios para preparar la prueba."
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "En esta sección se irán subiendo una serie de recursos relacionados con el curso."
  },
  {
    "objectID": "resource/index.html#glosario-de-conceptos",
    "href": "resource/index.html#glosario-de-conceptos",
    "title": "Recursos",
    "section": "Glosario de conceptos",
    "text": "Glosario de conceptos\n\n\n\nConcepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final."
  },
  {
    "objectID": "resource/index.html#reporte",
    "href": "resource/index.html#reporte",
    "title": "Recursos",
    "section": "Reporte",
    "text": "Reporte\n\nTablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto"
  },
  {
    "objectID": "resource/index.html#estadística-descriptiva",
    "href": "resource/index.html#estadística-descriptiva",
    "title": "Recursos",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023"
  },
  {
    "objectID": "resource/index.html#uso-de-r",
    "href": "resource/index.html#uso-de-r",
    "title": "Recursos",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R"
  },
  {
    "objectID": "resource/index.html#inferencia",
    "href": "resource/index.html#inferencia",
    "title": "Recursos",
    "section": "Inferencia",
    "text": "Inferencia\n\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada"
  },
  {
    "objectID": "resource/index.html#visualización",
    "href": "resource/index.html#visualización",
    "title": "Recursos",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery"
  },
  {
    "objectID": "resource/index.html#bases-de-datos",
    "href": "resource/index.html#bases-de-datos",
    "title": "Recursos",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación"
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Ejercicio de inferencia\nA Ud. se le ha solicitado estimar el promedio de salarios en la población, así como también si existen diferencias salariales entre quienes han completado la educación superior en institutos técnico-profesionales (IP) y quienes lo han hecho en instituciones universitarias. Para ello se le ha proporcionado la siguiente información:\n\nDatos: Encuesta de Ingresos, muestra aleatoria N=900 casos\nPromedio salarios: 850.000, desviación estándar 300.000\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\n\nAdemás de esto, se le han proporcionado los siguientes valores para realizar inferencia estadística:\n\nvalor crítico z para el promedio con un \\(\\alpha\\) de 5% (0,05)= 1,96, y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96; y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nError estándar del promedio:\n\n\\[\\sigma_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\n\nError estándar de la diferencia de medias salariales para esta muestra= 15000\n\n\n\nCódigo\n# Generación de los datos\noptions(scipen = 999)\n\n# Establecer la semilla para garantizar la reproducibilidad\nset.seed(281217)  \n\n# Parámetros actualizados\nn &lt;- 900  # Tamaño de la muestra\npromedio_salarios &lt;- 850000;desviacion_estandar_salarios &lt;- 300000  # Desviación estándar de los salarios\n\n# Generar la muestra con la nueva semilla y parámetros\ningresos &lt;- rnorm(n, mean = promedio_salarios, sd = desviacion_estandar_salarios)",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Prof. Juan Carlos Castillo\n   325 Sociología FACSO, Universidad de Chile\n   juancastillov@uchile.cl\n   Agendar reunión\n\n\n\n\n\n   Lunes y Martes\n   12 Agosto al 29 de Noviembre, 2023\n   10:15-11:45 (Lunes) y 8:30-10:00 (Martes)\n   Lunes - Aulario C6, Martes - Aulario C7-C8 & FACSO 345\n   Slack"
  },
  {
    "objectID": "syllabus.html#sobre-el-sentido-general-del-curso",
    "href": "syllabus.html#sobre-el-sentido-general-del-curso",
    "title": "Programa",
    "section": "Sobre el sentido general del curso",
    "text": "Sobre el sentido general del curso\nEn este curso vamos a aprender tres cosas principales:\n\ninferencia: los resultados que encontramos en nuestra muestra, ¿se encuentran también en la población de la cual proviene la muestra?\nmedidas de asociación entre variables: tamaño y significación estadística\nreporte y reproducibilidad de los análisis estadísticos: nuestros análisis se reflejan en productos como tablas y gráficos. No basta con entenderlos e interpretarlos, sino también es fundamental una buena comunicación."
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico inferencial. Se espera que los estudiantes sean capaces de:\n\nelaborar de manera pertinente hipótesis estadísticas\naplicar estadísticos de asociación bivariada, a partir de los cuáles puedan desarrollar análisis de problemas sociales\ncorroborar el cumplimiento de las condiciones de aplicación de cada estadístico\nutilizar software de análisis estadístico\ncontrastar hipótesis de investigación\nelaborar conclusiones integrando fundamentos teóricos con herramientas de análisis estadístico de resultados.\n\nComplementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias",
    "href": "syllabus.html#competencias",
    "title": "Programa",
    "section": "Competencias",
    "text": "Competencias\n1a. Delimitar, conceptualizar y analizar diversos objetos de investigación social, con especial énfasis en aquellos relacionados con los procesos de transformación del país y Latinoamérica\n1b. Manejar diversas estrategias metodológicas de las ciencias sociales\n1c. Manejar un conjunto de herramientas para el procesamiento y análisis de información\n1d. Transmitir los conocimientos derivados de la práctica investigativa, así como aquellos adquiridos durante el proceso formativo."
  },
  {
    "objectID": "syllabus.html#subcompetencias",
    "href": "syllabus.html#subcompetencias",
    "title": "Programa",
    "section": "Subcompetencias",
    "text": "Subcompetencias\n\n1.4 Contribuir a generar conocimiento sociológico en el marco de estudios y/o procesos de investigación donde se articulen creativamente las dimensiones teórica, metodológica y práctica.\n1.5 Comunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#resultados-del-aprendizaje",
    "href": "syllabus.html#resultados-del-aprendizaje",
    "title": "Programa",
    "section": "Resultados del aprendizaje",
    "text": "Resultados del aprendizaje\n\nComprende, domina y es capaz de explicar los elementos conceptuales subyacentes a la determinación de la asociación poblacional entre dos variables a partir del análisis de una muestra, y es capaz de traducir hipótesis derivadas de la teoría sociológica en hipótesis estadísticas posibles de contrastar empíricamente con los datos.\nEs capaz de seleccionar y usar herramientas estadísticas adecuadas para evaluar la asociación entre dos variables considerando las características de los datos y las condiciones de aplicación de cada técnica.\nLogra interpretar desde un punto de vista estadístico y sociológico los resultados derivados de pruebas estadísticas para analizar la relación entre dos variables.\nEs capaz de reportar y comunicar adecuada y eficientemente los resultados de los análisis estadísticos"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / Contenidos",
    "text": "Saberes / Contenidos\n\nUnidad I: Inferencia\n\nDatos, variables y probabilidad\nCurva normal y error estándar\nIntervalos de confianza\nTest de hipótesis\nHipótesis no direccionales y para proporciones\n\n\n\nUnidad II: Asociación\n\nAsociación y covarianza\nCorrelación de Pearson\nCorrelación con variables ordinales\nMatrices y tamaños de efecto en correlación\nAsociación con variables categóricas\n\n\n\nUnidad III: Reporte\n\nResponder problemas de investigación de lógica bivariada con datos reales\nEscritura de reportes de investigación\nVisualización de datos\nPresentación de resultados"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\n\nSesiones de clases lectivas presenciales semanales, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana.\nPrácticos: los temas del curso se acompañan de guías prácticas de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma, y también habrá espacio de revisión y consultas en el espacio de clases.\nTrabajos: se desarrollarán trabajos de investigación que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados por ayudantes que se asignarán a cada grupo.\n\nEl semestre comienza con clases lectivas, y posteriormente se integran elementos prácticos y de aplicación.\n\nLas clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Clases, y están desarrollados con base en Rmarkdown/Xaringan. Estos documentos no son:\n\n“la clase”\nautoexplicativos (ni aspiran a serlo)\n“el ppt” (ni menos “la ppt”)"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nEl curso tendrá tres instancias de evaluación (actualizado):\n\nEvaluación 1: Inferencia (30%, teórico)\nEvaluación 2: Asociación (40% = 30% teórico + 10% práctico)\nEvaluación 3: Reporte de aplicación - trabajo grupal (30%= 20% reporte escrito + 10% poster)\n\nLa nota ponderada de las evaluaciones equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\nLas evaluaciones se distribuyen en el semestre de la siguiente manera:\n\n\n\n\n\n\n\nATENCIÓN\n\n\n\nLas fechas de evaluación no se cambian por respeto a la planificación de los tiempos de tod_s quienes participan en el curso y el cumplimiento apropiado de los objetivos de aprendizaje.\n\n\n\n\n\n\n\n\nSobre las pruebas\n\n\n\n\nLas evaluaciones de las unidades 1 y 2 son en la sala de clases y se realizan de manera individual.\nHay preguntas sobre conceptos, y principalmente cálculos e interpretación\nEntra toda la materia de la unidad, lo visto en clase y los textos obligatorios.\nTodo lo que se requiere para realizar los ejercicios de la prueba está en la prueba, no requiere aprenderse las fórmulas de memoria ni tampoco valores específicos (ej: valores críticos de rechazo)\nLa prueba comenzará puntual, no se puede ingresar ni salir de la sala una vez comenzada la evaluación.\nSi alguien tiene alguna emergencia y necesita salir podrá contar con la compañía y apoyo de algun_ de l_s ayudantes en sala."
  },
  {
    "objectID": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "href": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "title": "Programa",
    "section": "Inasistencias y atraso en entregas",
    "text": "Inasistencias y atraso en entregas\nLos justificativos por ausencia o atraso se realizan en la secretaría de carrera. Lo que la carrera informe como justificado, es lo que se va a considerar en el curso. No enviar justificativos a equipo docente y a ayudantes directamente, no es necesario ni apropiado para l_s estudiantes tener que exponer situaciones personales.\nEn caso de faltar a alguna de las evaluaciones existirá una única fecha para evaluaciones recuperativas. Si en esa fecha no es posible asistir por motivos justificados, entonces pasará directo a examen.\nEn el caso de los trabajos, en caso de atraso se descontará 0.5 por día adicional. Si el trabajo no se entrega luego del tercer día de atraso será calificado con nota 1.0"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\nRequisitos de eximición a examen:\n\ncontar con un promedio ponderado igual o superior a 5.5\nno tener nota bajo 4.0 en ninguna de las evaluaciones\n\nRequisitos para presentación a examen:\n\nPodrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\nEl examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0."
  },
  {
    "objectID": "syllabus.html#bibliografía-obligatoria",
    "href": "syllabus.html#bibliografía-obligatoria",
    "title": "Programa",
    "section": "Bibliografía Obligatoria",
    "text": "Bibliografía Obligatoria\nCapítulos correspondientes a cada sesión de los siguientes textos principales:\n\nRitchey, F. (2008) Estadística para las ciencias sociales. McGraw-Hill: México.\nMoore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch.\nPardo, Ruiz y San Martín (2015). Análisis de Datos en Ciencias Sociales y de la Salud I. Editorial Síntesis: Madrid."
  },
  {
    "objectID": "syllabus.html#bibliografía-complementaria",
    "href": "syllabus.html#bibliografía-complementaria",
    "title": "Programa",
    "section": "Bibliografía Complementaria",
    "text": "Bibliografía Complementaria\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly.\nField, A., Milles, J., & Field, Z. (2012). Discovering statistics using R. London: Sage.\nSalkind, N. J. (Ed.). (2010). Encyclopedia of research design (Vol. 1). Sage.\nLevin, J. & Levin, W. (1997). Fundamentos de Estadística en la Investigación Social (Vol.2). Oxford University Press."
  },
  {
    "objectID": "syllabus.html#sobre-participación-y-comunicación",
    "href": "syllabus.html#sobre-participación-y-comunicación",
    "title": "Programa",
    "section": "Sobre participación y comunicación",
    "text": "Sobre participación y comunicación\n\nSe espera asistencia y participación activa, tanto a las sesiones lectivas como a las prácticas. Se pasará lista en todas las sesiones. No habrá penalización por inasistencia, pero si llevaremos registro principalmente con objetivos de monitoreo y retroalimentación del curso.\nInformar flexibilidades académicas al principio del semestre (en caso que la jefatura de carrera no lo haga de manera centralizada). Las flexibilidades academicas no aplican para cambios de fechas de evaluaciones grupales.\nSe espera y enfatiza la participación activa por distintos canales disponibles. Estos son:\n\ncontacto por correo con equipo docente del curso (profesor y apoyos docentes)\nespacio para resolver dudas individualmente al final de la clase\nreuniones con equipo docente, para lo cual se deben inscribir previamente en la página inicial de este sitio\nforos, disponibles tanto para las clases como para los prácticos.\nmentorías con ayudantes asignados\n\nTambién se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”, que si bien puede intentar transmitir cercanía finalmente expresan minimización de la contraparte. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo están siendo, se solicita reportar para solucionar la situación.\nNo se responderán mensajes fuera del horario laboral (incluyendo por supuesto fines de semana)."
  },
  {
    "objectID": "syllabus.html#programación-de-sesiones",
    "href": "syllabus.html#programación-de-sesiones",
    "title": "Programa",
    "section": "Programación de sesiones",
    "text": "Programación de sesiones\nVisitar la página de Planificación."
  },
  {
    "objectID": "news/2024-08-28_asignacion_ayudantes1.html",
    "href": "news/2024-08-28_asignacion_ayudantes1.html",
    "title": "Asignación asesorías ayudantes",
    "section": "",
    "text": "← News\n\n\n\n\nDurante las dos primeras unidades del curso l_s estudiantes están asignados a un/a ayudante para consultas y/o apoyo con los contenidos del curso. Sus ayudantes se contactarán con uds. para indicarles la forma y momentos de asesoría, también pueden ser contactados directamente mediante el correo de UCursos.\n\n\n\n\n\nAyudante\nEstudiante\n\n\n\n\nAntonia Jiménez F.\nAlarcón Riveros, Milen Valentina\n\n\n\nArriagada Rodríguez, Javiera Ignacia\n\n\n\nCelpa Bugueño, Álvaro Giovanni\n\n\n\nDíaz Devia, Eduardo Ignacio\n\n\n\nHernández Osses, Antonia Margarita\n\n\n\nHuerta Carrasco, Rodrigo Javier\n\n\n\nKovacevic Ardiles, Ruby Mladenka\n\n\n\nNavarro Sánchez, Camila Alexandra\n\n\n\nPadilla Maureira, Belén Monserrat\n\n\n\nZanca Garrido, Andrés Ignacio\n\n\nCristóbal Mejías G.\nAntil Contreras, Ana Paula\n\n\n\nBeroíza Aguilar, Benjamín Daniel David\n\n\n\nFuentes Fernández, Víctor Javier\n\n\n\nOlmos Jara, Vicente Martín\n\n\n\nRaccagni Mancilla, Matilda Isidora\n\n\n\nRendic Gomez, Andres Nicolas\n\n\n\nVásquez Campos, Fernanda María José\n\n\n\nVega Villanueva, Martina Alejandra\n\n\nFernanda Zúñiga M.\nÁlvarez Cárdenas, Javiera Ignacia\n\n\n\nCastro Rojas, Joel Wilson\n\n\n\nDuclos González, Gaspar\n\n\n\nFaúndez Ramírez, Jennifer Paola\n\n\n\nGonzález Núñez, Bastián Antonio\n\n\n\nGuzmán Reyes, Pablo Antonio\n\n\n\nMontecinos Quintanilla, Valentina Antonia\n\n\n\nSantos Chavarría, Catalina Paz\n\n\nIsmael Aguayo\nBustos Pérez, Benjamín Alfredo\n\n\n\nCastillo Rojas, Anahi Constanza\n\n\n\nChateau Vives, Manuela\n\n\n\nMaldonado Acevedo, Agustín Eduardo\n\n\n\nMorales Verdugo, Javiera Catalina\n\n\n\nRivera Valenzuela, Luis Felipe\n\n\n\nSalas Aguilar, Maximiliano Alonso\n\n\n\nThumala Raposo, Daniel\n\n\n\nTsukame Díaz, Amalia Victoria\n\n\nJaviera González\nBuzio Aranda, Martina Javiera\n\n\n\nCantillana Olave, Muriel Noelia\n\n\n\nFerrel Higuera, Benjamin Tomas Alexandre\n\n\n\nFigueroa Tengner, Nino\n\n\n\nMancilla Chaparro, Benjamín Patricio\n\n\n\nMansilla Fuentes, Violeta Del Rosario\n\n\n\nOuterbridge Ortega, Nicolás Eduardo\n\n\n\nRojas Murúa, Vicente Ignacio de Jesús\n\n\n\nRojas Santander, Matías Nicolás\n\n\n\nVillatoro Cepeda, Martina Alejandra\n\n\nJesús Díaz M.\nArias Acuña, Antonio Domingo\n\n\n\nConsuegra Erazo, Lucas Andrés\n\n\n\nJiménez Miranda, Constanza María\n\n\n\nJiménez Morales, Rosita Monserrat\n\n\n\nJullian Corral, Maite Ayelen\n\n\n\nMuñoz Caniuqueo, Ignacio Benjamín\n\n\n\nOsorio Huerta, Francisca Andrea\n\n\n\nPlaza Spate, Cristóbal Ignacio\n\n\n\nVenegas Moya, Alonso Elessar\n\n\nLuis Rios\nBalmaceda Yankovic, Bianca\n\n\n\nCaballero Salazar, Amador\n\n\n\nCanales Llanquitrú, Carla Jacqueline\n\n\n\nGaete Morgado, Paulina Andrea\n\n\n\nGatica Pailacura, Carolina Paz\n\n\n\nMartin Gerdes, Bastián Javier\n\n\n\nMena Rojas, Martín Elías\n\n\n\nValencia Almendras, Isidora Paz\n\n\n\nVásquez Olivares, Catalina Ignacia\n\n\nMaría Fernanda Núñez G.\nCalderón Guajardo, Elisa Amanda\n\n\n\nFlores Fuentes, Matías Gabriel\n\n\n\nGallo Novoa, Emilia Antonia\n\n\n\nLagos Zúñiga, Martina Jacinta\n\n\n\nLatorre González, Camila Ignacia\n\n\n\nPoblete Duarte, José Patricio\n\n\n\nRoa Neira, Carla Denisse\n\n\n\nSilva Díaz, Catalina Rosario\n\n\n\nVargas Olivares, Andrés Ignacio\n\n\nSophia Karoussis P.\nBascuñán Soto, Marta del Carmen\n\n\n\nBerríos Puentes, Rocío Belén\n\n\n\nFerran Villagra, Catalina Sofía\n\n\n\nGuerrero Tapia, Daniela Sofía\n\n\n\nPalma Valladares, Elisa Victoria\n\n\n\nPeña Gaete, Micaela Fabiana\n\n\n\nRobledo Dávila, Martina Elisa\n\n\n\nSuárez Urbina, Rocío Belén\n\n\n\nVega Gandolfo, Felipe Ignacio\n\n\nVictoria Arias O.\nCanales Calderón, Fernanda Paz\n\n\n\nCarrasco Gomberoff, Benjamín Eitan\n\n\n\nIbarra Domínguez, Asunción Rebeca\n\n\n\nIsla Hernández, Paz Magdalena\n\n\n\nNúñez Pérez, Joaquín Emilio\n\n\n\nReyes Aqueveque, Valeria Patricia\n\n\n\nRivera Sepúlveda, Sofía Belén\n\n\n\nSanta Cruz Claro, Amalia Magdalena\n\n\n\nSoto Ortega, Martina Paz\n\n\n\n\n\n\n\nPor dudas, comentarios o cambios respecto a esta asignación escribir a Andreas Laffert (Apoyo Docente) por UCursos."
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#compliance-and-treatment-effects",
    "href": "example/cace.html#compliance-and-treatment-effects",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets &lt;- read_csv(\"data/bed_nets_observed.csv\") %&gt;%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine &lt;- read_csv(\"data/bed_nets_time_machine.csv\") %&gt;%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model &lt;- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT &lt;- tidy(itt_model) %&gt;%\n  filter(term == \"treatmentTreatment\") %&gt;%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %&gt;%\n  group_by(treatment, bed_net) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   &lt;chr&gt;     &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c &lt;- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE &lt;- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls &lt;- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "assignment/01-practico.html",
    "href": "assignment/01-practico.html",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducirnos en la inferencia estadística, revisando los conceptos y aplicaciones de la curva normal y las probabilidades bajo esta con puntajes Z, además del cálculo de intervalos de confianza.\nEn detalle, aprenderemos y recordaremos:\n\nLos conceptos de promedio y desviación estándar\nQué es la probabilidad y su aplicación para estadística\nQué es la distribución normal\nCómo calcular e interpretar intervalos de confianza\n\n\n\nCargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\nlibrary(pacman)\npacman::p_load(tidyverse, # para sintaxis\n               ggplot2,   # para gráficos\n               car,       # para recodificar\n               psych,     # para analizar datos\n               sjmisc,    # para analizar datos\n               srvyr,     # para estimación de IC y ponderadores\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpar el entonrno de trabajo",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#librerías",
    "href": "assignment/01-practico.html#librerías",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "Cargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\nlibrary(pacman)\npacman::p_load(tidyverse, # para sintaxis\n               ggplot2,   # para gráficos\n               car,       # para recodificar\n               psych,     # para analizar datos\n               sjmisc,    # para analizar datos\n               srvyr,     # para estimación de IC y ponderadores\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpar el entonrno de trabajo",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#curvas-de-distribución",
    "href": "assignment/01-practico.html#curvas-de-distribución",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Curvas de distribución",
    "text": "3.1. Curvas de distribución\nPor distribución nos referimos al conjunto de todos los valores posibles de una variable y las frecuencias (o probabilidades) con las que se producen.\nExisten distribuciones empíricas y distribuciones teóricas, en donde:\n\nlas primeras reflejan la distribución de los valores que asume la variable en un grupo concreto a partir de una observación.\nlas segundas son una función matématica que expresan la distribución de un conjunto de números mediante su probabilidad de ocurencia.\n\nEstas últimas son también llamadas curvas de distribución.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-1",
    "href": "assignment/01-practico.html#distribución-normal-1",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.2. Distribución Normal",
    "text": "3.2. Distribución Normal\nEs una distribución teórica que corresponde a una curva que representa la distribución de los casos de la población en torno al promedio y con una varianza conocida.\n\nSimétricas y con un solo punto de elevación\nLa pendiente es más fuerte cerca del centro, y se suaviza hacia los extremos\nCoinciden al centro el promedio, la mediana y la moda\nLa desviación estandar expresa su dispersión.\nEstablece áreas o proporciones bajo la curva en base a desviaciones estándar del promedio.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-estándar",
    "href": "assignment/01-practico.html#distribución-normal-estándar",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.3. Distribución Normal Estándar",
    "text": "3.3. Distribución Normal Estándar\nLa distribución normal estándar es una distribución normal con una media de 0 y una desviación estándar de 1.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "href": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.4. Puntaje Z y estandarización de variables",
    "text": "3.4. Puntaje Z y estandarización de variables\nAl estandarizar las variables (como en la Curva Normal Estándar) lo que hacemos es expresar el valor de una distribución en términos de desviaciones estándar basados en la distribución normal. Esto nos permite comparar distribuciones distintas.\nAl valor estandarizado lo llamamos puntaje Z, y corresponde a la cantidad de desviaciones estándar que nos alejamos del promedio (para cada variable con la que trabajemos).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "href": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.5. Cálculo de probabilidades con puntaje z",
    "text": "3.5. Cálculo de probabilidades con puntaje z\nLos valores estandarizados o puntajes Z además nos permiten conocer probabilidades.\nCon R es posible generar un conjunto de datos simulados con una distribución normal.\n\nx_values &lt;- seq(-4,4,length=1000)\ny_values &lt;- dnorm(x_values)\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\n\n\n\n\n\n\n\n\nPodemos preguntar qué parte de la curva cae por debajo de un valor particular. Por ejemplo, preguntaremos sobre el valor 0 antes de ejecutar el código. Piense ¿cuál debería ser la respuesta?\n\npnorm(q = 0)\n\n[1] 0.5\n\n\nPor tanto, la probabilidad (en una curva normal estándar) de obtener un valor igual o menor a 0 es de 0.5, es decir, del 50%, pero ¿por qué?\n\nPorque como la distribución normal estándar es simétrica al rededor de cero, la probabilidad de que sea menor o igual a cero es 0.5, es decir, el 50% de la distribución está por debajo de cero y el otro 50% está por encima de cero.\n\nEso lo podemos ver en el gráfico:\n\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\nabline(v=0)\n\n\n\n\n\n\n\n\nAhora probemos los valores Z de +1,96 y -1,96.\nSabemos que estos valores aproximados marcan el 2,5% superior e inferior de la distribución normal estándar. Esto corresponde a un alfa típico \\(\\alpha = 0,05\\) para una prueba de hipótesis de dos colas.\n\npnorm(q = 1.96, lower.tail=TRUE)\n\n[1] 0.9750021\n\n\nLa respuesta nos dice lo que ya sabemos: el 97,5% de la distribución normal ocurre por debajo del valor z de 1,96.\nPodemos agregar una línea al gráfico para mostrar dónde se usaría abline.\nEl 97,5% de la distribución queda por debajo de esta línea.\n\nplot(x_values, y_values, type=\"l\", lty=1, xlab=\"Z value\", ylab=\"Probability\", main=\"Normal Distribution\") +\nabline(v = 1.96)\n\n\n\n\n\n\n\n\ninteger(0)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "href": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "4.1. Cálculo de intervalos de confianza",
    "text": "4.1. Cálculo de intervalos de confianza\nEn el caso de nuestro vector aleatorio, un intervalo de confianza para la media se puede calcular de la siguiente manera:\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1] 4.818567 5.543057\nattr(,\"conf.level\")\n[1] 0.95\n\n\nTambién podemos calcular intervalos de confianza para casos reales. Carguemos la base de datos que utilizaremos, que corresponde a un subset de la Encuesta Suplementaria de ingresos ESI para ocupados:\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/esi-2021-ocupados.rdata\"))\n\n\n\n\n\n\n\nNota\n\n\n\nRecordemos que podemos contar con bases de datos que tengan factor de expansión (ponderador) o no. Esta distinción se presenta cuando trabajamos con muestras simples o complejas. Al trabajar con muestras complejas debemos identificar cuál es la variable del ponderador e incorporarla en nuestro cálculo.\nEn esta guía practicaa trabajaremos sin factores de expansión o ponderadores.\n\n\n\nIC para Medias\nCalculemos un intervalo de confianza para la media de ingresos de personas ocupadas:\n\npsych::describe(esi$ing_t_p)\n\n   vars     n     mean       sd   median  trimmed      mad min      max\nX1    1 37124 586360.4 697362.9 405347.7 474473.1 255411.6   0 38206253\n      range skew kurtosis      se\nX1 38206253   12   402.32 3619.36\n\n\n\nPublish::ci.mean(esi$ing_t_p, alpha = 0.05)\n\n mean      CI-95%               \n 586360.41 [579266.37;593454.45]\n\n\nContamos con una media de ingresos de $586.360 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre $579.266 y $593.454.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  }
]