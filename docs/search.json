[
  {
    "objectID": "assignment/07-practico.html",
    "href": "assignment/07-practico.html",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducir a la visualización de datos con R en documentos dinámicos mediante Quarto, considerando las mejores prácticas para comunicar datos y análisis en ciencias sociales.\nEn detalle, aprenderemos:\n\nQué es la visualización de datos y cómo comunicarlos a una audiencia de manera eficiente, completa e insesgada.\nVisualizar datos bivariados con diferentes librerías, pero principalmente con ggplot2.\n\n\n\n\n\n\n\nNota\n\n\n\nSi quieres profundizar cómo generar gráficos univariados, visita este práctico de estadística descriptiva 2023.\n\n\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018.\n\n\n\nPara recordar cómo generar un archivo en Quarto, visitar el práctico 6 del curso.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "7: Gráficos bivariados en reportes dinámicos"
    ]
  },
  {
    "objectID": "assignment/07-practico.html#recursos-de-la-práctica",
    "href": "assignment/07-practico.html#recursos-de-la-práctica",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "7: Gráficos bivariados en reportes dinámicos"
    ]
  },
  {
    "objectID": "assignment/07-practico.html#crear-un-documento-quarto",
    "href": "assignment/07-practico.html#crear-un-documento-quarto",
    "title": "Práctico 7: Gráficos bivariados en reportes dinámicos",
    "section": "",
    "text": "Para recordar cómo generar un archivo en Quarto, visitar el práctico 6 del curso.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "7: Gráficos bivariados en reportes dinámicos"
    ]
  },
  {
    "objectID": "assignment/04-practico.html",
    "href": "assignment/04-practico.html",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "",
    "text": "El objetivo de esta guía práctica es conocer maneras de reportar coeficientes de correlación y otras medidas de correlación para variables ordinales. Además, nos introduciremos en el tratamiento de valores perdidos y generación de índices. Todo ello a partir de una pregunta de investigación empírica.\nEn detalle, aprenderemos a:\n\nEstimar e interpretar coeficientes de correlación de Spearman y Kendall\nGenerar y reportar matrices de correlación\nTratamiento de casos perdidos\nAnalizar baterías de indicadores y generar índices\n\nEn esta guía utilizaremos un ejemplo que desarrollaremos progresivamente para exponer los contenidos. Al final de esta guía se proporciona un ejercicio autónomo que deberá resolver de manera individual o grupal tomando como referencia el ejemplo aquí expuesto.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#recursos-de-la-práctica",
    "href": "assignment/04-practico.html#recursos-de-la-práctica",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuesta del Módulo de Desigualdad Social de la International Social Survey Programme (ISSP) para Chile del año 2009. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ISSP Chile 2009. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ISSP 2009 para Chile.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "href": "assignment/04-practico.html#correlación-para-variables-ordinales",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.1 Correlación para variables ordinales",
    "text": "3.1 Correlación para variables ordinales\n\n3.1.1 Coeficiente de correlación de Spearman\nCuando queremos conocer la asociación entre variables que son ordinales y/o cuando nuestras variables no cumplen con los supuestos de distribución normal, podemos utilizar la correlación de Spearman.\n\nEmplea rangos en lugar de valores numéricos para evaluar la relación.\nEs alta cuando las observaciones tienen un ranking similar.\n\nEn R calcularlo es sencillo, pero debemos tener en cuenta que las variables que relacionemos tengan un orden de rango similar: por ejemplo, que el valor más bajo sea el rango más bajo y que el valor más alto sea el rango más alto.\nObservemos las frecuencias de las variables conflict_rp (conflictos ricos-pobres) y perc_ineq (percepción desigualdad)\n\nsjmisc::frq(proc_issp$conflict_rp)\n\nConflictos: ricos - pobres (x) &lt;numeric&gt; \n# total N=1505 valid N=1438 mean=2.61 sd=0.87\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 | 161 | 10.70 |   11.20 |  11.20\n    2 | 442 | 29.37 |   30.74 |  41.93\n    3 | 627 | 41.66 |   43.60 |  85.54\n    4 | 208 | 13.82 |   14.46 | 100.00\n &lt;NA&gt; |  67 |  4.45 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_issp$perc_ineq)\n\nPercepción desigualdad (x) &lt;numeric&gt; \n# total N=1505 valid N=1492 mean=4.19 sd=0.83\n\nValue |   N | Raw % | Valid % | Cum. %\n--------------------------------------\n    1 |  16 |  1.06 |    1.07 |   1.07\n    2 |  65 |  4.32 |    4.36 |   5.43\n    3 | 105 |  6.98 |    7.04 |  12.47\n    4 | 742 | 49.30 |   49.73 |  62.20\n    5 | 564 | 37.48 |   37.80 | 100.00\n &lt;NA&gt; |  13 |  0.86 |    &lt;NA&gt; |   &lt;NA&gt;\n\n\nAhora, calculemos el coeficiente de correlación de Spearman con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"spearman\") #especificamos metodo spearman\n\n\n    Spearman's rank correlation rho\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nS = 430911455, p-value = 0.000008055\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.1176912 \n\n\nAhora conocemos el valor del coeficiente de Spearman mediante al argumento rho, que es igual a 0.12, siendo positivo y pequeño según los criterios de Cohen (1988).\n\n\n3.1.2 Coeficiente de correlación Tau de Kendall\nRecomendado cuando hay un set de datos pequeños y/o cuando hay mucha repetición de observaciones en el mismo ranking. Se basa en una comparación de pares de observaciones concordantes y discordantes.\nAhora, calculemos el coeficiente de correlación Tau de Kendall con cor.test.\n\ncor.test(proc_issp$conflict_rp, proc_issp$perc_ineq, method = \"kendall\") #especificamos metodo kendall\n\n\n    Kendall's rank correlation tau\n\ndata:  proc_issp$conflict_rp and proc_issp$perc_ineq\nz = 4.4558, p-value = 0.000008358\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.1043735 \n\n\nEl valor del coeficiente de Kendall mediante al argumento tau, es igual a 0.1, siendo positivo y muy pequeño según los criterios de Cohen (1988).\n¿PERO QUÉ HACER CON LOS CASOS PÉRDIDOS?",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "href": "assignment/04-practico.html#tratamiento-de-casos-perdidos",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.2 Tratamiento de casos perdidos",
    "text": "3.2 Tratamiento de casos perdidos\nTrabajar con datos a menudo implica enfrentar valores perdidos (NA), lo que puede ser un gran desafío. Estos valores indican la ausencia de un valor en una base de datos. Los valores perdidos pueden originarse por diversas razones, como el sesgo de no respuesta en encuestas, errores en la entrada de datos o simplemente la falta de información para ciertas variables.\n\n\n\n\n\n\nX1\nX2\nX3\nX4\n\n\n\n\nNA\n4\n1\nHola\n\n\n7\n1\n4\nNo soy un NA\n\n\n8\nNA\n2\nNA\n\n\n9\nNA\n9\nAmo R\n\n\n3\n3\n6\nNA\n\n\n\n\n\n\n\n\nLa presencia de valores perdidos puede tener un impacto considerable en la precisión y confiabilidad de los análisis estadísticos, lo que a su vez puede conducir a resultados sesgados y conclusiones incorrectas.\nExisten varias formas de tratar valores perdidos, que van desde enfoques simples hasta métodos más complejos, como la imputación. En esta ocasión, nos centraremos en las dos estrategias más comunes:\n\ntrabajar exclusivamente con casos completos (listwise) o\nretener los casos con valores perdidos, pero excluyéndolos al calcular estadísticas (pairwise).\n\n\n3.2.1 Analísis con casos completos: listwise deletion\nEste enfoque es uno de los más conocidos: implica remover completamente las observaciones que tienen valores perdidos en cualquier variable de interés. En otras palabras, si una fila/caso en un conjunto de datos tiene al menos un valor faltante en alguna de las variables que estás considerando, se eliminará por completo.\nEn R, esto podemos hacerlo con la función na.omit. Para hacer esto, sigamos estos pasos:\n\nrespaldar la base de datos original en el espacio de trabajo (por si queremos en adelante realizar algún análisis referido a casos perdidos)\ncontamos el número de casos con el comando dim.\ncontamos cuántos y en dónde tenemos casos perdidos.\nborramos los casos perdidos con na.omit.\ncontamos nuevamente con dim para asegurarnos que se borraron.\n\n\nproc_issp_original &lt;- proc_issp\ndim(proc_issp)\n\n[1] 1505    7\n\n\n\nsum(is.na(proc_issp))\n\n[1] 730\n\n\n\ncolSums(is.na(proc_issp))\n\n      educyrs        income     perc_ineq   conflict_rp conflict_wcmc \n           54           359            13            67            79 \n  conflict_mw   conflict_tb \n           78            80 \n\n\n\nproc_issp &lt;- na.omit(proc_issp)\ndim(proc_issp)\n\n[1] 1025    7\n\n\nAhora nos quedamos con 1021 observaciones sin casos perdidos.\nAunque simple de implementar, con este enfoque podemos perder información importante, especialmente si los valores perdidos no se distribuyen aleatoriamente.\n\nSiempre hay que intentar rescatar la mayor cantidad de casos posibles. Por lo tanto, si un listwise genera más de un 10% de casos perdidos se debe detectar qué variables esta produciendo esta pérdida e intentar recuperar datos. Puedes revisar un ejemplo aquí.\n\n\n\n3.2.2 Retener pero excluir: pairwise deletion\nA diferencia del anterior, este es un enfoque en el que las observaciones se utilizan para el análisis siempre que tengan datos disponibles para las variables específicas que se están analizando. En lugar de eliminar toda una fila si falta un valor, se eliminan solo los valores faltantes en las variables que se están analizando en ese momento.\nPara hacer esto en R debemos siempre verificar e indicar en nuestro código si queremos (o no) remover los NA para realizar los análisis.\n\nmean(proc_issp_original$conflict_rp); mean(proc_issp_original$perc_ineq)\n\n[1] NA\n\n\n[1] NA\n\nmean(proc_issp_original$conflict_rp, na.rm = TRUE); mean(proc_issp_original$perc_ineq, na.rm = TRUE)\n\n[1] 2.613352\n\n\n[1] 4.188338\n\n\nCon el primer código no obtuvimos información sustantiva en ciertas variables, pero con el segundo sí al remover los NA solo de dicha variable para un cálculo determinado.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#matrices-de-correlación",
    "href": "assignment/04-practico.html#matrices-de-correlación",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.3 Matrices de correlación",
    "text": "3.3 Matrices de correlación\nLa correlación es una estimación de asociación de dos variables. Sin embargo, en los análisis de bases de datos usualmente se exploran asociaciones entre múltiples pares de variables, lo que genera una matriz de correlación. En una matriz, las variables se presentan en las filas y las columnas, y en las celdas donde se cruzan los pares de variables se muestra su coeficiente de correlación.\nEn su forma simple en R se aplica la función cor a la base de datos, y la guardamos en un objeto que le damos el nombre M para futuras operaciones:\n\nM &lt;- cor(proc_issp_original, use = \"complete.obs\") \nM\n\n                   educyrs       income   perc_ineq conflict_rp conflict_wcmc\neducyrs        1.000000000  0.432514770  0.05504904 -0.08841474   -0.13352776\nincome         0.432514770  1.000000000  0.05477385 -0.06418553   -0.12973731\nperc_ineq      0.055049043  0.054773853  1.00000000  0.06824227   -0.02485978\nconflict_rp   -0.088414736 -0.064185525  0.06824227  1.00000000    0.50032361\nconflict_wcmc -0.133527759 -0.129737308 -0.02485978  0.50032361    1.00000000\nconflict_mw   -0.002602596 -0.009135604  0.09567990  0.49448964    0.44732312\nconflict_tb   -0.021292335 -0.008221726  0.09164984  0.66745078    0.41433338\n               conflict_mw  conflict_tb\neducyrs       -0.002602596 -0.021292335\nincome        -0.009135604 -0.008221726\nperc_ineq      0.095679896  0.091649843\nconflict_rp    0.494489639  0.667450775\nconflict_wcmc  0.447323122  0.414333385\nconflict_mw    1.000000000  0.524006738\nconflict_tb    0.524006738  1.000000000\n\n\nEste es el reporte simple, pero no muy amigable a la vista. Para una versión más reportable, utilizamos la funcion tab_corr.\n\nsjPlot::tab_corr(proc_issp_original, \n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nNivel educativo\nDecil ingreso\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nNivel educativo\n \n \n \n \n \n \n \n\n\nDecil ingreso\n0.433***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n0.055\n0.055\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.088**\n-0.064*\n0.068*\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n-0.134***\n-0.130***\n-0.025\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.003\n-0.009\n0.096**\n0.494***\n0.447***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.021\n-0.008\n0.092**\n0.667***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLa distinción entre listwise y pairwise es relevante al momento de estimar matricies de correlación, donde esta decisión debe estar claramente explicitada y fundamentada. En ejemplo de tabla anterior usamos listwise que es el argumento por defecto (y nos lo indica al final de la tabla).\nVeamos como hacerlo con pairwise:\n\nsjPlot::tab_corr(proc_issp_original, \n                 na.deletion = \"pairwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n \nNivel educativo\nDecil ingreso\nPercepción desigualdad\nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nNivel educativo\n \n \n \n \n \n \n \n\n\nDecil ingreso\n0.429***\n \n \n \n \n \n \n\n\nPercepción desigualdad\n0.057*\n0.041\n \n \n \n \n \n\n\nConflictos: ricos - pobres\n-0.068*\n-0.057\n0.087***\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n-0.139***\n-0.122***\n-0.025\n0.518***\n \n \n \n\n\nConflictos: directivos - trabajadores\n-0.016\n-0.005\n0.100***\n0.499***\n0.438***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n-0.037\n0.007\n0.089***\n0.651***\n0.441***\n0.527***\n \n\n\nComputed correlation used pearson-method with pairwise-deletion.\n\n\n\n\n\nCon esta mejor visualización, algunas observaciones sobre la matriz de correlaciones:\n\nEn esta matriz las variables están representadas en las filas y en las columnas.\nCada coeficiente expresa la correlación de una variable con otra. Por ejemplo, la correlación entre la variable de educyrs y income es 0.43.\nLa información de cada coeficiente se repite sobre y bajo la diagonal, ya que es el mismo par de variables pero en el orden alterno. Por convención en general se omiten las correlaciones redundantes sobre la diagonal, por eso aparece en blanco.\nEn la diagonal corresponde que todos los coeficientes sean 1, ya que la correlación de una variable consigo misma es perfectamente positiva.\n\nOtra manera de presentar matrices de correlación es mediante gráficos. Veamos un ejemplo con la función corrplot de la librería corrplot sobre nuestra matriz M ya creada.\n\ndiag(M) &lt;- NA\ncorrplot::corrplot(M,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"#0D0887\"))(12),\n                   bg = \"white\",\n                   na.label = \"-\")",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/04-practico.html#baterías-e-índices",
    "href": "assignment/04-practico.html#baterías-e-índices",
    "title": "Práctico 4: Matrices de correlación, casos pérdidos e índices",
    "section": "3.4 Baterías e índices",
    "text": "3.4 Baterías e índices\nEn la literatura sobre percepción de conflictos se suele utilizar un índice sumativo o promedio entre los distintos indicadores sobre conflictos percibidos: conflict_rp,conflict_wcmc,conflict_mw,conflict_tb.\nEntonces, para poder responder nuestras preguntas de investigación, primero generaremos una matriz de correlaciones entre estos indicadores, luego evaluaremos su consistencia y generaremos el índice psci. Finalmente, realizaremos un test de correlación para examinar la asociación entre psci y perc_ineq.\n\nM_psci &lt;- proc_issp %&gt;% \n  dplyr::select(starts_with(\"conflict\"))\n\nsjPlot::tab_corr(M_psci, \n                 na.deletion = \"listwise\", # espeficicamos tratamiento NA\n                 triangle = \"lower\")\n\n\n\n\n\n\n\n\n\n\n\n \nConflictos: ricos - pobres\nConflictos: clase trabajadora - clase\nmedia\nConflictos: directivos - trabajadores\nConflictos: gente de arriba - gente de\nabajo\n\n\nConflictos: ricos - pobres\n \n \n \n \n\n\nConflictos: clase trabajadora - clase\nmedia\n0.500***\n \n \n \n\n\nConflictos: directivos - trabajadores\n0.494***\n0.447***\n \n \n\n\nConflictos: gente de arriba - gente de\nabajo\n0.667***\n0.414***\n0.524***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\nLos ítems se correlacionan de manera positiva y con tamaños de efecto moderados y altos para las ciencias sociales. Con ello, podemos pasar a evaluar sus relaciones tienen consistencia interna.\n\nalpha_psci &lt;- psych::alpha(M_psci)\nalpha_psci$total$raw_alpha\n\n[1] 0.8044404\n\n\nDe acuerdo con este resultado, el alpha de Cronbach reflejado en el raw_alpha del output es superior al estandar de 0.6 en ciencias sociales, por lo que se sostiene su consistencia.\nAhora, generemos el índice psci\n\nproc_issp &lt;- cbind(proc_issp, \"psci\" = rowMeans(proc_issp %&gt;% select(starts_with(\"conflict\")), na.rm=TRUE))\n\nsjmisc::descr(proc_issp$psci, show = c(\"range\", \"mean\", \"sd\", \"NA.prc\", \"n\")) %&gt;%\n  kable(.,\"markdown\")\n\n\n\n\nvar\nn\nNA.prc\nmean\nsd\nrange\n\n\n\n\ndd\n1025\n0\n2.585122\n0.6986039\n3 (1-4)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "4- Matrices de correlación, casos perdidos e índices"
    ]
  },
  {
    "objectID": "assignment/03-practico.html",
    "href": "assignment/03-practico.html",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "",
    "text": "El propósito de esta guía es introducir el coeficiente de correlación de Pearson como una herramienta para la investigación, enfocándonos en su aplicación en R. A lo largo del ejercicio, aprenderemos a:\n\nPreparar los datos,\nEstimar el coeficiente de Pearson en R,\nInterpretar el tamaño del efecto,\nVisualizar la relación entre variables mediante gráficos,\nAplicar la correlación en inferencia estadística,\nEl rol del coeficiente de determinación, y\nReconocer una las principales limitaciones del coeficiente de Pearson.\n\nUtilizaremos un ejemplo que desarrollaremos progresivamente para ilustrar cada paso. Al finalizar, se propondrá un ejercicio autónomo que deberá resolverse de manera individual o grupal, aplicando los conceptos vistos en clases y en esta guía.\n\n\nEn esta práctica trabajaremos con los datos del Estudio Longitudinal Social de Chile (ELSOC) del año 2021, elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ELSOC 2021. Desde allí, se puede descargar el archivo que contiene la base de datos ELSOC 2021.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/03-practico.html#recursos-de-la-práctica",
    "href": "assignment/03-practico.html#recursos-de-la-práctica",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "",
    "text": "En esta práctica trabajaremos con los datos del Estudio Longitudinal Social de Chile (ELSOC) del año 2021, elaborado por COES. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ELSOC 2021. Desde allí, se puede descargar el archivo que contiene la base de datos ELSOC 2021.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/03-practico.html#recordemos",
    "href": "assignment/03-practico.html#recordemos",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "Recordemos…",
    "text": "Recordemos…\nEl coeficiente de correlación de Pearson es una medida estandarizada de covarianza que nos muestra la asociación lineal (sentido y fuerza) entre dos variables continuas. En otras palabras, nos permite conocer cómo y cuánto se relaciona la variación de una variable, con la variación de otra variable.\nSus valores oscilan entre -1 y 1, donde:\n\n\\(r\\) = 1: Correlación positiva perfecta. Cuando una variable aumenta, la otra también aumenta.\n\\(r\\) = -1: Correlación negativa perfecta. Cuando una variable aumenta, la otra disminuye.\n\\(r\\) = 0: No hay correlación lineal entre las variables. No hay una relación lineal discernible entre los cambios en las variables.\n\nCuanto más cercano esté el valor de \\(r\\) a 1 o -1, más fuerte será la correlación. Cuanto más cercano esté a 0, más débil será la correlación.\n\n\n\n\n\n\n\nFormula de la correlación\n\n\n\n\\[\nCorrelacion = r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})} {(n-1)\\sigma_x \\sigma_y }\n\\]",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/03-practico.html#a-valores-extremos",
    "href": "assignment/03-practico.html#a-valores-extremos",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "(a) Valores extremos",
    "text": "(a) Valores extremos\nAnteriormente, observamos valores extremos en el diagrama de dispersión de nuestro ejemplo.\n\nsjPlot::plot_scatter(data = proc_elsoc, \n                     x = ing_per, \n                     y = ing_per_just) +\n    geom_text(aes(label = \"← Ingresos = 750.000 e Ingresos justos = 50.000.000\"),\n                 x = 5500000, \n                 y = 50100000, \n                 size = 3, \n                 hjust = 1, \n                 color = \"black\"\n                 )\n\n\n\n\n\n\n\n\nVemos que el punto más extremo en el eje y corresponde a un caso que reporta que sus ingresos mensuales son de $750.000 y los ingresos que considera merecer son $50.000.000 ¿Cambiaría el coeficiente si eliminamos este valor de la base de datos?\n\n\n\n\n\n\nSobre eliminar valores…\n\n\n\nLa decisión de eliminar uno o más de valores específicos de una base de datos debe estar justificada. Generalmente, estas decisiones están basadas en posibles errores técnicos con el dato, por ejemplo, un error de digitación.\n\n\n\n# Encuentra el punto con el valor máximo de ing_per_just\nmax_ing_per_just &lt;- proc_elsoc %&gt;% \n    dplyr::filter(ing_per_just == max(ing_per_just, na.rm = T))\n\n# Excluye este caso de proc_elsoc\nproc_elsoc2 &lt;- proc_elsoc %&gt;% \n    dplyr::filter(!idencuesta %in% max_ing_per_just$idencuesta)\n\n# Calcular coeficiente\ncor(x = proc_elsoc2$ing_per, \n    y = proc_elsoc2$ing_per_just, \n    use = \"complete.obs\")\n\n[1] 0.8479801\n\n\nVemos ahora que el coeficente de correlación entre los ingresos reales y los ingresos considerados justos es de 0.85.\nVisualicemos nuevamente sin este caso extremo:\n\nsjPlot::plot_scatter(data = proc_elsoc2, \n                     x = ing_per, \n                     y = ing_per_just)\n\n\n\n\n\n\n\n\nAl eliminar este caso extremo, se facilita la identificación del patrón subyacente en la relación entre las variables, revelando una asociación positiva fuerte. Este caso, que mostraba una gran discrepancia entre los ingresos reales y los ingresos percibidos como justos, estaba afectando significativamente el análisis, reduciendo el coeficiente de correlación a casi la mitad de su valor original.\nEsto ilustra cómo un solo valor atípico puede distorsionar nuestras conclusiones sobre la fuerza y dirección de la relación entre dos variables.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/03-practico.html#b-distintas-distribuciones",
    "href": "assignment/03-practico.html#b-distintas-distribuciones",
    "title": "Práctico 3: Correlación de Pearson",
    "section": "(b) Distintas distribuciones",
    "text": "(b) Distintas distribuciones\nOtra de las limitaciones más conocidas del coeficiente de correlación es que un mismo valor puede representar distintas distribuciones de datos. El mejor ejemplo de esta limitación es el cuarteto de Anscombe, que muestra cuatro conjuntos de datos con las mismas propiedades estadísticas (media, mediana y varianza), pero con distribuciones muy diferentes.\n\n\n\n\n\n\n\n\n\nA pesar de tener las mismas propiedades estadísticas, los cuatro conjuntos producen el mismo coeficiente de correlación (\\(r = 0.82\\)). Esto podría llevarnos a esperar que las distribuciones sean similares, pero el cuarteto de Anscombe demuestra lo contrario: el mismo coeficiente de correlación no implica que los conjuntos de datos tengan una distribución bivariada similar.\nEste ejemplo subraya la importancia de complementar los análisis estadísticos (como el coeficiente de correlación) con visualizaciones de los datos para tener una mejor comprensión de las relaciones entre las variables.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "3: Correlación de Pearson"
    ]
  },
  {
    "objectID": "assignment/08-practico.html",
    "href": "assignment/08-practico.html",
    "title": "Plantilla reporte final",
    "section": "",
    "text": "El objetivo de esta guía es explicar el formato del informe de los trabajos del curso. Ya que la elaboración de los informes incluye análisis en R, la idea es poder aprovechar los recursos existentes para poder realizar escritura y análisis en un mismo documento. La base de esto eslla clase sobre documentos dinámicos y también los prácticos sobre generación de tablas y gráficos en documentos dinámicos.\nPara facilitar el desarrollo de los trabajos en este entorno ponemos a disposición una carpeta que se puede bajar aquí. Esta carpeta está basada en el protocolo IPO, mencionado en la clase sobre documentos dinámicos, con la siguente estructura de archivos y carpetas:\nEn detalle, aprenderemos los siguientes contenidos:"
  },
  {
    "objectID": "assignment/08-practico.html#crear-un-documento-quarto",
    "href": "assignment/08-practico.html#crear-un-documento-quarto",
    "title": "Plantilla reporte final",
    "section": "Crear un documento Quarto",
    "text": "Crear un documento Quarto\nPara generar un documento Quarto hacemos lo siguiente: en RStudio File &gt; New File &gt; Quarto Document"
  },
  {
    "objectID": "assignment/08-practico.html#encabezado-o-yaml",
    "href": "assignment/08-practico.html#encabezado-o-yaml",
    "title": "Plantilla reporte final",
    "section": "Encabezado o YAML",
    "text": "Encabezado o YAML\nPara comenzar, definiremos los elementos que van en el encabezado (front matter o YAML), al menos debemos especificar:\n\nTítulo\nSubtítulo\nAutores\nFecha\nIdioma\n\n\nCon ese YAML el encabezado se ve de la siguiente forma:"
  },
  {
    "objectID": "assignment/08-practico.html#apartados-y-subapartados",
    "href": "assignment/08-practico.html#apartados-y-subapartados",
    "title": "Plantilla reporte final",
    "section": "Apartados y subapartados",
    "text": "Apartados y subapartados\nPara los títulos de los apartados deben poner un # antes del nombre, y para los subapartados cada vez más pequeños dos o más #.\nPor ejemplo, si ponemos:\n# Variables\n## Descripción de variables\nLos apartados y subapartados diferirán en su tamaño y se verán de esta forma."
  },
  {
    "objectID": "assignment/08-practico.html#insertar-imágenes",
    "href": "assignment/08-practico.html#insertar-imágenes",
    "title": "Plantilla reporte final",
    "section": "Insertar imágenes",
    "text": "Insertar imágenes\nPara llamar una imagen se puede utilizar el código markdown:\n![](acá_ruta_a_imagen)\nPor ejemplo, para llamar una imagen que está en la web:\n![](https://www.desarrollosocialyfamilia.gob.cl/storage/image/banner-saludmental.png)\nSe vé luego así al renderizar:\n\nO si la imagen está en una carpeta local, ejemplo:\n\nPara cambiar el tamaño de la imagen usar width, y para cambiar la alineación fig-align:\n![](input/imagen/banner-saludmental.png){width=50% fig-align=\"center\"}\nResulta en:"
  },
  {
    "objectID": "assignment/08-practico.html#carga-de-librerías",
    "href": "assignment/08-practico.html#carga-de-librerías",
    "title": "Plantilla reporte final",
    "section": "Carga de librerías",
    "text": "Carga de librerías\nLas librerías que utilizaremos en esta guía práctica son:\n\nlibrary(pacman)\npacman::p_load(tidyverse,   # manipulacion datos\n               sjPlot,      # tablas\n               confintr,    # IC\n               gginference, # visualizacion \n               rempsyc,     # reporte\n               broom,       # varios\n               sjmisc,      # para descriptivos\n               knitr)       # para       \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo"
  },
  {
    "objectID": "assignment/08-practico.html#carga-de-datos",
    "href": "assignment/08-practico.html#carga-de-datos",
    "title": "Plantilla reporte final",
    "section": "Carga de datos",
    "text": "Carga de datos\nComo señalamos antes, cargaremos los datos del Estudio Longitudinal Social de Chile (ELSOC) para ejemplificar. En esta guía práctica llamaremos los datos desde la web, pero en la carpeta del proyecto se encuentran alojados en la carpeta input/data, y se llama de la siguiente forma:\nload(\"input/data/ELSOC_Long.RData\")\nPero, para llamar la base de datos desde la web:\n\nload(url(\"https://dataverse.harvard.edu/api/access/datafile/7245118\"))"
  },
  {
    "objectID": "assignment/08-practico.html#limpieza-de-datos",
    "href": "assignment/08-practico.html#limpieza-de-datos",
    "title": "Plantilla reporte final",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nRealizaremos un tratamiento simple de los casos:\n\n# Filtrar casos y seleccionar variables\ndata &lt;- elsoc_long_2016_2022.2 %&gt;% \n  filter(ola==1) %&gt;%\n  select(sexo=m0_sexo,edad=m0_edad,nedu=m01,\n         s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09)\n\n# remover NA's\ndata &lt;- data %&gt;% \n  set_na(., na = c(-888, -999)) %&gt;% \n  na.omit()\n\n# crear variable nueva \ndata &lt;- data %&gt;% \n  rowwise() %&gt;%\n  mutate(sint_depresivos = mean(c(s11_01,s11_02,s11_03,s11_04,s11_05,s11_06,s11_07,s11_08,s11_09))) %&gt;% \n  ungroup()"
  },
  {
    "objectID": "assignment/08-practico.html#guardar-base-de-datos-resultante",
    "href": "assignment/08-practico.html#guardar-base-de-datos-resultante",
    "title": "Plantilla reporte final",
    "section": "Guardar base de datos resultante",
    "text": "Guardar base de datos resultante\nGuardamos la base de datos procesada en la carpeta de output, con\nsaveRDS(data, \"output/data.Rdata\")"
  },
  {
    "objectID": "assignment/08-practico.html#introducción",
    "href": "assignment/08-practico.html#introducción",
    "title": "Plantilla reporte final",
    "section": "Introducción",
    "text": "Introducción\n\nEn este apartado pueden poner su introducción, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nEn este ejemplo daremos una mirada a la salud mental, y exploraremos posibles asociaciones con la edad, sexo y nivel educacional."
  },
  {
    "objectID": "assignment/08-practico.html#variables",
    "href": "assignment/08-practico.html#variables",
    "title": "Plantilla reporte final",
    "section": "Variables",
    "text": "Variables\n\nEn este apartado pueden poner sus variables, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nA continuación, en nuestro ejemplo describiremos las variables necesarias para responder a nuestro objetivo."
  },
  {
    "objectID": "assignment/08-practico.html#descripción-de-variables",
    "href": "assignment/08-practico.html#descripción-de-variables",
    "title": "Plantilla reporte final",
    "section": "Descripción de variables",
    "text": "Descripción de variables\nEn este ejemplo, se seleccionaron las variables:\n\nsexo: sexo del encuestado, con nivel de medición nominal\nedad: edad del encuestado, con nivel de medición intervalar\nnedu: nivel educativo del encuestado, con nivel de medición ordinal\n\nY las variables del módulo de Salud y Bienestar, referentes a Estado de ánimo: sintomatología depresiva, con nivel de medición ordinal, los ítems son los siguientes:\n\nFrecuencia: Poco interés o alegría\nFrecuencia: Decaimiento, pesadez o desesperanza\nFrecuencia: Dificultad para dormir o exceso de sueño\nFrecuencia: Cansancio o sensación de falta de energía\nFrecuencia: Apetito disminuido o aumentado\nFrecuencia: Dificultad para concentrarse\nFrecuencia: Mala opinión de sí mismo\nFrecuencia: Enlentecimiento físico\nFrecuencia: Pensamiento de muerte o dañarse\n\n\nPodemos caargar los datos en nuestro informe sin que se vea poniendo la option echo=FALSE: data &lt;-readRDS(\"output/data.RData\").\n\n\ntab1 &lt;- data %&gt;%\n  group_by(sexo) %&gt;% # agrupamos por sexo\n  summarise(n = n()) %&gt;% # contamos por categ de respuesta\n  mutate(prop = round((n / sum(n)) * 100, 2)) # porcentaje\n \npm &lt;- as.numeric(tab1[2,3])\nph &lt;- as.numeric(tab1[1,3])\n\ntabla1 &lt;- tab1 %&gt;% \n  kableExtra::kable(format = \"html\",\n                    align = \"c\",\n                    col.names = c(\"Sexo\", \"n\", \"Proporción\"),\n                    caption = \"Tabla 1. Distribución de sexo\") %&gt;% \n  kableExtra::kable_classic(full_width = FALSE, position = \"center\", font_size = 14) %&gt;% \n  kableExtra::add_footnote(label = \"Fuente: Elaboración propia en base a ELSOC 2016.\")\n\nEn la Tabla 1 podemos ver que la proporción de mujeres que responde la encuesta corresponde a 60.12%, mientras que la propoción de hombres corresponde a 39.88%.\n\ntabla1\n\n\n\nTabla 1: Distribución de sexo\n\n\n\n\nTabla 1. Distribución de sexo\n\n\nSexo\nn\nProporción\n\n\n\n\n1\n1151\n39.88\n\n\n2\n1735\n60.12\n\n\n\na Fuente: Elaboración propia en base a ELSOC 2016.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn las options del chunk desde el que llamamos a la tabla le ponemos tbl-nombre tabla para etiquetarla, y luego en el texto ponemos @tbl-nombre-tabla para referenciarla. También, cuando queremos llamar un valor, es necesario asignarlo a un objeto, y en el texto lo llamamos con:"
  },
  {
    "objectID": "assignment/08-practico.html#análisis",
    "href": "assignment/08-practico.html#análisis",
    "title": "Plantilla reporte final",
    "section": "Análisis",
    "text": "Análisis\n\nEn este apartado pueden poner sus análisis, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nEn nuestro ejemplo, analizaremos la correlación entre algunas variables.\n\ncor_edad_dep &lt;- cor(data$edad, data$sint_depresivos)\ncor_nedu_dep &lt;- cor(data$nedu, data$sint_depresivos)\ncor_nedu_edad &lt;- cor(data$nedu, data$edad)\n\n\ng1 &lt;- data %&gt;% \n  group_by(nedu) %&gt;% \n  summarise(sint_dep = mean(sint_depresivos, na.rm = T),\n            edad=mean(edad, na.rm = T))\n\ngrafico1 &lt;- ggplot(data = g1,\n       mapping = aes(x = sint_dep, y = edad, label = nedu)) +\n  geom_point() +\n  geom_smooth(method = \"lm\",colour = \"black\",fill=\"lightblue\",size=0.5) + \n  labs(x = \"Sintomatología depresiva\",\n       y = \"Edad\",\n       caption = \"Fuente: Elaboración propia en base a ELSOC 2026\") +\n  theme_bw()\n\nEn la Figura 1 es posible apreciar… La correlación entre la edad y el promedio de la sintomatología depresiva corresponde a 0.0176236.\n\ngrafico1\n\n\n\n\n\n\n\nFigura 1: Correlación entre edad y sintomatología depresiva\n\n\n\n\n\n\nEn las options del chunk desde el que llamamos a la figura le ponemos fig-nombre figura para etiquetarla, y luego en el texto ponemos @fig-nombre-figura para referenciarla."
  },
  {
    "objectID": "assignment/08-practico.html#conclusiones",
    "href": "assignment/08-practico.html#conclusiones",
    "title": "Plantilla reporte final",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nEn este apartado pueden poner sus conclusiones, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nAquí redactamos algunas conclusiones."
  },
  {
    "objectID": "assignment/08-practico.html#bibliografía",
    "href": "assignment/08-practico.html#bibliografía",
    "title": "Plantilla reporte final",
    "section": "Bibliografía",
    "text": "Bibliografía\n\nEn este apartado pueden poner su bibliografía, de acuerdo con la pauta del trabajo que se encuentra disponible en el enlace.\n\nPonemos un - para generar un listado.\n\nCOES (2023). Radiografía del Cambio Social: Análisis de Resultados Longitudinales ELSOC 2016-2022. Presentación de Resultados COES. Marzo, Santiago de Chile.\nR Core Team (2023). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/."
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html",
    "href": "news/2024-11-19_reporte-notas2.html",
    "title": "Reporte Evaluación 2",
    "section": "",
    "text": "← News\nEste reporte realiza un análisis de la Evaluación 2 sobre la Unidad 2: Bivariada"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#etiquetados",
    "href": "news/2024-11-19_reporte-notas2.html#etiquetados",
    "title": "Reporte Evaluación 2",
    "section": "Etiquetados",
    "text": "Etiquetados\n\n# Label variables\n\nprueba2$puntaje_p1_1 &lt;- set_label(x = prueba2$puntaje_p1_1, \n                         label = \"Correlación: Código\")\nprueba2$puntaje_p1_2 &lt;- set_label(x = prueba2$puntaje_p1_2, \n                         label = \"Correlación: Intepretación\")\nprueba2$puntaje_p2_1 &lt;- set_label(x = prueba2$puntaje_p2_1, \n                         label = \"Matriz cor: Código\")\nprueba2$puntaje_p2_2a &lt;- set_label(x = prueba2$puntaje_p2_2a, \n                         label = \"Matriz cor: Interpretación significación\")\nprueba2$puntaje_p2_2b &lt;- set_label(x = prueba2$puntaje_p2_2b, \n                         label = \"Matriz cor: Interpretación perdidos\")\nprueba2$puntaje_p2_2c &lt;- set_label(x = prueba2$puntaje_p2_2c, \n                         label = \"Matriz cor: Interpretación tipo\")                                                  \nprueba2$puntaje_p2_2 &lt;- set_label(x = prueba2$puntaje_p2_2, \n                         label = \"Matriz cor: Interpretación total\")\nprueba2$puntaje_p3_1 &lt;- set_label(x = prueba2$puntaje_p3_1, \n                         label = \"Chi: Código\")\nprueba2$puntaje_p3_2 &lt;- set_label(x = prueba2$puntaje_p3_2, \n                         label = \"Chi: Interpretación\")\nprueba2$p1_total &lt;- set_label(x = prueba2$p1_total, \n                         label = \"Pregunta 1\")\nprueba2$p2_total &lt;- set_label(x = prueba2$p2_total, \n                         label = \"Pregunta 2\")\nprueba2$p3_total &lt;- set_label(x = prueba2$p3_total, \n                         label = \"Pregunta 3\")\nprueba2$nota &lt;- set_label(x = prueba2$nota, \n                         label = \"Nota\") \n\n# Cambiar inasistentes a NA\nfilas_a_modificar &lt;- which(!is.na(prueba2$nota) & prueba2$nota == 1)\nfilas_a_modificar\n\n[1] 18 19\n\n  # Asignamos NA a todas las columnas de las filas identificadas\nprueba2[filas_a_modificar, ] &lt;- NA"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#tabla-descriptiva",
    "href": "news/2024-11-19_reporte-notas2.html#tabla-descriptiva",
    "title": "Reporte Evaluación 2",
    "section": "Tabla descriptiva",
    "text": "Tabla descriptiva\n\nprueba2 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n8\npuntaje_p1_1\nCorrelación: Código\n83\n0.85\n0.22\n0.75 (0.25-1)\n\n\n9\npuntaje_p1_2\nCorrelación: Intepretación\n83\n2.25\n0.81\n3 (0-3)\n\n\n10\npuntaje_p2_1\nMatriz cor: Código\n83\n0.80\n0.34\n1 (0-1)\n\n\n12\npuntaje_p2_2a\nMatriz cor: Interpretación significación\n83\n0.54\n0.38\n1 (0-1)\n\n\n13\npuntaje_p2_2b\nMatriz cor: Interpretación perdidos\n83\n0.65\n0.36\n1 (0-1)\n\n\n14\npuntaje_p2_2c\nMatriz cor: Interpretación tipo\n83\n0.63\n0.49\n1 (0-1)\n\n\n11\npuntaje_p2_2\nMatriz cor: Interpretación total\n83\n1.82\n0.89\n3 (0-3)\n\n\n15\npuntaje_p3_1\nChi: Código\n82\n0.64\n0.39\n1 (0-1)\n\n\n16\npuntaje_p3_2\nChi: Interpretación\n82\n1.35\n1.24\n3 (0-3)\n\n\n5\np1_total\nPregunta 1\n83\n3.10\n0.91\n3.75 (0.25-4)\n\n\n6\np2_total\nPregunta 2\n83\n2.53\n1.10\n4 (0-4)\n\n\n7\np3_total\nPregunta 3\n83\n1.97\n1.53\n4 (0-4)\n\n\n17\npuntaje_total\npuntaje_total\n83\n7.60\n2.88\n10 (2-12)\n\n\n3\nnota\nNota\n83\n4.80\n1.44\n5 (2-7)\n\n\n1\nasistida\nasistida\n83\n74.75\n15.84\n70.8 (29.2-100)\n\n\n2\nasistida_ult_practico\nasistida_ult_practico\n84\n0.54\n0.50\n1 (0-1)\n\n\n4\nnota_p1\nnota_p1\n70\n4.50\n1.43\n6 (1-7)"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#nota",
    "href": "news/2024-11-19_reporte-notas2.html#nota",
    "title": "Reporte Evaluación 2",
    "section": "Nota",
    "text": "Nota\n\nmedia_nota &lt;- mean(prueba2$nota, na.rm = TRUE)\nsd_nota &lt;- sd(prueba2$nota, na.rm = TRUE)\nhist(prueba2$nota, prob = TRUE, col = \"lightblue\",\n     main = \"Histograma de Notas\",\n     xlab = \"Nota\", ylab = \"Densidad\")\nabline(v = media_nota, col = \"red\", lwd = 2, lty = 2)\n\n\n\n\n\n\n\n\n\nprueba2 &lt;- prueba2 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba2$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n29\n32.58\n34.94\n34.94\n\n\n\n4.0-5.0\n14\n15.73\n16.87\n51.81\n\n\n\n5.0-6.0\n20\n22.47\n24.10\n75.90\n\n\n\n6.0-7.0\n20\n22.47\n24.10\n100.00\n\n\n\ntotal N=83 · valid N=63 · x̄=2.37 · σ=1.20\n\n\n\n\n\n\nprueba2 &lt;- prueba2 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#preguntas",
    "href": "news/2024-11-19_reporte-notas2.html#preguntas",
    "title": "Reporte Evaluación 2",
    "section": "Preguntas",
    "text": "Preguntas\n\n# violin plot\nprueba2_long &lt;- prueba2 %&gt;% \n  pivot_longer(cols=starts_with(\"p\"),\n               names_to = \"Prueba\",\n               values_to = \"Valor\")\n\n  \nprueba2_long %&gt;% filter(Prueba==\"p1_total\" |Prueba==\"p2_total\" | Prueba==\"p3_total\") %&gt;%   \nggplot(., aes(x = Prueba, y = Valor, fill = Prueba)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +\n  theme_minimal() +\n  labs(title = \"Comparación de Preguntas\",\n       x = \"Preguntas\",\n       y = \"Valor\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nprueba2_long %&gt;% filter(Prueba==\"puntaje_p1_1\" |Prueba==\"puntaje_p2_1\" | Prueba==\"puntaje_p3_1\") %&gt;%   \nggplot(., aes(x = Prueba, y = Valor, fill = Prueba)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +\n  theme_minimal() +\n  labs(title = \"Comparación de Puntajes en Código\",\n       x = \"Preguntas Código\",\n       y = \"Valor\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nprueba2_long %&gt;% filter(Prueba==\"puntaje_p1_2\" |Prueba==\"puntaje_p2_2\" | Prueba==\"puntaje_p3_2\") %&gt;%   \nggplot(., aes(x = Prueba, y = Valor, fill = Prueba)) +\n  geom_violin(trim = FALSE) +\n  geom_boxplot(width = 0.1, fill = \"white\", outlier.shape = NA) +\n  theme_minimal() +\n  labs(title = \"Comparación de Puntajes en Interpretación\",\n       x = \"Preguntas Código\",\n       y = \"Valor\") +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#asociaciones",
    "href": "news/2024-11-19_reporte-notas2.html#asociaciones",
    "title": "Reporte Evaluación 2",
    "section": "Asociaciones",
    "text": "Asociaciones\n\nM1 &lt;- prueba2 %&gt;% select(puntaje_p1_1, puntaje_p1_2, puntaje_p2_1, puntaje_p2_2, puntaje_p3_1, puntaje_p3_2) %&gt;% cor(., use = \"complete.obs\")\ndiag(M1) &lt;- NA\ncorrplot::corrplot(M1,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"#0D0834\"))(10),\n                   bg = \"white\",\n                   na.label = \"-\") \n\n\n\n\n\n\n\nM2 &lt;- prueba2 %&gt;% select(p1_total, p2_total, p3_total, nota) %&gt;% cor(., use = \"complete.obs\")\ndiag(M2) &lt;- NA\ncorrplot::corrplot(M2,\n                   method = \"color\",\n                   addCoef.col = \"black\",\n                   type = \"upper\",\n                   tl.col = \"black\",\n                   col = colorRampPalette(c(\"#E16462\", \"white\", \"blue\"))(10),\n                   bg = \"white\",\n                   na.label = \"-\")"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#asistencia",
    "href": "news/2024-11-19_reporte-notas2.html#asistencia",
    "title": "Reporte Evaluación 2",
    "section": "Asistencia",
    "text": "Asistencia\n\ncor(prueba2$nota, prueba2$asistida,use = \"complete.obs\")\n\n[1] 0.3438108\n\nggplot(prueba2, aes(x = asistida, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 2) + \n  labs(title = \"Relación entre asistencia y notas en Evaluación 2 (r=0.34)\") + \n  labs(x = \"Asistencia\", y = \"Nota\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5)) \n\n\n\n\n\n\n\nprueba2 &lt;- prueba2 %&gt;%  mutate(asist_total_cat=cut(asistida, breaks=c(-Inf,40,50,60,70,80,90,Inf), labels=c(\"Menos de 40%\",\"50%\",\"60%\",\"70%\",\"80%\",\"90%\", \"100%\")))\n\nfrq(prueba2$asist_total_cat, out=\"browser\", show.na = FALSE, title = \"Asistencia\")\n\n\nAsistencia\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenos de 40%\n2\n2.25\n2.41\n2.41\n\n\n\n50%\n6\n6.74\n7.23\n9.64\n\n\n\n60%\n9\n10.11\n10.84\n20.48\n\n\n\n70%\n10\n11.24\n12.05\n32.53\n\n\n\n80%\n25\n28.09\n30.12\n62.65\n\n\n\n90%\n17\n19.10\n20.48\n83.13\n\n\n\n100%\n14\n15.73\n16.87\n100.00\n\n\n\ntotal N=83 · valid N=69 · x̄=4.89 · σ=1.58\n\n\n\n\n\n\nprueba2 %&gt;% # se especifica la base de datos\n  dplyr::select(asist_total_cat, nota)  %&gt;% # se seleccionan las variables\n  dplyr::group_by(Asistencia=sjlabelled::as_label(asist_total_cat)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=round(mean(nota),2),SD=round(sd(nota),2)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nAsistencia\nObs.\nPromedio\nSD\n\n\n\n\nMenos de 40%\n2\n3.31\n0.62\n\n\n50%\n6\n3.44\n0.81\n\n\n60%\n9\n4.31\n1.73\n\n\n70%\n10\n5.66\n1.45\n\n\n80%\n25\n4.30\n1.46\n\n\n90%\n17\n5.07\n0.93\n\n\n100%\n14\n5.85\n0.89\n\n\nNA\n6\nNA\nNA\n\n\n\n\nprueba2 &lt;- prueba2 %&gt;% dplyr::select(-asist_total_cat)"
  },
  {
    "objectID": "news/2024-11-19_reporte-notas2.html#correlación-entre-evaluaciones",
    "href": "news/2024-11-19_reporte-notas2.html#correlación-entre-evaluaciones",
    "title": "Reporte Evaluación 2",
    "section": "Correlación entre evaluaciones",
    "text": "Correlación entre evaluaciones\n\ncor(prueba2$nota, prueba2$nota_p1, use = \"complete.obs\")\n\n[1] 0.4392045\n\nggplot(prueba2, aes(x = nota_p1, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 2) + \n  labs(title = \"Relación entre Evaluación 1 y Evaluación 2 (r=0.4.4)\") + \n  labs(x = \"Evaluación 1\", y = \"Evaluación 2\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5))"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html",
    "href": "files/reporte_notas/reporte_notas.html",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "pacman::p_load(tidyverse, sjmisc, sjPlot, kableExtra, sjlabelled, readxl, here)\n\n\n\n [1] \"Nº\"          \"Persona\"     \"1a\"          \"1b\"          \"1c\"         \n [6] \"2a\"          \"2b\"          \"2c\"          \"Puntos\"      \"Nota\"       \n[11] \"Asistida\"    \"Justificada\" \"asist_total\"\n\n\n\n\n\n\n# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Intervalo de Confianza\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Error tipo II\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistida &lt;- set_label(x = prueba1$asistida, \n                         label = \"Asistencia Efectiva\")\nprueba1$asist_total &lt;- set_label(x = prueba1$asist_total, \n                         label = \"Asistencia Registrada\")\n\n\n\n\n\nprueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n4\np1a\nIntervalo de Confianza\n70\n0.55\n0.30\n1 (0-1)\n\n\n5\np1b\nError tipo II\n70\n0.31\n0.45\n1 (0-1)\n\n\n6\np1c\nRechazo H0 valor p\n70\n0.81\n0.70\n2 (0-2)\n\n\n7\np2a\nFormulación hipótesis\n70\n1.47\n0.69\n2 (0-2)\n\n\n8\np2b\nContraste de prueba t\n70\n2.59\n1.32\n4 (0-4)\n\n\n9\np2c\nIntervalo confianza de prueba t\n70\n1.26\n0.74\n2 (0-2)\n\n\n3\nnota\nNota final\n70\n4.50\n1.43\n6 (1-7)\n\n\n2\nasistida\nAsistencia Efectiva\n70\n10.16\n1.86\n8 (4-12)\n\n\n1\nasist_total\nAsistencia Registrada\n70\n10.24\n1.81\n8 (4-12)\n\n\n\n\n\n\n\n\n\nhist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n25\n35.71\n35.71\n35.71\n\n\n\n4.0-5.0\n14\n20.00\n20.00\n55.71\n\n\n\n5.0-6.0\n24\n34.29\n34.29\n90.00\n\n\n\n6.0-7.0\n7\n10.00\n10.00\n100.00\n\n\n\ntotal N=70 · valid N=63 · x̄=2.19 · σ=1.04\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)\n\n\n\n\n\ntab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nIntervalo de Confianza\nError tipo II\nRechazo H0 valor p\nFormulación hipótesis\nContraste de prueba t\nIntervalo confianza de prueba t\nNota final\nAsistencia Efectiva\nAsistencia Registrada\n\n\nIntervalo de Confianza\n \n \n \n \n \n \n \n \n \n\n\nError tipo II\n0.337**\n \n \n \n \n \n \n \n \n\n\nRechazo H0 valor p\n0.271*\n0.399***\n \n \n \n \n \n \n \n\n\nFormulación hipótesis\n0.180\n0.202\n0.014\n \n \n \n \n \n \n\n\nContraste de prueba t\n0.243*\n0.244*\n0.214\n0.485***\n \n \n \n \n \n\n\nIntervalo confianza de prueba t\n0.275*\n0.280*\n0.405***\n0.281*\n0.590***\n \n \n \n \n\n\nNota final\n0.453***\n0.525***\n0.544***\n0.592***\n0.849***\n0.772***\n \n \n \n\n\nAsistencia Efectiva\n0.278*\n-0.048\n0.117\n0.355**\n0.352**\n0.382**\n0.398***\n \n \n\n\nAsistencia Registrada\n0.316**\n0.006\n0.106\n0.380**\n0.382**\n0.377**\n0.427***\n0.980***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nggplot(prueba1, aes(x = asist_total, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 4) + \n  labs(title = \"Relación entre asistencia y notas en Evaluación 1 (r=0.43)\") + \n  labs(x = \"Asistencia\", y = \"Nota\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(1, 12, by = 1), limits = c(1, 12)) +   # Ajuste del eje de asistencia\n  scale_y_continuous(breaks = seq(1, 7, by = 1), limits = c(1, 7))       # Ajuste del eje de notas de 1 a 7\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(asist_total_cat=cut(asist_total, breaks=c(-Inf,7,8,9,10,11,Inf), labels=c(\"Menos de 8\",\"8\",\"9\",\"10\",\"11\",\"12\")))\n\nfrq(prueba1$asist_total_cat, out=\"browser\", show.na = FALSE, title = \"Asistencia\")\n\n\nAsistencia\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenos de 8\n6\n8.57\n8.57\n8.57\n\n\n\n8\n4\n5.71\n5.71\n14.29\n\n\n\n9\n10\n14.29\n14.29\n28.57\n\n\n\n10\n11\n15.71\n15.71\n44.29\n\n\n\n11\n19\n27.14\n27.14\n71.43\n\n\n\n12\n20\n28.57\n28.57\n100.00\n\n\n\ntotal N=70 · valid N=50 · x̄=4.33 · σ=1.58\n\n\n\n\n\n\nprueba1 %&gt;% # se especifica la base de datos\n  dplyr::select(asist_total_cat, nota)  %&gt;% # se seleccionan las variables\n  dplyr::group_by(Asistencia=sjlabelled::as_label(asist_total_cat)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=round(mean(nota),2),SD=round(sd(nota),2)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nAsistencia\nObs.\nPromedio\nSD\n\n\n\n\nMenos de 8\n6\n2.98\n1.63\n\n\n8\n4\n3.40\n0.20\n\n\n9\n10\n4.33\n1.46\n\n\n10\n11\n4.46\n1.56\n\n\n11\n19\n4.62\n1.44\n\n\n12\n20\n5.16\n0.98\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-asist_total_cat)\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 8\nSample units: 70\nalpha: 0.753"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "href": "files/reporte_notas/reporte_notas.html#librerías-datos",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "pacman::p_load(tidyverse, sjmisc, sjPlot, kableExtra, sjlabelled, readxl, here)\n\n\n\n [1] \"Nº\"          \"Persona\"     \"1a\"          \"1b\"          \"1c\"         \n [6] \"2a\"          \"2b\"          \"2c\"          \"Puntos\"      \"Nota\"       \n[11] \"Asistida\"    \"Justificada\" \"asist_total\""
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#etiquetados",
    "href": "files/reporte_notas/reporte_notas.html#etiquetados",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Intervalo de Confianza\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Error tipo II\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistida &lt;- set_label(x = prueba1$asistida, \n                         label = \"Asistencia Efectiva\")\nprueba1$asist_total &lt;- set_label(x = prueba1$asist_total, \n                         label = \"Asistencia Registrada\")"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "href": "files/reporte_notas/reporte_notas.html#tabla-descriptiva",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "prueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n4\np1a\nIntervalo de Confianza\n70\n0.55\n0.30\n1 (0-1)\n\n\n5\np1b\nError tipo II\n70\n0.31\n0.45\n1 (0-1)\n\n\n6\np1c\nRechazo H0 valor p\n70\n0.81\n0.70\n2 (0-2)\n\n\n7\np2a\nFormulación hipótesis\n70\n1.47\n0.69\n2 (0-2)\n\n\n8\np2b\nContraste de prueba t\n70\n2.59\n1.32\n4 (0-4)\n\n\n9\np2c\nIntervalo confianza de prueba t\n70\n1.26\n0.74\n2 (0-2)\n\n\n3\nnota\nNota final\n70\n4.50\n1.43\n6 (1-7)\n\n\n2\nasistida\nAsistencia Efectiva\n70\n10.16\n1.86\n8 (4-12)\n\n\n1\nasist_total\nAsistencia Registrada\n70\n10.24\n1.81\n8 (4-12)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "href": "files/reporte_notas/reporte_notas.html#gráficos-descriptivos",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "hist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n25\n35.71\n35.71\n35.71\n\n\n\n4.0-5.0\n14\n20.00\n20.00\n55.71\n\n\n\n5.0-6.0\n24\n34.29\n34.29\n90.00\n\n\n\n6.0-7.0\n7\n10.00\n10.00\n100.00\n\n\n\ntotal N=70 · valid N=63 · x̄=2.19 · σ=1.04\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "href": "files/reporte_notas/reporte_notas.html#preguntas-y-asociaciones",
    "title": "Reporte Notas Prueba 1 - Estadística Correlacional 2024",
    "section": "",
    "text": "tab_corr(prueba1,\n         triangle = \"lower\")\n\n\n\n\n \nIntervalo de Confianza\nError tipo II\nRechazo H0 valor p\nFormulación hipótesis\nContraste de prueba t\nIntervalo confianza de prueba t\nNota final\nAsistencia Efectiva\nAsistencia Registrada\n\n\nIntervalo de Confianza\n \n \n \n \n \n \n \n \n \n\n\nError tipo II\n0.337**\n \n \n \n \n \n \n \n \n\n\nRechazo H0 valor p\n0.271*\n0.399***\n \n \n \n \n \n \n \n\n\nFormulación hipótesis\n0.180\n0.202\n0.014\n \n \n \n \n \n \n\n\nContraste de prueba t\n0.243*\n0.244*\n0.214\n0.485***\n \n \n \n \n \n\n\nIntervalo confianza de prueba t\n0.275*\n0.280*\n0.405***\n0.281*\n0.590***\n \n \n \n \n\n\nNota final\n0.453***\n0.525***\n0.544***\n0.592***\n0.849***\n0.772***\n \n \n \n\n\nAsistencia Efectiva\n0.278*\n-0.048\n0.117\n0.355**\n0.352**\n0.382**\n0.398***\n \n \n\n\nAsistencia Registrada\n0.316**\n0.006\n0.106\n0.380**\n0.382**\n0.377**\n0.427***\n0.980***\n \n\n\nComputed correlation used pearson-method with listwise-deletion.\n\n\n\n\n\n\nggplot(prueba1, aes(x = asist_total, y = nota)) + \n  geom_jitter(width = 0.2, color = \"red\", size = 4) + \n  labs(title = \"Relación entre asistencia y notas en Evaluación 1 (r=0.43)\") + \n  labs(x = \"Asistencia\", y = \"Nota\") + \n  theme(axis.title = element_text(size = 12),        # Tamaño de las etiquetas de los ejes\n        axis.text = element_text(size = 12)) +       # Tamaño del texto de los ejes\n  theme(aspect.ratio = 1/1.5) +\n  theme(plot.title = element_text(size = 12,         # Tamaño del título\n                                  face = \"bold\",     # Tipo de letra (negrita)\n                                  hjust = 0.5)) +\n  scale_x_continuous(breaks = seq(1, 12, by = 1), limits = c(1, 12)) +   # Ajuste del eje de asistencia\n  scale_y_continuous(breaks = seq(1, 7, by = 1), limits = c(1, 7))       # Ajuste del eje de notas de 1 a 7\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(asist_total_cat=cut(asist_total, breaks=c(-Inf,7,8,9,10,11,Inf), labels=c(\"Menos de 8\",\"8\",\"9\",\"10\",\"11\",\"12\")))\n\nfrq(prueba1$asist_total_cat, out=\"browser\", show.na = FALSE, title = \"Asistencia\")\n\n\nAsistencia\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenos de 8\n6\n8.57\n8.57\n8.57\n\n\n\n8\n4\n5.71\n5.71\n14.29\n\n\n\n9\n10\n14.29\n14.29\n28.57\n\n\n\n10\n11\n15.71\n15.71\n44.29\n\n\n\n11\n19\n27.14\n27.14\n71.43\n\n\n\n12\n20\n28.57\n28.57\n100.00\n\n\n\ntotal N=70 · valid N=50 · x̄=4.33 · σ=1.58\n\n\n\n\n\n\nprueba1 %&gt;% # se especifica la base de datos\n  dplyr::select(asist_total_cat, nota)  %&gt;% # se seleccionan las variables\n  dplyr::group_by(Asistencia=sjlabelled::as_label(asist_total_cat)) %&gt;% # se agrupan por la variable categórica y se usan sus etiquetas con as_label\n  dplyr::summarise(Obs.=n(),Promedio=round(mean(nota),2),SD=round(sd(nota),2)) %&gt;% # se agregan las operaciones a presentar en la tabla\n  kable(, format = \"markdown\") # se genera la tabla\n\n\n\n\nAsistencia\nObs.\nPromedio\nSD\n\n\n\n\nMenos de 8\n6\n2.98\n1.63\n\n\n8\n4\n3.40\n0.20\n\n\n9\n10\n4.33\n1.46\n\n\n10\n11\n4.46\n1.56\n\n\n11\n19\n4.62\n1.44\n\n\n12\n20\n5.16\n0.98\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-asist_total_cat)\n\nConsistencia interna\n\npacman::p_load(ltm)\n\npreguntas &lt;- prueba1 %&gt;% dplyr::select(-nota)\ncronbach.alpha(na.omit(preguntas))\n\n\nCronbach's alpha for the 'na.omit(preguntas)' data-set\n\nItems: 8\nSample units: 70\nalpha: 0.753"
  },
  {
    "objectID": "example/cace.html",
    "href": "example/cace.html",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#compliance-and-treatment-effects",
    "href": "example/cace.html#compliance-and-treatment-effects",
    "title": "Complier average treatment effects",
    "section": "",
    "text": "Throughout this course, we’ve talked about the difference between the average treatment effect (ATE), or the average effect of a program for an entire population, and conditional average treatment effect (CATE), or the average effect of a program for some segment of the population. There are all sorts of CATEs: you can find the CATE for men vs. women, for people who are treated with the program (the average treatment on the treated, or ATT or TOT), for people who are not treated with the program (the average treatment on the untreated, or ATU), and so on.\nOne important type of CATE is the effect of a program on just those who comply with the program. We can call this the complier average treatment effect, but the acronym would be the same as conditional average treatment effect, so we’ll call it the complier average causal effect or CACE.\nThinking about compliance is important. You might randomly assign people to receive treatment or a program, but people might not do what you tell them. Additionally, people might do the program if assigned to do it, but they would have done it anyway. We can split the population into four types of people:\n\nCompliers: People who follow whatever their assignment is (if assigned to treatment, they do the program; if assigned to control, they don’t)\nAlways takers: People who will receive or seek out the program regardless of assignment (if assigned to treatment, they do the program; if assigned to control, they still do the program)\nNever takers: People who will not receive or seek out the program regardless of assignment (if assigned to treatment, they don’t do the program; if assigned to control, they also don’t do it)\nDefiers: People who will do the opposite of whatever their assignment is (if assigned to treatment, they don’t do the program; if assigned to control, they do the program)\n\nTo simplify things, evaluators and econometricians assume that defiers don’t exist based on the idea of monotonicity, which means that we can assume that the effect of being assigned to treatment only increases the likelihood of participating in the program (and doesn’t make it more likely).\nThe tricky part about trying to find who the compliers are in a sample is that we can’t know what people would have done in the absence of treatment. If we see that someone in the experiment was assigned to be in the treatment group and they then participated in the program, they could be a complier (since they did what they were assigned to do), or they could be an always taker (they did what they were assigned to do, but they would have done it anyway). Due to the fundamental problem of causal inference, we cannot know what each person would have done in a parallel world.\nWe can use data from a hypothetical program to see how these three types of compliers distort our outcomes, and more importantly, how we can disentangle compliers from their always- and never-taker counterparts.\nIf you want to follow along with this example, you can download these two datasets:\n\n bed_nets_time_machine.csv\n bed_nets_observed.csv"
  },
  {
    "objectID": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "href": "example/cace.html#finding-compliers-with-a-mind-reading-time-machine",
    "title": "Complier average treatment effects",
    "section": "Finding compliers with a mind-reading time machine",
    "text": "Finding compliers with a mind-reading time machine\nFirst let’s load the data and reorder some of the categories:\n\n\nCode\nlibrary(tidyverse)  # ggplot(), %&gt;%, mutate(), and friends\nlibrary(broom)  # Convert models to data frames\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\n\nbed_nets &lt;- read_csv(\"data/bed_nets_observed.csv\") %&gt;%\n  # Make \"No bed net\" (control) come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"))\n\nbed_nets_time_machine &lt;- read_csv(\"data/bed_nets_time_machine.csv\") %&gt;%\n  # Make \"No bed net\" come first and \"Complier\" come first\n  mutate(bed_net = fct_relevel(bed_net, \"No bed net\"),\n         status = fct_relevel(status, \"Complier\"))\n\n\nThis is what we would be able to see if we could read everyone’s minds. There are always takers who will use a bed net regardless of the program, and they’ll have higher health outcomes. However, those better outcomes are because of something endogenous—there’s something else that makes these people always pursue bed nets, and that’s likely related to health. We probably want to not consider them when looking for the program effect. There are never takers who won’t ever use a bed net, and they have worse health outcomes. Again, there’s endogeneity here—something is causing them to not use the bed nets, and it likely also causes their health level. We don’t want to look at them either.\nThe first group—the compliers—are the people we want to focus on. Here we see that the program had an effect when compared to a control group.\n\n\nCode\nset.seed(1234)  # Make the jittering the same every time\n\nggplot(bed_nets_time_machine, aes(y = health, x = treatment)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(status)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()"
  },
  {
    "objectID": "example/cace.html#finding-compliers-in-actual-data",
    "href": "example/cace.html#finding-compliers-in-actual-data",
    "title": "Complier average treatment effects",
    "section": "Finding compliers in actual data",
    "text": "Finding compliers in actual data\nThis is what we actually see in the data, though. You can tell who some of the always takers are (those who used bed nets after being assigned to the control group) and who some of the never takers are (those who did not use a bed net after being assigned to the treatment group), but compliers are mixed up with the always and never takers. We have to somehow disentangle them!\n\n\nCode\nset.seed(1234)\nggplot(bed_nets_time_machine, aes(y = health, x = bed_net)) +\n  geom_point(aes(shape = bed_net, color = status),\n             position = position_jitter(height = NULL, width = 0.25)) +\n  facet_wrap(vars(treatment)) +\n  labs(color = \"Type of person\", shape = \"Compliance\",\n       x = NULL, y = \"Health status\") +\n  scale_color_viridis_d(option = \"plasma\", end = 0.85) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nWe can do this by assuming the proportion of compliers, never takers, and always takers are equally spread across treatment and control (which we can assume through the magic of randomization). If that’s the case, we can calculate the intent to treat (ITT) effect, which is the CATE of being assigned treatment (or the effect of being assigned treatment on health status, regardless of actual compliance).\nThe ITT is actually composed of three different causal effects: the complier average causal effect (CACE), the always taker average causal effect (ATACE), and the never taker average causal effect (NTACE). In the formula below, \\(\\pi\\) stands for the proportion of people in each group. Formally, the ITT can be defined like this:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{compliers} \\times (\\text{T} - \\text{C})_\\text{compliers}} + \\\\\n&\\color{#B7318A}{\\pi_\\text{always takers} \\times (\\text{T} - \\text{C})_\\text{always takers}} + \\\\\n&\\color{#FEBA2C}{\\pi_\\text{never takers} \\times (\\text{T} - \\text{C})_\\text{never takers}}\n\\end{aligned}\n\\]\nWe can simplify this to this acronymized version:\n\\[\n\\text{ITT}\\ =\\ \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}}\n\\]\nThe number we care about the most here is the CACE, which is stuck in the middle of the equation. But we can rescue it with some fun logical and algebraic trickery!\nIf we assume that assignment to treatment doesn’t make someone more likely to be an always taker or a never taker, we can set the ATACE and NTACE to zero, leaving us with just three variables to worry about: ITT, \\(\\pi_\\text{c}\\), and CACE:\n\\[\n\\begin{aligned}\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\text{ATACE}} + \\color{#FEBA2C}{\\pi_\\text{N} \\text{NTACE}} \\\\[6pt]\n=\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}} + \\color{#B7318A}{\\pi_\\text{A} \\times 0} + \\color{#FEBA2C}{\\pi_\\text{N} \\times 0}\\\\[6pt]\n\\text{ITT}\\ =\\ & \\color{#0D0887}{\\pi_\\text{C} \\text{CACE}}\n\\end{aligned}\n\\]\nWe can use algebra to rearrange this formula so that we’re left with an equation that starts with CACE (since that’s the value we care about):\n\\[\n\\text{CACE} = \\frac{\\text{ITT}}{\\pi_\\text{C}}\n\\]\nIf we can find the ITT and the proportion of compliers, we can find the complier average causal effect (CACE). Fortunately, both those pieces—ITT and \\(\\pi_\\text{C}\\)—are findable in the data we have!"
  },
  {
    "objectID": "example/cace.html#finding-the-itt",
    "href": "example/cace.html#finding-the-itt",
    "title": "Complier average treatment effects",
    "section": "Finding the ITT",
    "text": "Finding the ITT\nThe ITT is easy to find with a simple OLS model:\n\n\nCode\nitt_model &lt;- lm(health ~ treatment, data = bed_nets)\n\ntidy(itt_model)\n## # A tibble: 2 × 5\n##   term               estimate std.error statistic  p.value\n##   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n## 1 (Intercept)           40.9      0.444     92.1  0       \n## 2 treatmentTreatment     5.99     0.630      9.51 5.20e-21\n\nITT &lt;- tidy(itt_model) %&gt;%\n  filter(term == \"treatmentTreatment\") %&gt;%\n  pull(estimate)\n\n\nThe ITT here is ≈6—being assigned treatment increases average health status by 5.99 health points."
  },
  {
    "objectID": "example/cace.html#finding-the-proportion-of-compliers",
    "href": "example/cace.html#finding-the-proportion-of-compliers",
    "title": "Complier average treatment effects",
    "section": "Finding the proportion of compliers",
    "text": "Finding the proportion of compliers\nThe proportion of compliers is a little trickier, but doable with some algebraic trickery. Recall from the graph above that the people who were in the treatment group and who complied are a combination of always takers and compliers. This means we can say:\n\\[\n\\begin{aligned}\n\\pi_\\text{A} + \\pi_\\text{C} =& \\text{% yes in treatment; or} \\\\\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A}\n\\end{aligned}\n\\]\nWe actually know \\(\\pi_\\text{A}\\)—remember in the graph above that the people who were in the control group and who used bed nets are guaranteed to be always takers (none of them are compliers or never takers). If we assume that the proportion of always takers is the same in both treatment and control, we can use that percent here, giving us this final equation for \\(\\pi_\\text{C}\\):\n\\[\n\\begin{aligned}\n\\pi_\\text{C} =& \\text{% yes in treatment} - \\pi_\\text{A} \\\\\n=& \\text{% yes in treatment} - \\text{% yes in control}\n\\end{aligned}\n\\]\nSo, if we can find the percent of people assigned to treatment who used bed nets, find the percent of people assigned to control and used bed nets, and subtract the two percentages, we’ll have the proportion of compliers, or \\(\\pi_\\text{C}\\). We can do that with the data we have (61% - 19.5% = 41.5% compliers):\n\n\nCode\nbed_nets %&gt;%\n  group_by(treatment, bed_net) %&gt;%\n  summarize(n = n()) %&gt;%\n  mutate(prop = n / sum(n))\n## # A tibble: 4 × 4\n## # Groups:   treatment [2]\n##   treatment bed_net        n  prop\n##   &lt;chr&gt;     &lt;fct&gt;      &lt;int&gt; &lt;dbl&gt;\n## 1 Control   No bed net   808 0.805\n## 2 Control   Bed net      196 0.195\n## 3 Treatment No bed net   388 0.390\n## 4 Treatment Bed net      608 0.610\n\n# pi_c = prop yes in treatment - prop yes in control\npi_c &lt;- 0.6104418 - 0.1952191\n\n\nFinally, now that we know both the ITT and \\(\\pi_\\text{C}\\), we can find the CACE (or the LATE):\n\n\nCode\nCACE &lt;- ITT / pi_c\nCACE\n## [1] 14.43\n\n\nIt’s 14.4, which means that using bed nets increased health by 14 health points for compliers (which is a lot bigger than the 6 that we found before). We successfully filtered out the always takers and the never takers, and we have our complier-specific causal effect."
  },
  {
    "objectID": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "href": "example/cace.html#finding-the-cacelate-with-iv2sls",
    "title": "Complier average treatment effects",
    "section": "Finding the CACE/LATE with IV/2SLS",
    "text": "Finding the CACE/LATE with IV/2SLS\nDoing that is super tedious though! What if there was an easier way to find the effect of the bed net program for just the compliers? We can do this with IV/2SLS regression by using assignment to treatment as an instrument.\nAssignment to treatment works as an instrument because it’s (1) relevant, since being told to use bed nets is probably highly correlated with using bed nets, (2) exclusive, since the only way that being told to use bed nets can cause changes in health is through the actual use of the bed nets, and (3) exogenous, since being told to use bed nets probably isn’t related to other things that cause health.\nHere’s a 2SLS regression with assignment to treatment as the instrument:\n\n\nCode\nmodel_2sls &lt;- iv_robust(health ~ bed_net | treatment, data = bed_nets)\ntidy(model_2sls)\n##             term estimate std.error statistic   p.value conf.low conf.high   df outcome\n## 1    (Intercept)    38.12    0.5151     74.01 0.000e+00    37.11     39.13 1998  health\n## 2 bed_netBed net    14.43    1.2538     11.51 1.038e-29    11.97     16.89 1998  health\n\n\nThe coefficient for bed_net is identical to the CACE that we found manually! Instrumental variables are helpful for isolated program effects to only compliers when you’re dealing with noncompliance."
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "A Ud. se le ha solicitado estimar el promedio de salarios en la población, así como también si existen diferencias salariales entre quienes han completado la educación superior en institutos técnico-profesionales (IP) y quienes lo han hecho en instituciones universitarias. Para ello se le ha proporcionado la siguiente información:\n\nDatos: Encuesta de Ingresos, muestra aleatoria N=900 casos\nPromedio salarios: 850.000, desviación estándar 300.000\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\n\nAdemás de esto, se le han proporcionado los siguientes valores para realizar inferencia estadística:\n\nvalor crítico z para el promedio con un \\(\\alpha\\) de 5% (0,05)= 1,96, y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96; y con un \\(\\alpha\\) de 1% (0,01)= 2,58\nError estándar del promedio:\n\n\\[\\sigma_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\n\nError estándar de la diferencia de medias salariales para esta muestra= 15000\n\n\n\nCódigo\n# Generación de los datos\noptions(scipen = 999)\n\n# Establecer la semilla para garantizar la reproducibilidad\nset.seed(281217)  \n\n# Parámetros actualizados\nn &lt;- 900  # Tamaño de la muestra\npromedio_salarios &lt;- 850000;desviacion_estandar_salarios &lt;- 300000  # Desviación estándar de los salarios\n\n# Generar la muestra con la nueva semilla y parámetros\ningresos &lt;- rnorm(n, mean = promedio_salarios, sd = desviacion_estandar_salarios)\n\n\n\n\n\nTengo que el promedio de salarios de la muestra es: 900.000\nPromedio de salarios de la población: \\(X\\)?\n\nNo podemos dar un valor certero para el promedio poblacional, pero si un rango probable de valores.\n\n\n¿Qué tipo de aproximación de test de hipótesis corresponde en este caso? Recordemos las dos aproximaciones principales para test de hipótesis: a) contraste con valor crítico, y b) generación de intervalo de confianza. En general se pueden aplicar siempre las dos, pero su pertinencia es distinta según lo que se esté estimando:\n\nen este caso (estimación del promedio) se podría realizar la alternativa de contraste con valor crítico, que nos permitiría rechazar (o no) la hipótesis nula de que el promedio es cero en la población.\nya que la alternativa anterior no es muy informativa en este caso, en la estimación puntual de parámetros (como el promedio) se prefiere utilizar un rango de probabilidad, expresado en un intervalo de confianza.\n\nPor lo tanto, en este caso lo que es más pertinente es la alternativa b: estimación de un intervalo de confianza\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (el promedio es igual a 0 en la población):\n\\[H_{0}: \\bar{X}_{salarios}=0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salarios} \\neq 0\\]\n\n\n\nEl error estándar (SE, por Standard Error) del promedio es:\n\\[SE_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\nReemplazando:\n\\[SE_{\\bar{X}}=\\frac{300000}{\\sqrt{900}}=\\frac{300000}{30}=10000\\]\n\n\nCódigo\nerror_estandar &lt;- desviacion_estandar_salarios / sqrt(n)\nerror_estandar\n\n\n[1] 10000\n\n\n\n\n\nEsta informació fue proporcionada en el enunciado: \\(\\alpha=5%\\), valor crítico= 1,96\n\n\n\nRecordar fórmula del intervalo de 95% de confianza para el promedio:\n\\[\\begin{align*}\n\\bar{x} &\\pm Z_{\\alpha/2}*SE_{\\bar{x}} \\\\\\\\\n850000 &\\pm 1.96*10000 \\\\\\\\\n850000 &\\pm 19600 \\\\\\\\\nCI[830400&;869600]\n\\end{align*}\\]\nEn R:\n\n\nCódigo\n# Calcular el intervalo de confianza al 95%\nz_95 &lt;- 1.96  # Valor z para el 95% de confianza\nlimite_inferior &lt;- promedio_salarios - z_95 * error_estandar\nlimite_superior &lt;- promedio_salarios + z_95 * error_estandar\n\n# Mostrar los resultados\ncat(\"Intervalo de confianza al 95%: [\", round(limite_inferior, 2), \", \", round(limite_superior, 2), \"]\\n\")\n\n\nIntervalo de confianza al 95%: [ 830400 ,  869600 ]\n\n\n\n\n\nUtilizando una muestra de 900 individuos, se estimó el promedio de ingresos en $850,000 con una desviación estándar de $300,000. El error estándar para esta estimación es $10,000, y el intervalo de confianza al 95%, calculado con estos parámetros, se extiende de $830,400 a $869,600. Este intervalo refleja que, con un 95% de confianza, se puede afirmar que el promedio verdadero de ingresos en la población se encuentra dentro de este rango, asumiendo una distribución normal de los ingresos.\n\n\n\n\n\nPara este ejercicio consideramos la siguiente información proporcionada arriba:\n\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96\nerror estándar de la diferencia de medias= 15000\n\nCon esta información ya podemos calcular la diferencia de promedios de la muestra:\n\\(\\bar{X}_{salario-universitario}-\\bar{X}_{salario-técnico}=1500000-1200000=300000\\)\nLa pregunta ahora es: ¿existe esta diferencia de promedios en la población?\n\n\nPara el caso anterior de la estimación del promedio hablamos de dos aproximaciones: a) contraste con valor crítico, y b) intervalo de confianza. En este caso (estimación de diferencias de promedio) tradicionalmente se utiliza el contraste con valor crítico, ya que lo central es poder establecer si existen o no diferencias en la población. Complementariamente, también se puede entregar información del intervalo de confianza.\nPor lo tanto, en este caso lo que es más pertinente es la alternativa a: contraste con valor crítico, pero también es recomendable agregar la información del intervalo de confianza.\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (no hay diferencias de promedios entre grupos):\n\\[H_{0}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto}= 0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto} \\neq 0\\]\n\n\n\nEl error estándar de la diferencias de promedios es:\n\\[SE=\\sqrt{\\frac{\\sigma_{diff}}{n_a}+\\frac{\\sigma_{diff}}{n_b}}\\]\nLa información sobre el resultado de este cálculo se nos entrega inicialmente y es igual a 15000\nCon esto podemos calcular el valor del t empírico:\n\\(t=\\frac{diferenciamedias}{se_{diferenciamedias}} \\frac{(\\bar{x}_1-\\bar{x}_2)}{se_{(\\bar{x}_1-\\bar{x}_2)}}\\)\nCon nuestros datos:\n\\(t=\\frac{300000}{15000}=20\\)\n\n\n\n\nProporcionado en el enunciado\n\n\n\n\nt empírico= 20 &gt; t critico=1,96\nIntervalo al 95% de confianza:\n\\[\\begin{align*}\n\\bar{x}_1-\\bar{x}_2 &\\pm t_{\\alpha/2}*SE_{\\bar{x_1}-\\bar{x_2}} \\\\\\\\\n300000 &\\pm 1.96*15000 \\\\\\\\\n300000 &\\pm 29400 \\\\\\\\\nCI[270600&\\ ;329400]\n\\end{align*}\\]\n\n\n\nSe llevó a cabo una prueba t para evaluar las diferencias salariales entre graduados de institutos técnicos-profesionales y universidades, utilizando un tamaño de muestra de 900 para cada grupo. La diferencia de medias observada fue de $750,000, con un error estándar fijo de $15,000 para esta diferencia. El análisis resultó en un valor t de 50.00, indicando una diferencia estadísticamente significativa entre los dos grupos (p &lt; .01). Este valor t refleja que los graduados universitarios tienen un ingreso promedio significativamente mayor en comparación con los graduados de institutos técnicos-profesionales. Estos resultados sugieren una marcada disparidad salarial en función del nivel educativo alcanzado, subrayando la importancia de las decisiones educativas en las trayectorias de ingresos de los individuos.",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "content/07-content.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "href": "content/07-content.html#a.-estimación-del-promedio-de-salarios-de-la-población",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Tengo que el promedio de salarios de la muestra es: 900.000\nPromedio de salarios de la población: \\(X\\)?\n\nNo podemos dar un valor certero para el promedio poblacional, pero si un rango probable de valores.\n\n\n¿Qué tipo de aproximación de test de hipótesis corresponde en este caso? Recordemos las dos aproximaciones principales para test de hipótesis: a) contraste con valor crítico, y b) generación de intervalo de confianza. En general se pueden aplicar siempre las dos, pero su pertinencia es distinta según lo que se esté estimando:\n\nen este caso (estimación del promedio) se podría realizar la alternativa de contraste con valor crítico, que nos permitiría rechazar (o no) la hipótesis nula de que el promedio es cero en la población.\nya que la alternativa anterior no es muy informativa en este caso, en la estimación puntual de parámetros (como el promedio) se prefiere utilizar un rango de probabilidad, expresado en un intervalo de confianza.\n\nPor lo tanto, en este caso lo que es más pertinente es la alternativa b: estimación de un intervalo de confianza\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (el promedio es igual a 0 en la población):\n\\[H_{0}: \\bar{X}_{salarios}=0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salarios} \\neq 0\\]\n\n\n\nEl error estándar (SE, por Standard Error) del promedio es:\n\\[SE_{\\bar{X}}=\\frac{s\\ (desv.\\ estandar)}{\\sqrt{N} (tamaño\\ muestral)}\\]\nReemplazando:\n\\[SE_{\\bar{X}}=\\frac{300000}{\\sqrt{900}}=\\frac{300000}{30}=10000\\]\n\n\nCódigo\nerror_estandar &lt;- desviacion_estandar_salarios / sqrt(n)\nerror_estandar\n\n\n[1] 10000\n\n\n\n\n\nEsta informació fue proporcionada en el enunciado: \\(\\alpha=5%\\), valor crítico= 1,96\n\n\n\nRecordar fórmula del intervalo de 95% de confianza para el promedio:\n\\[\\begin{align*}\n\\bar{x} &\\pm Z_{\\alpha/2}*SE_{\\bar{x}} \\\\\\\\\n850000 &\\pm 1.96*10000 \\\\\\\\\n850000 &\\pm 19600 \\\\\\\\\nCI[830400&;869600]\n\\end{align*}\\]\nEn R:\n\n\nCódigo\n# Calcular el intervalo de confianza al 95%\nz_95 &lt;- 1.96  # Valor z para el 95% de confianza\nlimite_inferior &lt;- promedio_salarios - z_95 * error_estandar\nlimite_superior &lt;- promedio_salarios + z_95 * error_estandar\n\n# Mostrar los resultados\ncat(\"Intervalo de confianza al 95%: [\", round(limite_inferior, 2), \", \", round(limite_superior, 2), \"]\\n\")\n\n\nIntervalo de confianza al 95%: [ 830400 ,  869600 ]\n\n\n\n\n\nUtilizando una muestra de 900 individuos, se estimó el promedio de ingresos en $850,000 con una desviación estándar de $300,000. El error estándar para esta estimación es $10,000, y el intervalo de confianza al 95%, calculado con estos parámetros, se extiende de $830,400 a $869,600. Este intervalo refleja que, con un 95% de confianza, se puede afirmar que el promedio verdadero de ingresos en la población se encuentra dentro de este rango, asumiendo una distribución normal de los ingresos.",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "content/07-content.html#estimación-de-diferencia-de-medias",
    "href": "content/07-content.html#estimación-de-diferencia-de-medias",
    "title": "Ejercicio de repaso general Unidad 1",
    "section": "",
    "text": "Para este ejercicio consideramos la siguiente información proporcionada arriba:\n\nSalario promedio técnico-profesional: 1.200.000, desviación estandar 180.000\nSalario promedio universitario: 1.500.000, desviación estándar 270.000\nvalor crítico t para diferencia de medias con un \\(\\alpha\\) de 5% (0,05) y grados de libertad 898 (N-2)= 1,96\nerror estándar de la diferencia de medias= 15000\n\nCon esta información ya podemos calcular la diferencia de promedios de la muestra:\n\\(\\bar{X}_{salario-universitario}-\\bar{X}_{salario-técnico}=1500000-1200000=300000\\)\nLa pregunta ahora es: ¿existe esta diferencia de promedios en la población?\n\n\nPara el caso anterior de la estimación del promedio hablamos de dos aproximaciones: a) contraste con valor crítico, y b) intervalo de confianza. En este caso (estimación de diferencias de promedio) tradicionalmente se utiliza el contraste con valor crítico, ya que lo central es poder establecer si existen o no diferencias en la población. Complementariamente, también se puede entregar información del intervalo de confianza.\nPor lo tanto, en este caso lo que es más pertinente es la alternativa a: contraste con valor crítico, pero también es recomendable agregar la información del intervalo de confianza.\n\n\n\nLos 5 pasos de la inferencia en esta caso son los siguientes:\n\n\nContrastamos la hipótesis nula (no hay diferencias de promedios entre grupos):\n\\[H_{0}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto}= 0\\]\nEn referencia a la siguiente hipótesis alternativa:\n\\[H_{a}: \\bar{X}_{salariouniversidad} -  \\bar{X}_{salarioinstituto} \\neq 0\\]\n\n\n\nEl error estándar de la diferencias de promedios es:\n\\[SE=\\sqrt{\\frac{\\sigma_{diff}}{n_a}+\\frac{\\sigma_{diff}}{n_b}}\\]\nLa información sobre el resultado de este cálculo se nos entrega inicialmente y es igual a 15000\nCon esto podemos calcular el valor del t empírico:\n\\(t=\\frac{diferenciamedias}{se_{diferenciamedias}} \\frac{(\\bar{x}_1-\\bar{x}_2)}{se_{(\\bar{x}_1-\\bar{x}_2)}}\\)\nCon nuestros datos:\n\\(t=\\frac{300000}{15000}=20\\)\n\n\n\n\nProporcionado en el enunciado\n\n\n\n\nt empírico= 20 &gt; t critico=1,96\nIntervalo al 95% de confianza:\n\\[\\begin{align*}\n\\bar{x}_1-\\bar{x}_2 &\\pm t_{\\alpha/2}*SE_{\\bar{x_1}-\\bar{x_2}} \\\\\\\\\n300000 &\\pm 1.96*15000 \\\\\\\\\n300000 &\\pm 29400 \\\\\\\\\nCI[270600&\\ ;329400]\n\\end{align*}\\]\n\n\n\nSe llevó a cabo una prueba t para evaluar las diferencias salariales entre graduados de institutos técnicos-profesionales y universidades, utilizando un tamaño de muestra de 900 para cada grupo. La diferencia de medias observada fue de $750,000, con un error estándar fijo de $15,000 para esta diferencia. El análisis resultó en un valor t de 50.00, indicando una diferencia estadísticamente significativa entre los dos grupos (p &lt; .01). Este valor t refleja que los graduados universitarios tienen un ingreso promedio significativamente mayor en comparación con los graduados de institutos técnicos-profesionales. Estos resultados sugieren una marcada disparidad salarial en función del nivel educativo alcanzado, subrayando la importancia de las decisiones educativas en las trayectorias de ingresos de los individuos.",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Ejercicio Inferencia"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "",
    "text": "Inferencia, asociación y reporte\n        \n        \n            SOC01019 • Segundo Semestre 2025Departamento de Sociología, Facultad de Ciencias SocialesUniversidad de Chile"
  },
  {
    "objectID": "index.html#últimas-informaciones",
    "href": "index.html#últimas-informaciones",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Últimas informaciones",
    "text": "Últimas informaciones\n\n\n\n\n\n\n\n\n\n\nInicio practicos\n\n\n\n\n\n\n\n\n\nAug 19, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPadlet\n\n\n\n\n\n\n\n\n\nAug 13, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nInformaciones por acá\n\n\n\n\n\n\n\n\n\nAug 19, 2024\n\n\n\n\n\n\nNo matching items\n\n-&gt; ir a la página de Informaciones del sitio."
  },
  {
    "objectID": "index.html#versiones-previas-del-curso",
    "href": "index.html#versiones-previas-del-curso",
    "title": "\n            Estadística Correlacional\n        ",
    "section": "Versiones previas del curso:",
    "text": "Versiones previas del curso:\n\n2023"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMiércoles 27\n\nPráctico Inferencia 2\n\n\n\n Septiembre \n\n\n\n\n\nLunes 1\nRepaso Unidad 1\n\n\n\n\nMiércoles 03\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 22\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMiércoles 24\n\nPráctico. Bivariada 1\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n Octubre \n\n\n\n\n\nMiércoles 01\n\nPráctico: Bivariada 2\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 3\n\n\n\nLunes 13\nRepaso Unidad 2\n\n\n\n\nMiércoles 15\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\nLunes 20\nSeminario encuestas\n\n\n\n\nMiércoles 22\n\nDefinición de grupos y temas\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule.html#forma-general-de-funcionamiento",
    "href": "schedule.html#forma-general-de-funcionamiento",
    "title": "Planificación",
    "section": "",
    "text": "Este curso se compone de tres actividades principales:\n\n Clases lectivas presenciales: donde en base a las lecturas correspondientes a esa semana se presentará un resumen de los contenidos principales y se resolverán dudas.\n Guías prácticas: actividades con énfasis en el manejo de software para análisis y reporte de los resultados.\n Lecturas: los temas del curso se acompañan de lecturas, las que se encuentran a disposición en esta página.\n\nLas actividades semanales se resumen en el siguiente esquema:\n\nEn cuanto a la metodología, el curso comienza con clases lectivas y desarrollo autónomo de guías prácticas, y en la última unidad se realizará un trabajo grupal práctico de aplicación de los contenidos.\n\n\n\n\n\n\n\n\n\n\n Agosto \n Clases\n Prácticos\n Lecturas\n\n\nLunes 4\n1. Presentación\n\nLeer detalladamente programa del curso\n\n\n\n\n\n\n\n\n\n\nMiércoles 6\nDatos, probabilidad y distribuciones muestrales\n\n*Pardo cap 2 Conceptos previos\nRichtey 1-21 : La imaginación estadística\n\n\nLunes 11\nError estándar y distribución normal\n\n*Richtey cap 6\nPardo cap 6 Probabilidad y distribución normal\n\n\nMiércoles 13\nIntervalos de confianza\n\n*Richtey cap 7 Probabilidad y distribuciones muestrales\n\n\nLunes 18\nTest de hipótesis\n\n*Richtey cap 8: Intervalos de confianza\n*Richtey cap 9: Prueba de hipótesis\nMontoya: Los conceptos de especificación y falsación\n\n\nMiércoles 20\n\nPráctico: Inferencia 1\n\n\n\n\n\n\n\n\n\nLunes 25\nHipótesis para una y dos muestras\n\n*Richtey cap 10: Hipótesis de una muestra\n*Richtey cap 11: Hipótesis de dos muestras (prueba t)\n\n\nMiércoles 27\n\nPráctico Inferencia 2\n\n\n\n Septiembre \n\n\n\n\n\nLunes 1\nRepaso Unidad 1\n\n\n\n\nMiércoles 03\nEvaluación 1\n\n\n\n\n\n\n\n\n\n\nLunes 08\nAsociación, covarianza y correlación\n\nMoore 97-131 Análisis de relaciones\nPiovani - The historical construction of correlation\n\n\nMiércoles 10\nMagnitud de la correlación y contraste de hipótesis\n\nPardo 307 - 330 Relación lineal\nHuck 183 - 203 Statistical Inferences Concerning Bivariate Correlation Coefﬁcients\n\n\nLunes 22\nCorrelación con variables ordinales y matrices de correlación\n\nField 223 -233 Spearman, Kendall y otros\n\n\nMiércoles 24\n\nPráctico. Bivariada 1\n\n\n\nLunes 29\nAsociación con categóricas 1\n\n\n\n\n Octubre \n\n\n\n\n\nMiércoles 01\n\nPráctico: Bivariada 2\n\n\n\nLunes 06\nAsociación con categóricas 2\n\n\n\n\nMiércoles 08\n\nPráctico: Bivariada 3\n\n\n\nLunes 13\nRepaso Unidad 2\n\n\n\n\nMiércoles 15\nEvaluación 2\n\n\n\n\n\n\n\n\n\n\nLunes 20\nSeminario encuestas\n\n\n\n\nMiércoles 22\n\nDefinición de grupos y temas\n\n\n\nLunes 28\nSemana receso\n\n\n\n\nMiércoles 30\nSemana receso\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 03\nEscritura y reportes dinámicos\n\n\n\n\nMiércoles 05\n\nVisualización1: tablas\n\n\n\nLunes 10\nVisualización 2: Gráficos / Poster\n\n\n\n\nMiércoles 12\n\nAsesoría grupos\n\n\n\nLunes 17\nAsesoría grupos\n\n\n\n\nMiércoles 19\nPruebas recuperativas\nEntrega de trabajos finales\n\n\n\n\nLunes 24\nSemana de preparación exámentes\n\n\n\n\nMiércoles 26\nSemana preparación exámenes\n\n\n\n\n Noviembre\n\n\n\n\n\nLunes 01\nExámen primera oportunidad\n\n\n\n\nLunes 08\nExámen segunda oportunidad"
  },
  {
    "objectID": "schedule.html#exámenes-finales-orales",
    "href": "schedule.html#exámenes-finales-orales",
    "title": "Planificación",
    "section": "Exámenes finales (orales)",
    "text": "Exámenes finales (orales)\nVer requisitos de aprobación y eximición\n\nExamen de primera oportunidad: Miércoles 11 Diciembre desde las 9:30\nExamen de segunda oportunidad: Lunes 16 Diciembre desde las 10:15"
  },
  {
    "objectID": "news/index.html",
    "href": "news/index.html",
    "title": "Informaciones",
    "section": "",
    "text": "Acá las principales informaciones y actualizaciones del curso.\n\n\n   \n    \n    \n      Ordenar por\n      Por defecto\n      \n        Fecha - Menos reciente\n      \n      \n        Fecha - Más reciente\n      \n      \n        Título\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nFecha\n\n\n\nTítulo\n\n\n\nCategorías\n\n\n\n\n\n\n\n\nmartes agosto 19, 2025 at 12:00 AM\n\n\nInicio practicos\n\n\ninfo\n\n\n\n\n\n\nmiércoles agosto 13, 2025 at 12:00 AM\n\n\nPadlet\n\n\ninfo\n\n\n\n\n\n\nlunes agosto 19, 2024 at 12:00 AM\n\n\nInformaciones por acá\n\n\ninfo\n\n\n\n\n\n\nNo hay resultados\n\n\n\n\n\n\n\nSuscribirse!\n\n\n\nPuedes usar un lector de feeds como Feedly o un servicio RSS-to-email como Blogtrottr para suscribirte a cualquiera de estos mensajes.\n\n\n\n\n\n RSS"
  },
  {
    "objectID": "trabajos.html",
    "href": "trabajos.html",
    "title": "Trabajos",
    "section": "",
    "text": "El curso de Estadística Correlacional considera la elaboración de un trabajo grupal como instancia final de evaluación. El trabajo a realizar es la elaboración de un reporte de análisis bivariado.\nLa nota de este trabajo equivale a un 30% de la nota final del curso, donde 20% equivale al reporte escrito y 10% a la presentación (en formato póster)."
  },
  {
    "objectID": "trabajos.html#organización-de-actividades",
    "href": "trabajos.html#organización-de-actividades",
    "title": "Trabajos",
    "section": "9.1 Organización de actividades",
    "text": "9.1 Organización de actividades\nHay 4 semanas para realizar el trabajo. Durante este tiempo los horarios de clases estarán destinados a contenidos asociados a la realización de los reportes, así como también a asesorar a los grupos. Se sugiere organizar las actividades de la siguiente manera:\n\nSemana 1: definición de grupos, temas y base de datos\nSemana 2: análisis descriptivos univariados, chequeo de nivel de medición de variables, varianza y casos perdidos\nSemana 3: escritura de introducción y análisis bivariados. Diseño de póster.\nSemana 4: conclusiones y redacción final, presentación de póster y entrega de reporte."
  },
  {
    "objectID": "trabajos.html#escritura-académica",
    "href": "trabajos.html#escritura-académica",
    "title": "Trabajos",
    "section": "9.2 Escritura académica",
    "text": "9.2 Escritura académica\n\nUna idea por párrafo\nUso de “oración principal” (topic sentence): usualmente es la oración al principio del párrafo, que resume el sentido del párrafo completo y que conecta con el párrafo anterior.\nRecursos de apoyo a la escritura académica de la Universidad de Chile"
  },
  {
    "objectID": "trabajos.html#a-tener-en-cuenta",
    "href": "trabajos.html#a-tener-en-cuenta",
    "title": "Trabajos",
    "section": "9.3 A tener en cuenta:",
    "text": "9.3 A tener en cuenta:\n\nlos conceptos centrales deben estar en las hipótesis y también luego operacionalizarse en variables. No presentar variables que no se relacionen con los conceptos centrales de la sección inicial\nsi hay muchos casos perdidos (mas de un tercio de datos originales), explicar claramente a qué se debe esta pérdida. Existe la posibilidad de recuperar casos perdidos de predictores categóricos (o recodificados a categóricos) agregando una categoría adicional de perdidos. Esto se explica en la guía de índices y transformación de variables.\ninterpretación de hipótesis e inferencia: las hipótesis nunca se comprueban o se descartan, solo se puede hablar de que existe o no existe evidencia a favor de la hipótesis planteada. Recordar que la ausencia de evidencia no es evidencia de ausencia.\nevitar términos técnicos estadísticos (ej: correlación) antes de la sección de metodología\nmantener coherencia entre conceptos, hipótesis, descripción de variables, análisis, discusión, ojalá siempre en el mismo orden."
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos",
    "section": "",
    "text": "En esta sección se irán subiendo una serie de recursos relacionados con el curso.",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#glosario-de-conceptos",
    "href": "resource/index.html#glosario-de-conceptos",
    "title": "Recursos",
    "section": "Glosario de conceptos",
    "text": "Glosario de conceptos\n\n\n\nConcepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#reporte",
    "href": "resource/index.html#reporte",
    "title": "Recursos",
    "section": "Reporte",
    "text": "Reporte\n\nTablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#estadística-descriptiva",
    "href": "resource/index.html#estadística-descriptiva",
    "title": "Recursos",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#uso-de-r",
    "href": "resource/index.html#uso-de-r",
    "title": "Recursos",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#inferencia",
    "href": "resource/index.html#inferencia",
    "title": "Recursos",
    "section": "Inferencia",
    "text": "Inferencia\n\nInfer: Inferencia estadística en R, acá video tutorial en español\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#visualización",
    "href": "resource/index.html#visualización",
    "title": "Recursos",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "resource/index.html#bases-de-datos",
    "href": "resource/index.html#bases-de-datos",
    "title": "Recursos",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación",
    "crumbs": [
      "Recursos",
      "Descripción"
    ]
  },
  {
    "objectID": "news/2024-11-18_guia-poster.html",
    "href": "news/2024-11-18_guia-poster.html",
    "title": "Guía para la elaboración de posters académicos",
    "section": "",
    "text": "← News\n\n\n\n\n\n\n\n\n\nLa evaluación del trabajo final del curso contempla su presentación en formato de póster de investigación (10% de la nota final del curso). Abajo se presenta una guía para su elaboración, y también se pone a disposición una plantilla en Canva como base para su diseño.\n\nElaborar un póster académico efectivo es fundamental para comunicar de manera clara y concisa los hallazgos de una investigación. A continuación, se presentan directrices esenciales para el diseño y contenido de un póster enfocado en análisis de estadística bivariada y contraste de hipótesis.\n1. Estructura del Póster\nUna organización lógica facilita la comprensión del contenido. Se recomienda incluir las siguientes secciones:\n\nTítulo: Debe ser claro y reflejar el tema central de la investigación.\nAutores y Afiliaciones: Incluir nombres completos y las instituciones correspondientes.\nIntroducción: Presentar el contexto, la relevancia del estudio y los objetivos planteados.\nMetodología: Describir el diseño del estudio, las variables analizadas y los métodos de recolección de datos y las técnicas estadísticas utilizadas, como el análisis bivariado y las pruebas de hipótesis aplicadas.\nAnálisis/Resultados: Presentar los hallazgos principales, apoyados con tablas y gráficos que faciliten la interpretación.\nDiscusión y Conclusiones: Interpretar los resultados, discutir su implicancia y sugerir posibles aplicaciones o investigaciones futuras.\nReferencias: Citar las fuentes consultadas siguiendo un formato académico estándar.\n\n2. Diseño Visual\nUn diseño atractivo y ordenado mejora la legibilidad y el impacto del póster. Considerar los siguientes aspectos:\n\nTipografía: Utilizar fuentes legibles; se recomienda un tamaño mínimo de 24 puntos para el texto principal y 36-48 puntos para el título.\nColores: Seleccionar una paleta de colores coherente que facilite la lectura y destaque las secciones importantes.\nEspaciado: Mantener espacios adecuados entre secciones para evitar la saturación visual.\nGráficos y Tablas: Incluir elementos visuales que complementen el texto y ayuden a ilustrar los resultados de manera clara.\n\n3. Contenido Específico sobre Estadística Bivariada y Contraste de Hipótesis\nDado el enfoque en estadística bivariada y contraste de hipótesis, es esencial detallar:\n\nVariables Analizadas: Definir claramente las variables independientes y dependientes.\nPruebas Estadísticas: Especificar las pruebas utilizadas (e.g., prueba t, chi-cuadrado) y justificar su elección.\nResultados de las Pruebas: Presentar los valores obtenidos, niveles de significancia y la interpretación de los mismos.\nConclusiones: Discutir si se rechaza o no la hipótesis nula y las implicancias de este resultado en el contexto del estudio.\n\n4. Herramientas y Recursos para el Diseño\nExisten diversas plataformas que facilitan la creación de pósters académicos:\n\nCanva: Ofrece plantillas personalizables para pósters de investigación.\nMind the Graph: Proporciona recursos para diseñar pósters científicos con elementos visuales atractivos.\nEdit.org: Brinda plantillas gratuitas para pósters académicos.\n\n5. Recomendaciones Finales\n\nRevisión: Antes de la presentación, revisar el póster en busca de errores ortográficos y asegurar la coherencia en el formato.\nFeedback: Solicitar opiniones de colegas o mentores para mejorar el contenido y diseño.\nPreparación para la Presentación: Practicar una breve exposición oral que resuma los puntos clave del póster, anticipando posibles preguntas del público.\n\nSiguiendo estas directrices, se podrá elaborar un póster académico que comunique eficazmente los resultados de la investigación en estadística bivariada y contraste de hipótesis."
  },
  {
    "objectID": "news/2024-10-20_tutoriales.html",
    "href": "news/2024-10-20_tutoriales.html",
    "title": "Videos Tutoriales",
    "section": "",
    "text": "← News\n\n\n\n\n\nElementos básicos\n\n\n\n\nLenguaje y trabajo en R\n\n\n\n\nTrabajo en R Studio\n\n\n\n\nRecodificación\n\n\n\n\nHerramientas de ayuda"
  },
  {
    "objectID": "news/2024-10-14_evaluacion2.html",
    "href": "news/2024-10-14_evaluacion2.html",
    "title": "Informaciones evaluación 2",
    "section": "",
    "text": "← News\nComo se puede ver en la página del programa del curso, la Evaluación de la Unidad 2 vale un 40% de la nota del curso: un 10% es práctico (análisis de datos basado en R) y 30% conceptual. Inicialmente la idea era separar en dos días la evaluación - un día teórico y otro práctico -, pero para no sobrecargar con instancias evaluativas finalemente la prueba será el día Martes 22 (8:30) y combinará preguntas de análisis y preguntas conceptuales."
  },
  {
    "objectID": "news/2024-10-14_evaluacion2.html#consideraciones",
    "href": "news/2024-10-14_evaluacion2.html#consideraciones",
    "title": "Informaciones evaluación 2",
    "section": "Consideraciones:",
    "text": "Consideraciones:\n\nLa prueba será frente al computador, para así poder realizar las preguntas de análisis de datos.\nLas preguntas conceptuales también se responderán en el computador\nLas respuestas tanto de análisis como conceptuales se responderán en un formulario habilitado en UCursos"
  },
  {
    "objectID": "news/2024-10-14_evaluacion2.html#cómo-será-la-evaluación",
    "href": "news/2024-10-14_evaluacion2.html#cómo-será-la-evaluación",
    "title": "Informaciones evaluación 2",
    "section": "¿Cómo será la evaluación?",
    "text": "¿Cómo será la evaluación?\n\nHabrá preguntas en tres temas:\n\ncorrelación\nmatrices de correlación y casos perdidos\nasociación en tablas de contingencia\n\nSerán preguntas puntuales de análisis e interpretación, y se calcula que cada pregunta requiere una dedicación de no más de 20 min, por lo que la prueba se puede contestar en aproximadamente una hora. De todas maneras, quienes requieran tiempo adicional, la prueba se podrá entregar hasta las 10:00\nCada tema tiene 4 puntos, 1 punto será por análisis de datos, y 3 por temas conceptuales/interpretación\nSe permitirá acceso a apuntes y a la página del curso online, no se permite el uso de otras plataformas como whatsapp o IA."
  },
  {
    "objectID": "news/2024-10-14_evaluacion2.html#cómo-prepararse",
    "href": "news/2024-10-14_evaluacion2.html#cómo-prepararse",
    "title": "Informaciones evaluación 2",
    "section": "¿Cómo prepararse?",
    "text": "¿Cómo prepararse?\n\nEn los últimos prácticos hay una sección de ejercicio autónomo, el realizar estos ejercicios y luego corregirlos (aparecen también desarrollados en la misma página) es la mejor forma de prepararse, tanto en términos de análisis como de interpretación\nRevisar el material de las presentaciones y lecturas sugeridas\nAnotarse en las asesorías grupales y también en el taller del Centro Idea\nSoftware: revisar que los ejercicios de los prácticos los puedan desarrollar bien en el computador que traerán a la evaluación. Quienes no pueden traer computador podrán realizar la evaluación en la sala de computación.\nSe realizará un ensayo de la evaluación el día lunes 21 (tal como en el caso de la evaluación anterior)"
  },
  {
    "objectID": "news/2024-10-07_Desarrollo ejercicio autonomo.html",
    "href": "news/2024-10-07_Desarrollo ejercicio autonomo.html",
    "title": "Desarrollo Ejercicio autónomo Práctico 3",
    "section": "",
    "text": "← News\n\n\n\n\nEl ejericio autónomo del práctico 3 se encuentra desarrollado en la página correspondiente, link directo aquí"
  },
  {
    "objectID": "news/2024-09-03_cambios evaluacion 1.html",
    "href": "news/2024-09-03_cambios evaluacion 1.html",
    "title": "Cambios en evaluación 1",
    "section": "",
    "text": "← News\n\n\n\n\nEn el plan original la Evaluación 1 y la Evaluación 2 se componían de dos partes cada una: teórica (30%) y práctica (5%) (ver sección de evaluación en el programa del curso). Dado que en esta primera unidad ha sido principalmente teórica y tendremos solo dos instancias prácticas, vamos a traspasar el 5% de la evaluación práctica a la evaluación 2, que tendrá por lo tanto un 10% de evaluación práctica además del 30% de evaluación teórica.\nLa evaluación 1 se llevará a cabo el día Martes 10 de Septiembre a las 8:30. El día lunes 9 vamos a realizar un repaso general de la Unidad 1 y ejercicios para preparar la prueba."
  },
  {
    "objectID": "news/2024-08-23_primera-practica.html",
    "href": "news/2024-08-23_primera-practica.html",
    "title": "Sesión práctica martes 27 de agosto",
    "section": "",
    "text": "← News\n\n\n\n\nAlgunas informaciones importantes:\n-El próximo martes 27 de agosto tendremos nuestra primera sesión práctica del curso.\n-En esta instancia contaremos con el equipo docente completo y ayudantes.\n-Aquellas personas que, por diversos motivos, no puedan contar con un computador personal para las sesiones del curso, les pedimos encarecidamente que rellenen este formulario: https://forms.gle/iGVJjAWRGYh9GGpZ8 Esta información nos permitirá ir organizando el uso de computadores de la sala de computación.\n-Nos dividiremos en dos grupos: una parte del curso en las salas C7 y C8 del aulario C (idealmente quienes dispongan de computador) y otra parte en la sala 345 de computación del edificio nuevo de Facso (para quienes no puedan contar con un computador).\n-Dentro de la próxima semana les enviaremos un correo respecto a la asignación de ayudantes para el asesoramiento en las unidades 1 y 2 del curso."
  },
  {
    "objectID": "news/2024-08-19_cambio-practico.html",
    "href": "news/2024-08-19_cambio-practico.html",
    "title": "Prácticos parten próxima semana (Martes 27)",
    "section": "",
    "text": "← News\n\n\n\n\nInicialmente en el programa estaba contemplado que esta semana el martes 20 comenzaba la primera sesión de prácticos, para lo cual debían traer sus computadores. Esto se modifica, el práctico es el próximo martes 27."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html",
    "href": "evaluations/plantilla_reporte/reporte.html",
    "title": "Título del trabajo grupal",
    "section": "",
    "text": "Definición de la problemática a abordar, su relevancia y principales conceptos.\nEn este apartado es importante considerar:\n\nRelevancia del tema de investigación.\nProblematización: señalar problema de investigación y principales antecedentes\nPrecisar los conceptos centrales a investigar: Ejemplo “vamos a analizar la participación informal, entendiendo por ello la frecuencia de participación en actividades como marchas, boycotts y en redes sociales” [cita que apoye la definición].\nMencionar el principal objetivo del trabajo y las hipótesis de investigación en el párrafo final de esta sección (ej: se espera que el nivel educacional sea mayor en zonas urbanas en relación a zonas rurales). Mencionar al menos tres hipótesis.\n\nEsta sección debe estar respaldada por al menos 5 referencias bibliográficas."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#datos",
    "href": "evaluations/plantilla_reporte/reporte.html#datos",
    "title": "Título del trabajo grupal",
    "section": "2.1 Datos",
    "text": "2.1 Datos\nDescripción detallada de los datos a utilizar. Acá también se puede insertar el chunk para llamar los datos que se van a analizar:"
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#variables",
    "href": "evaluations/plantilla_reporte/reporte.html#variables",
    "title": "Título del trabajo grupal",
    "section": "2.2 Variables",
    "text": "2.2 Variables\nDescripción de cada una de las variables, su operacionalización y medición. Esta sección también incluye una tabla de descriptivos básicos.\n\n\n\n\n\n\nNota\n\n\n\nAtención sobre recodificación de variables\nEs importante que las variables sean recodificadas en el sentido del atributo que se está midiendo de menos a más, es decir, que el mayor valor exprese la mayor presencia del atributo.\n\nEjemplo 1: si lo que se está midiendo es apoyo al aborto libre en una escala donde 5 es totalmente en desacuerdo y 1 totalmente de acuerdo, se deben recodificar los valores para que un mayor puntaje exprese mayor apoyo al aborto libre. En concreto: 1=5, 2=4, 4=2, 5=1.\nEjemplo 2: variable dicotómica 0: si vota, 1: no vota, debe ser recodificada a 1: si vota, 0: no vota."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#métodos",
    "href": "evaluations/plantilla_reporte/reporte.html#métodos",
    "title": "Título del trabajo grupal",
    "section": "2.3 Métodos",
    "text": "2.3 Métodos\nMencionar los métodos estadísticos a utilizar para el contraste de hipótesis y cálculo del tamaño de efecto."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#análisis-descriptivo",
    "href": "evaluations/plantilla_reporte/reporte.html#análisis-descriptivo",
    "title": "Título del trabajo grupal",
    "section": "3.1 Análisis descriptivo",
    "text": "3.1 Análisis descriptivo\nTablas y/o gráficos comentados, univariados y bivariados según sea más pertinente. Para esto considere medidas de tendencia central, dispersión y frecuencias, siempre considerando el nivel de medición de sus variables. En los casos que sea atingente, incluya los intervalos de confianza al 95 %."
  },
  {
    "objectID": "evaluations/plantilla_reporte/reporte.html#análisis-estadístico-bivariado",
    "href": "evaluations/plantilla_reporte/reporte.html#análisis-estadístico-bivariado",
    "title": "Título del trabajo grupal",
    "section": "3.2 Análisis estadístico bivariado",
    "text": "3.2 Análisis estadístico bivariado\nConsiderar la estimación de coeficientes de correlación y también medidas de asociación para variables categóricas. Esta parte del análisis se relaciona directamente con las hipótesis planteadas. Para esto realizar pruebas de hipótesis estadísticas, estadísticos de tamaño del efecto y tablas de contingencia / cruzadas, siempre considerando el nivel de medición de sus variables.\nAl final de esta sección también se realiza la discusión de resultados en relación a las hipótesis planteadas"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases",
    "section": "",
    "text": "En esta sección se encuentran disponibles los documentos de presentación que sirven de base a cada clase, en el menú de la izquierda Presentaciones. Los documentos son en formato html (no son ppt), producidos con Xaringan. Para verlos en pantalla completa presionar F sobre el documento, y para una vista general de todas las slides presionar O.\nTambién a la izquierda hay un link al Foro para hacer preguntas relacionadas con las clases.\nCada clase tiene como referencia lecturas que deben completarse antes de la sesión correspondiente.",
    "crumbs": [
      "Clases",
      "Descripción"
    ]
  },
  {
    "objectID": "content/13-content.html",
    "href": "content/13-content.html",
    "title": "Documentos dinámicos",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Documentos dinámicos"
    ]
  },
  {
    "objectID": "content/11-content.html",
    "href": "content/11-content.html",
    "title": "Asociación con categóricas 1",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 4"
    ]
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Inferencia en correlación y magnitud del coeficiente",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 2"
    ]
  },
  {
    "objectID": "content/06-content.html",
    "href": "content/06-content.html",
    "title": "Inferencia 5 - Prueba t + hipótesis direccionales",
    "section": "",
    "text": "Sesión del lunes, 25 de agosto de 2025\n\n\n\n\n\nDocumento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 5"
    ]
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Inferencia 3 - Intervalos de confianza",
    "section": "",
    "text": "Sesión del martes, 20 de agosto de 2024\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 3"
    ]
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Inferencia 1: Datos, probabilidad y distribuciones muestrales",
    "section": "",
    "text": "Sesión del miércoles, 6 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 1"
    ]
  },
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Prácticos",
    "section": "",
    "text": "Las clases se acompañan de guías de trabajo con énfasis en la aplicación práctica mediante el uso de software estadístico.\nLas guías se encontrarán disponibles en esta página (link a la izquierda). Habrá dos guías para la Unidad 1 (Inferencia), y 2 para la Unidad 2 (Asociación). La unidad 3 será eminentemente práctica y de aplicación.\nLas guías son desarrolladas de manera autónoma, y cada dos semanas los días martes habrá un espacio práctico de revisión de las guías y de consultas. Para ello se espera que quienes puedan traigan su computador a la sala, y quienes no tienen lo podrán hacer simultáneamente en la sala de computación 345.\nEn las prácticas vamos a trabajar con el software R, Versión 4.4.1.",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#descripción",
    "href": "assignment/index.html#descripción",
    "title": "Prácticos",
    "section": "Descripción",
    "text": "Descripción\nLas clases se acompañan de guías de trabajo con énfasis en la aplicación práctica mediante el uso de software estadístico.\nLas guías se encontrarán disponibles en esta página (link a la izquierda). Habrá dos guías para la Unidad 1 (Inferencia), y 2 para la Unidad 2 (Asociación). La unidad 3 será eminentemente práctica y de aplicación.\nLas guías son desarrolladas de manera autónoma, y cada dos semanas los días martes habrá un espacio práctico de revisión de las guías y de consultas. Para ello se espera que quienes puedan traigan su computador a la sala, y quienes no tienen lo podrán hacer simultáneamente en la sala de computación 345.\nEn las prácticas vamos a trabajar con el software R, Versión 4.4.1.",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#trabajo-con-software-r",
    "href": "assignment/index.html#trabajo-con-software-r",
    "title": "Prácticos",
    "section": "Trabajo con software R",
    "text": "Trabajo con software R\nPara los análisis estadísticos de este curso usamos el programa R, en parte porque es gratuito, pero la principal razón es que es de código abierto. Esto quiere decir que cualquier persona puede revisar cómo está hecho y aportar con modificaciones y procedimientos nuevos, como son las librerías que realizan funciones específicas.\nEl carácter de apertura de R posee muchas ventajas, pero también conlleva complicaciones. Se actualiza permanentemente, así como también las librerías, y esto puede generar problemas de compatibilidad y de fallas en ejecución del código de análisis.\nPara minimizar estos posibles problemas en este curso, vamos a:\n\ntrabajar con la misma y última versión de R\nevitar uso de tilde, ñ, espacios y mayúsculas tanto en carpetas y archivos, así como también en los nombres de las variables",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "href": "assignment/index.html#sobre-errores-y-consultas-sobre-problemas-con-r-y-ejecución-de-código",
    "title": "Prácticos",
    "section": "Sobre errores y consultas sobre problemas con R y ejecución de código",
    "text": "Sobre errores y consultas sobre problemas con R y ejecución de código\nEn caso de preguntas sobre las clases hacerlas en Foro prácticos\n\nInstalación de R & RStudio\nPara esta versión del curso vamos a trabajar con el programa R Version 4.4.1 y con RStudio, que ofrece un entorno más amigable para trabajar con R.\nPara instalar R: ir a https://cran.r-project.org/index.html y bajar/instalar la versión correspondiente a la plataforma utilizada (Windows, Mac o Linux)\nPara instalar RStudio: ir a https://rstudio.com/products/rstudio/ y bajar/instalar RStudio desktop, Open Source License (libre).\nEn caso de dudas se puede revisar el siguiente video tutorial de instalación de R & RStudio, preparado por Julio Iturra (apoyo docente) del curso Estadística Multivariada 2020:\n\n\n\n\n\nSi por alguna razón se prefiere trabajar sin descargar, también se puede utilizar RCloud, abajo un tutorial preparado por Valentina Andrade para el curso de Estadística Multivariada:\n\n\n\n\n\n\nSobre el trabajo en hojas de código en RStudio\n\nEl trabajo de análisis en RStudio se efectua en una hoja de código (o R script o sintaxis, o para los usuarios de Stata la do-file), que es donde se anotan los comandos y funciones. Para abrir una hoja, en RStudio ir a File &gt; New File &gt; R Script (o ctrl+shift+N),y aparecerá un panel con una pestaña “Untitled” (sin título). Esta es la hoja de código donde se anotan los comandos.\nLos contenidos de las hojas de código son básicamente 2:\n\ncomandos o funciones: se escriben en la hoja, y para ejecutarlos se debe posicionar el cursor en la línea respectiva y ctrl+enter, el resultado aparecerá en el panel de resultados o Consola.\ntexto: para escribir títulos, comentarios, y todo lo que permita entender qué se está haciendo, al principio de la línea respectiva escribir el signo #\n\nPara grabar nuestra hoja de código y así respaldar nuestros análisis, File &gt; Save (o ctrl+s), y dar un nombre al archivo. Recordar: breve, sin espacios ni tildes ni eñes. Por defecto, la extensión de estos archivos es .R",
    "crumbs": [
      "Prácticos",
      "Descripción"
    ]
  },
  {
    "objectID": "assignment/foro-practicos.html",
    "href": "assignment/foro-practicos.html",
    "title": "Foro prácticos",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre llas guías prácticas. Para poder participar en el foro hay que abir una cuenta en Github\n\n¿Cuándo usar este foro?\n\n\n\n\n\nMuchas veces sucede que los códigos de análisis no resultan, lo que puede deberse a errores menores en la escritura de código, otras a versiones de librerías, y la mayoría a que R es algo mañoso.\nCuando hay un error o el código no corre lo importante es evitar que la frustración lleve a desmotivarse o tirar el computador por la ventana. Por eso se sugiere:\n\nintentar resolverlo por no más de 10 minutos: en este tiempo revisar bien el material disponible y lo que hay en la web. Un lugar clásico donde se discuten problemas de código es Stack overflow.\nsi no se logra solucionar entonces se sugiere encarecidamente usar el foro al final de esta página, ya que nos sirve para dejar la respuesta disponible para otr_s compañer_s que pueden tener la misma duda (generalmente es así)\n\n\n\n¿Cómo preguntar?\n\nDesripción general del problema, código y error que ocurre\nSi con esta información no basta para solucionar el problema, entonces se le podrá solicitar información adicionales, tales como el archivo de código y la información de la versión de las librerías que aparece al ejecutar el comando sessionInfo()\n\n\n\nForo prácticos",
    "crumbs": [
      "Prácticos",
      "Foro Prácticos"
    ]
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Presentación",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nForo\nEn caso de preguntas sobre las clases hacerlas en Foro Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Introducción"
    ]
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Inferencia 2: Curva normal y error estándar",
    "section": "",
    "text": "Documento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 2"
    ]
  },
  {
    "objectID": "content/05-content.html",
    "href": "content/05-content.html",
    "title": "Inferencia 4 - Test de hipótesis",
    "section": "",
    "text": "Sesión del lunes, 18 de agosto de 2025\n\n\n\n\n\nDocumento de presentación\n\n\n\n\nLink al Foro de Clases",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Inferencia 4"
    ]
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Bivariada 1 - Asociación y covarianza",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 1"
    ]
  },
  {
    "objectID": "content/10-content.html",
    "href": "content/10-content.html",
    "title": "Ordinales y matrices",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 3"
    ]
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Asociación con categóricas 2: Chi 2",
    "section": "",
    "text": "Documento de presentación",
    "crumbs": [
      "Clases",
      "Presentaciones",
      "Bivariada 5"
    ]
  },
  {
    "objectID": "content/foro-clases.html",
    "href": "content/foro-clases.html",
    "title": "Foro clases",
    "section": "",
    "text": "Foro para compartir dudas, aclaraciones, sugerencias sobre los contenidos del curso vistos en clases. Para poder participar en el foro hay que abir una cuenta en Github",
    "crumbs": [
      "Clases",
      "Foro Clases"
    ]
  },
  {
    "objectID": "evaluations/index.html",
    "href": "evaluations/index.html",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "evaluations/index.html#descripción",
    "href": "evaluations/index.html#descripción",
    "title": "Evaluaciones",
    "section": "",
    "text": "En esta sección se encuentran disponibles las evaluaciones vigentes del curso."
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Code examples",
    "section": "",
    "text": "Visit this section after you have finished the readings and lecture videos. It contains fully annotated R code and other supplementary information and it will be indispensable as you work on your problem sets and project.\nMany sections also contain videos of me live coding the examples so you can see what it looks like to work with R in real time. You’ll notice me make all sorts of little errors, which is totally normal—everyone does!"
  },
  {
    "objectID": "news/2024-08-19_inicio.html",
    "href": "news/2024-08-19_inicio.html",
    "title": "Informaciones por acá",
    "section": "",
    "text": "← News\n\n\n\n\nEstimad_s estudiantes, acá en esta pestaña quedará registro de las informaciones y actualizaciones del curso. De todas maneras se enviará link por correo a UCursos cuando haya noticias relevantes."
  },
  {
    "objectID": "news/2024-09-02_equipo docente y ayudantes.html",
    "href": "news/2024-09-02_equipo docente y ayudantes.html",
    "title": "Equipo docente y ayudantes",
    "section": "",
    "text": "← News\n\n\n\n\n2 actualizaciones respecto del equipo a cargo del curso:\n\ncomo se informó por UCursos, la apoyo docente Daniela Olivares no seguirá en su rol a partir de este mes de Septiembre, y se suma al equipo Martín Venegas como nuevo apoyo docente. Martín también es sociólogo UChile y actualmente trabaja en el INE. Bienvenido!\nse completa el equipo de ayudantes luego de la segunda ronda de postulaciones, son 11 en total y pueden ver sus nombres en la página inicial del curso."
  },
  {
    "objectID": "news/2024-09-04_taller_centro_idea.html",
    "href": "news/2024-09-04_taller_centro_idea.html",
    "title": "Taller Centro IDEA",
    "section": "",
    "text": "← News\n\n\n\n\nEl centro IDEA está ofreciendo una instancia de tutorías específica para la Unidad I (Inferencia) este viernes 6 de septiembre a las 12:00:"
  },
  {
    "objectID": "news/2024-10-10_tutorias_grupales.html",
    "href": "news/2024-10-10_tutorias_grupales.html",
    "title": "Nuevo sistema de asesorías grupales",
    "section": "",
    "text": "← News\n\n\n\n\n\nCon el objetivo de dar asesoría y acompañamiento en la preparación para la segunda evaluación del curso (Martes 22 de Octubre), hemos implementado una nueva modalidad que reemplaza la asignación previa de ayudantes realizada durante la Unidad 1. Ahora,se podrá postular a asesorías por grupos conformados según su preferencia.\nPasos:\n\nConformación de grupo: entre 3 a 8 integrantes\nUn integrante del grupo (coordinador) se inscribe en el siguiente formulario, hasta el día lunes 14 a las 12:00 PM\nEl día martes 15 se les comunicará el horario y ayudante asignado para esta tutoría\n\nPor cualquier duda respecto a la inscripción, escribir Andreas Laffert (apoyo docente) vía UCursos.\n(Nota: estos grupos no son - necesariamente - los mismos que luego se inscribirán para realizar el trabajo grupal de la Unidad 3)."
  },
  {
    "objectID": "news/2024-10-14_taller_centro_idea2.html",
    "href": "news/2024-10-14_taller_centro_idea2.html",
    "title": "Taller Centro Idea 2",
    "section": "",
    "text": "← News\n\n\n\n\nEl centro IDEA está ofreciendo nuevamente un taller para preparar la evaluación del curso, esta vez de la Unidad II. Será este miércoles 16 de Octubre a las 14:30"
  },
  {
    "objectID": "news/2024-11-04_trabajo_final.html",
    "href": "news/2024-11-04_trabajo_final.html",
    "title": "Trabajo final",
    "section": "",
    "text": "← News\n\n\n\n\n\nSe agrega información en el sitio sobre la realización de los trabajos finales, ver pestaña arriba 👆"
  },
  {
    "objectID": "news/2024-11-19_informaciones-final-curso.html",
    "href": "news/2024-11-19_informaciones-final-curso.html",
    "title": "Informaciones varias final del curso",
    "section": "",
    "text": "← News\nQuedan las últimas semanas y bastantes cosas que hacer, van algunas informaciones y definiciones sobre esta etapa final del curso:"
  },
  {
    "objectID": "news/2024-11-19_informaciones-final-curso.html#sobre-presentación-en-formato-póster",
    "href": "news/2024-11-19_informaciones-final-curso.html#sobre-presentación-en-formato-póster",
    "title": "Informaciones varias final del curso",
    "section": "Sobre presentación en formato póster",
    "text": "Sobre presentación en formato póster\nEn breve: se suspende. En extenso: luego de la sesión de asesorías grupales de ayer nuestra impresión es que la mayor parte de los trabajos va bien encaminado, pero aún en una fase muy inicial considerando el plazo de entrega (viernes prox. semana). Nos parece que llevar acabo la presentación de resultados finales en formato póster el próximo lunes – como estaba planificado – establece mucha presión para varios grupos, lo que podría restar energía y tiempo para la elaboración del reporte final. Además, al suspender podemos usar el espacio inicialmente destinado a presentar poster (próx. lunes 25) a una segunda sesión de asesorías grupales en horario de clases. Entonces, nos concentraremos solo en el reporte como instancia final de evaluación, que tendrá una ponderación del 30 %."
  },
  {
    "objectID": "news/2024-11-19_informaciones-final-curso.html#plantilla-de-trabajo",
    "href": "news/2024-11-19_informaciones-final-curso.html#plantilla-de-trabajo",
    "title": "Informaciones varias final del curso",
    "section": "Plantilla de trabajo",
    "text": "Plantilla de trabajo\nPara facilitar la elaboración del trabajo en formato Quarto hemos puesto a disposición una plantilla (template) que facilita la escritura y organización del informe. La plantilla es una carpeta organizada en base al protocolo IPO, se puede descargar comprimida aquí. Al descomprimirla, ejecutar el archivo reporte.Rproj, se abrirá RStudio en modo proyecto, por lo tanto la carpeta base para todas las operaciones es la carpeta reporte. El principal archivo es reporte.qmd (qmd es la extensión de archivos Quarto), abrirlo y renderizar con el botón render de RStudio. Luego completar cada una de las secciones."
  },
  {
    "objectID": "news/2024-11-19_informaciones-final-curso.html#pruebas-recuperativas",
    "href": "news/2024-11-19_informaciones-final-curso.html#pruebas-recuperativas",
    "title": "Informaciones varias final del curso",
    "section": "Pruebas recuperativas",
    "text": "Pruebas recuperativas\nTal como estaba informado desde el principio del semestre en la planificación del curso, las pruebas recuperativas (evaluación 1 y evaluación 2) son el Martes 26 de Noviembre a las 8:30, Aulario C7/C8. Los contenidos para cada prueba son los mismos que para las versiones originales (respectivamente), y el formato de evaluación también es análogo. En el caso de la prueba 2 recordar las informaciones correspondientes, principalmente en lo que respecta al uso de software (R y librerías actualizadas), y también traer computador a la sala para realizar la prueba.\nPara quienes deban 2 pruebas, comenzarán con la prueba 1 a las 8:30, y luego 10:15 nos pasamos a la sala 345 para rendir la prueba 2.\nNo existe otra instancia de recuperación de pruebas."
  },
  {
    "objectID": "news/2024-11-19_informaciones-final-curso.html#exámenes",
    "href": "news/2024-11-19_informaciones-final-curso.html#exámenes",
    "title": "Informaciones varias final del curso",
    "section": "Exámenes",
    "text": "Exámenes\nEl examen de primera oportunidad está fijado para el día miércoles 11 de Diciembre desde las 9:30, y el de segunda el lunes 16 Diciembre desde las 10:15. Será oral y entra toda la materia del curso.\nLos criterios de nota de eximición se ajustan. La nota de eximición será promedio 5.0 o superior (en lugar de 5.5). También se flexibiliza lo de la obligación de dar examen en caso de una nota bajo 4, y se aplicará solo a quienes tengan menos del 50% de asistencia. Es decir, si alguien tiene una nota bajo 4, pero tiene promedio 5.0 o superior, y ha asistido al menos a un 50% de las clases, se exime. Quienes tengan dos notas bajo 4 dan examen sin excepción."
  },
  {
    "objectID": "resource/varios.html",
    "href": "resource/varios.html",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#reporte",
    "href": "resource/varios.html#reporte",
    "title": "Varios",
    "section": "",
    "text": "Tablas con R, con ejemplo de canciones de Spotify\nIntroduction to Quarto",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#estadística-descriptiva",
    "href": "resource/varios.html#estadística-descriptiva",
    "title": "Varios",
    "section": "Estadística descriptiva",
    "text": "Estadística descriptiva\n\nCurso Estadística Descriptiva Sociología UChile, 1er Sem 2023",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#uso-de-r",
    "href": "resource/varios.html#uso-de-r",
    "title": "Varios",
    "section": "Uso de R",
    "text": "Uso de R\n\nConocimientos básicos de programación en R\nImportar datos en R\nProcesamiento y análisis de datos en R (tidyverse)\nProcesamiento y análisis de datos en R (base)\nMás para aprender R",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#inferencia",
    "href": "resource/varios.html#inferencia",
    "title": "Varios",
    "section": "Inferencia",
    "text": "Inferencia\n\nPor qué se divide la varianza por N-1?\nStatistical Inference via Data Science A ModernDive into R and the Tidyverse\nIntroduction to modern statistics (Mine Çetinkaya-Rundel and Johanna Hardin)\nInferencia univariada",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#visualización",
    "href": "resource/varios.html#visualización",
    "title": "Varios",
    "section": "Visualización",
    "text": "Visualización\n\nVisualización descriptiva de datos en R\nR Graph Gallery",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/varios.html#bases-de-datos",
    "href": "resource/varios.html#bases-de-datos",
    "title": "Varios",
    "section": "Bases de datos",
    "text": "Bases de datos\n\nBases de datos para trabajos o investigación",
    "crumbs": [
      "Recursos",
      "Guías",
      "Varios"
    ]
  },
  {
    "objectID": "resource/glosario.html",
    "href": "resource/glosario.html",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "resource/glosario.html#glosario-de-conceptos",
    "href": "resource/glosario.html#glosario-de-conceptos",
    "title": "Glosario de conceptos",
    "section": "",
    "text": "Concepto\nDefinición\n\n\n\n\nEstadística \nConjunto de métodos y herramientas que involucra la recopilación, análisis, interpretación y presentación de datos numéricos con el objetivo de describir patrones, relaciones y tendencias en fenómenos naturales o sociales.\n\n\nReproducibilidad \nLa capacidad de regenerar un experimento, análisis o estudio utilizando los mismos datos y métodos para llegar a los mismos resultados originales, verificando y asegurando la validez de los hallazgos.\n\n\nCiencia Social Abierta \nUn enfoque en la investigación social que promueve la transparencia, el acceso abierto a datos, métodos y resultados, y la colaboración entre investigadores para mejorar la calidad y confiabilidad de la investigación.\n\n\nProtocolo IPO (Input-Process-Output) \nSistema digital de carpetas interconectadas: entrada, proceso y salida. Se utiliza para organizar, procesar y documentar los datos y código de un proyecto de investigación para que cualquier persona pueda ejecutarlo y compartirlo.\n\n\nR project \nCarpeta raíz organizada donde trabajas en un proyecto concreto en el lenguaje de programación R, permitiéndote gestionar archivos, paquetes y configuraciones de manera específica para ese proyecto.\n\n\nTexto plano \nTipo de texto sin formato especial que se puede leer independiente del lector que se utilice.\n\n\nMarkdown \nClase especial de lenguaje que permite darle formato a texto simple con pocas marcas. Se utiliza comúnmente para escribir documentos simples con formato, como páginas web, documentación y presentaciones.\n\n\nDocumentos dinámicos \nArchivos que combinan texto plano y código de análisis (gráficos, tablas y resultados), de manera simultánea en un solo documento, permitiendo la generación automática y reproducible de resultados actualizados a medida que cambian los datos o parámetros.\n\n\nRMarkdown \nUna extensión de Markdown en el entorno R que permite la integración simultánea de texto plano y código R y su ejecución en el documento, lo que facilita la creación de documentos dinámicos con análisis estadísticos y visualizaciones.\n\n\nLibrerías \nConjuntos de funciones y herramientas predefinidas que se pueden utilizar en lenguajes de programación, como R, para realizar tareas específicas sin tener que escribir todo el código desde cero.\n\n\nKnitear \nProceso de compilación secuencial de código y resultados de ejecución en un documento RMarkdown, generando un documento final con texto formateado, código y gráficos integrados.\n\n\nRenderizar \nEn el contexto de RMarkdown se refiere al proceso de convertir el código y contenido en un documento legible y presentable. En otras palabras, cuando renderizas un documento RMarkdown, estás transformando el código, texto y elementos visuales en un formato final, como un informe, una presentación o un documento HTML, que pueda ser compartido o presentado a otros de manera comprensible.\n\n\nYAML \nAcrónimo de “YAML Ain’t Markup Language”, es un formato de serialización de datos legible por humanos que se utiliza para configurar y definir la estructura de datos en muchos programas y aplicaciones. En RMarkdown corresponden al encabezado de instrucciones generales del documento.\n\n\nChunk \nUn bloque de código, que puede ser en R, en un documento RMarkdown, rodeado por marcas especiales que indican al sistema cómo manejar y ejecutar ese fragmento de código, y luego mostrar sus resultados en el documento final.",
    "crumbs": [
      "Recursos",
      "Guías",
      "Glosario de conceptos"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Programa",
    "section": "",
    "text": "Prof. Juan Carlos Castillo\n   325 Sociología FACSO, Universidad de Chile\n   juancastillov@uchile.cl\n   Agendar reunión\n\n\n\n\n\n   Lunes y Miércoles\n   04 Agosto al 26 de Noviembre - 2025\n   08:30-10:00 (Lunes) y 8:30-10:00 (Miércoles)\n   Lunes - Aulario C6, Miércoles - Aulario B1 & FACSO 345\n   Slack"
  },
  {
    "objectID": "syllabus.html#sobre-el-sentido-general-del-curso",
    "href": "syllabus.html#sobre-el-sentido-general-del-curso",
    "title": "Programa",
    "section": "Sobre el sentido general del curso",
    "text": "Sobre el sentido general del curso\nEn este curso vamos a aprender tres cosas principales:\n\ninferencia: los resultados que encontramos en nuestra muestra, ¿se encuentran también en la población de la cual proviene la muestra?\nmedidas de asociación entre variables: tamaño y significación estadística\nreporte y reproducibilidad de los análisis estadísticos: nuestros análisis se reflejan en productos como tablas y gráficos. No basta con entenderlos e interpretarlos, sino también es fundamental una buena comunicación."
  },
  {
    "objectID": "syllabus.html#propósito-general-del-curso",
    "href": "syllabus.html#propósito-general-del-curso",
    "title": "Programa",
    "section": "Propósito general del curso",
    "text": "Propósito general del curso\nAl finalizar el curso los estudiantes conocerán los fundamentos del análisis estadístico inferencial. Se espera que los estudiantes sean capaces de:\n\nelaborar de manera pertinente hipótesis estadísticas\naplicar estadísticos de asociación bivariada, a partir de los cuáles puedan desarrollar análisis de problemas sociales\ncorroborar el cumplimiento de las condiciones de aplicación de cada estadístico\nutilizar software de análisis estadístico\ncontrastar hipótesis de investigación\nelaborar conclusiones integrando fundamentos teóricos con herramientas de análisis estadístico de resultados.\n\nComplementariamente se espera que los estudiantes adquieran herramientas que les permitan comunicar resultados de investigación en contextos sociales, profesionales y académicos."
  },
  {
    "objectID": "syllabus.html#competencias",
    "href": "syllabus.html#competencias",
    "title": "Programa",
    "section": "Competencias",
    "text": "Competencias\n1a. Delimitar, conceptualizar y analizar diversos objetos de investigación social, con especial énfasis en aquellos relacionados con los procesos de transformación del país y Latinoamérica\n1b. Manejar diversas estrategias metodológicas de las ciencias sociales\n1c. Manejar un conjunto de herramientas para el procesamiento y análisis de información\n1d. Transmitir los conocimientos derivados de la práctica investigativa, así como aquellos adquiridos durante el proceso formativo."
  },
  {
    "objectID": "syllabus.html#subcompetencias",
    "href": "syllabus.html#subcompetencias",
    "title": "Programa",
    "section": "Subcompetencias",
    "text": "Subcompetencias\n\n1.4 Contribuir a generar conocimiento sociológico en el marco de estudios y/o procesos de investigación donde se articulen creativamente las dimensiones teórica, metodológica y práctica.\n1.5 Comunicar los saberes disciplinares de manera pertinente a las características de distintos contextos y audiencias, utilizando diversas estrategias y formatos."
  },
  {
    "objectID": "syllabus.html#resultados-del-aprendizaje",
    "href": "syllabus.html#resultados-del-aprendizaje",
    "title": "Programa",
    "section": "Resultados del aprendizaje",
    "text": "Resultados del aprendizaje\n\nComprende, domina y es capaz de explicar los elementos conceptuales subyacentes a la determinación de la asociación poblacional entre dos variables a partir del análisis de una muestra, y es capaz de traducir hipótesis derivadas de la teoría sociológica en hipótesis estadísticas posibles de contrastar empíricamente con los datos.\nEs capaz de seleccionar y usar herramientas estadísticas adecuadas para evaluar la asociación entre dos variables considerando las características de los datos y las condiciones de aplicación de cada técnica.\nLogra interpretar desde un punto de vista estadístico y sociológico los resultados derivados de pruebas estadísticas para analizar la relación entre dos variables.\nEs capaz de reportar y comunicar adecuada y eficientemente los resultados de los análisis estadísticos"
  },
  {
    "objectID": "syllabus.html#saberes-contenidos",
    "href": "syllabus.html#saberes-contenidos",
    "title": "Programa",
    "section": "Saberes / Contenidos",
    "text": "Saberes / Contenidos\n\nUnidad I: Inferencia\n\nDatos, variables y probabilidad\nCurva normal y error estándar\nIntervalos de confianza\nTest de hipótesis - Pruebas t y Z\nHipótesis no direccionales y para proporciones\n\n\n\nUnidad II: Asociación\n\nAsociación y covarianza\nCorrelación de Pearson\nCorrelación con variables ordinales\nMatrices y tamaños de efecto en correlación\nAsociación con variables categóricas\n\n\n\nUnidad III: Reporte\n\nResponder problemas de investigación de lógica bivariada con datos reales\nEscritura de reportes de investigación\nVisualización de datos\nPresentación de resultados"
  },
  {
    "objectID": "syllabus.html#metodología",
    "href": "syllabus.html#metodología",
    "title": "Programa",
    "section": "Metodología",
    "text": "Metodología\n\nSesiones de clases lectivas presenciales semanales, donde se presentarán los aspectos centrales de los contenidos correspondientes a la semana.\nPrácticos: los temas del curso se acompañan de guías prácticas de aplicación de contenidos. Estas guías están diseñadas para ser desarrolladas de manera autónoma, y también habrá espacio de revisión y consultas en el espacio de clases.\nTrabajos: se desarrollarán trabajos de investigación que permitirán a l_s participantes aplicar contenidos y recibir retroalimentación de su desempeño. Los trabajos serán asesorados por ayudantes que se asignarán a cada grupo.\n\nEl semestre comienza con clases lectivas, y posteriormente se integran progresivamente elementos prácticos y de aplicación.\n\nLas clases en general se acompañan de documentos de presentación, que estarán disponibles antes de la sesión en la página de Clases, y están desarrollados con base en Rmarkdown/Xaringan. Estos documentos no son:\n\n“la clase”\nautoexplicativos (ni aspiran a serlo)\n“el ppt” (ni menos “la ppt”)"
  },
  {
    "objectID": "syllabus.html#evaluación",
    "href": "syllabus.html#evaluación",
    "title": "Programa",
    "section": "Evaluación",
    "text": "Evaluación\nEl curso tendrá tres instancias de evaluación :\n\nEvaluación 1: Inferencia (30%, teórico)\nEvaluación 2: Asociación (40% = 30% teórico + 10% práctico)\nEvaluación 3: Reporte de aplicación - trabajo grupal (30%= 25% reporte escrito + 5% presentación/cápsula)\n\nLa nota ponderada de las evaluaciones equivaldrá al 60% de la nota del curso y el examen final al 40% restante.\nLas evaluaciones se distribuyen en el semestre de la siguiente manera:\n\n\n\n\n\n\n\nATENCIÓN\n\n\n\nLas fechas de evaluación no se cambian por respeto a la planificación de los tiempos de tod_s quienes participan en el curso y el cumplimiento apropiado de los objetivos de aprendizaje.\n\n\n\n\n\n\n\n\nSobre las pruebas\n\n\n\n\nLas evaluaciones de las unidades 1 y 2 son en la sala de clases y se realizan de manera individual.\nHay preguntas sobre conceptos, y principalmente cálculos e interpretación\nEntra toda la materia de la unidad, lo visto en clase y los textos obligatorios.\nTodo lo que se requiere para realizar los ejercicios de la prueba está en la prueba, no requiere aprenderse las fórmulas de memoria ni tampoco valores específicos (ej: valores críticos de rechazo)\nLa prueba comenzará puntual, no se puede ingresar ni salir de la sala una vez comenzada la evaluación.\nSi alguien tiene alguna emergencia y necesita salir podrá contar con la compañía y apoyo de algun_ de l_s ayudantes en sala."
  },
  {
    "objectID": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "href": "syllabus.html#inasistencias-y-atraso-en-entregas",
    "title": "Programa",
    "section": "Inasistencias y atraso en entregas",
    "text": "Inasistencias y atraso en entregas\nLos justificativos por ausencia o atraso se realizan en la secretaría de carrera. Lo que la carrera informe como justificado, es lo que se va a considerar en el curso. No enviar justificativos a equipo docente y a ayudantes directamente, no es necesario ni apropiado para l_s estudiantes tener que exponer situaciones personales.\nEn caso de faltar a alguna de las evaluaciones existirá una única fecha para evaluaciones recuperativas. Si en esa fecha no es posible asistir por motivos justificados, entonces pasará directo a examen.\nEn el caso de los trabajos, en caso de atraso se descontará 0.5 por día adicional. Si el trabajo no se entrega luego del tercer día de atraso será calificado con nota 1.0"
  },
  {
    "objectID": "syllabus.html#requisitos-de-aprobación",
    "href": "syllabus.html#requisitos-de-aprobación",
    "title": "Programa",
    "section": "Requisitos de aprobación",
    "text": "Requisitos de aprobación\nRequisitos de eximición a examen:\n\ncontar con un promedio ponderado igual o superior a 5.5\nno tener nota bajo 4.0 en ninguna de las evaluaciones\n\nRequisitos para presentación a examen:\n\nPodrán presentarse al examen de primera oportunidad los estudiantes que hayan obtenido una calificación final igual o superior a 3.5.\nEl examen de segunda oportunidad será para aquellos estudiantes que presenten una nota igual o inferior a 3.5 o aquellos que en el examen de primera oportunidad no hubiesen logrado una nota igual o superior a 4.0."
  },
  {
    "objectID": "syllabus.html#bibliografía-obligatoria",
    "href": "syllabus.html#bibliografía-obligatoria",
    "title": "Programa",
    "section": "Bibliografía Obligatoria",
    "text": "Bibliografía Obligatoria\nCapítulos correspondientes a cada sesión de los siguientes textos principales:\n\nRitchey, F. (2008) Estadística para las ciencias sociales. McGraw-Hill: México.\nMoore (2010) Estadística aplicada básica. Barcelona: Antoni Bosch.\nPardo, Ruiz y San Martín (2015). Análisis de Datos en Ciencias Sociales y de la Salud I. Editorial Síntesis: Madrid."
  },
  {
    "objectID": "syllabus.html#bibliografía-complementaria",
    "href": "syllabus.html#bibliografía-complementaria",
    "title": "Programa",
    "section": "Bibliografía Complementaria",
    "text": "Bibliografía Complementaria\nWickham, H., & Grolemund, G. (2016). R for data science: import, tidy, transform, visualize, and model data (First edition). Sebastopol: O’Reilly.\nField, A., Milles, J., & Field, Z. (2012). Discovering statistics using R. London: Sage.\nSalkind, N. J. (Ed.). (2010). Encyclopedia of research design (Vol. 1). Sage.\nLevin, J. & Levin, W. (1997). Fundamentos de Estadística en la Investigación Social (Vol.2). Oxford University Press."
  },
  {
    "objectID": "syllabus.html#sobre-participación-y-comunicación",
    "href": "syllabus.html#sobre-participación-y-comunicación",
    "title": "Programa",
    "section": "Sobre participación y comunicación",
    "text": "Sobre participación y comunicación\n\nSe espera asistencia y participación activa, tanto a las sesiones lectivas como a las prácticas. Se pasará lista en todas las sesiones. No habrá penalización por inasistencia, pero si llevaremos registro principalmente con objetivos de monitoreo y retroalimentación del curso.\nInformar flexibilidades académicas al principio del semestre (en caso que la jefatura de carrera no lo haga de manera centralizada). Las flexibilidades academicas no aplican para cambios de fechas de evaluaciones grupales.\nSe espera y enfatiza la participación activa por distintos canales disponibles. Estos son:\n\ncontacto por correo con equipo docente del curso (profesor y apoyos docentes)\nespacio para resolver dudas individualmente al final de la clase\nreuniones con equipo docente, para lo cual se deben inscribir previamente en la página inicial de este sitio\nforos, disponibles tanto para las clases como para los prácticos.\nmentorías con ayudantes asignados\n\nTambién se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”, que si bien puede intentar transmitir cercanía finalmente expresan minimización de la contraparte. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo están siendo, se solicita reportar para solucionar la situación.\nNo se responderán mensajes fuera del horario laboral (incluyendo por supuesto fines de semana)."
  },
  {
    "objectID": "syllabus.html#programación-de-sesiones",
    "href": "syllabus.html#programación-de-sesiones",
    "title": "Programa",
    "section": "Programación de sesiones",
    "text": "Programación de sesiones\nVisitar la página de Planificación."
  },
  {
    "objectID": "news/2024-08-28_asignacion_ayudantes1.html",
    "href": "news/2024-08-28_asignacion_ayudantes1.html",
    "title": "Asignación asesorías ayudantes",
    "section": "",
    "text": "← News\n\n\n\n\nDurante las dos primeras unidades del curso l_s estudiantes están asignados a un/a ayudante para consultas y/o apoyo con los contenidos del curso. Sus ayudantes se contactarán con uds. para indicarles la forma y momentos de asesoría, también pueden ser contactados directamente mediante el correo de UCursos.\n\n\n\n\n\nAyudante\nEstudiante\n\n\n\n\nAntonia Jiménez F.\nAlarcón Riveros, Milen Valentina\n\n\n\nArriagada Rodríguez, Javiera Ignacia\n\n\n\nCelpa Bugueño, Álvaro Giovanni\n\n\n\nDíaz Devia, Eduardo Ignacio\n\n\n\nHernández Osses, Antonia Margarita\n\n\n\nHuerta Carrasco, Rodrigo Javier\n\n\n\nKovacevic Ardiles, Ruby Mladenka\n\n\n\nNavarro Sánchez, Camila Alexandra\n\n\n\nPadilla Maureira, Belén Monserrat\n\n\n\nZanca Garrido, Andrés Ignacio\n\n\nCristóbal Mejías G.\nAntil Contreras, Ana Paula\n\n\n\nBeroíza Aguilar, Benjamín Daniel David\n\n\n\nFuentes Fernández, Víctor Javier\n\n\n\nOlmos Jara, Vicente Martín\n\n\n\nRaccagni Mancilla, Matilda Isidora\n\n\n\nRendic Gomez, Andres Nicolas\n\n\n\nVásquez Campos, Fernanda María José\n\n\n\nVega Villanueva, Martina Alejandra\n\n\nFernanda Zúñiga M.\nÁlvarez Cárdenas, Javiera Ignacia\n\n\n\nCastro Rojas, Joel Wilson\n\n\n\nDuclos González, Gaspar\n\n\n\nFaúndez Ramírez, Jennifer Paola\n\n\n\nGonzález Núñez, Bastián Antonio\n\n\n\nGuzmán Reyes, Pablo Antonio\n\n\n\nMontecinos Quintanilla, Valentina Antonia\n\n\n\nSantos Chavarría, Catalina Paz\n\n\nIsmael Aguayo\nBustos Pérez, Benjamín Alfredo\n\n\n\nCastillo Rojas, Anahi Constanza\n\n\n\nChateau Vives, Manuela\n\n\n\nMaldonado Acevedo, Agustín Eduardo\n\n\n\nMorales Verdugo, Javiera Catalina\n\n\n\nRivera Valenzuela, Luis Felipe\n\n\n\nSalas Aguilar, Maximiliano Alonso\n\n\n\nThumala Raposo, Daniel\n\n\n\nTsukame Díaz, Amalia Victoria\n\n\nJaviera González\nBuzio Aranda, Martina Javiera\n\n\n\nCantillana Olave, Muriel Noelia\n\n\n\nFerrel Higuera, Benjamin Tomas Alexandre\n\n\n\nFigueroa Tengner, Nino\n\n\n\nMancilla Chaparro, Benjamín Patricio\n\n\n\nMansilla Fuentes, Violeta Del Rosario\n\n\n\nOuterbridge Ortega, Nicolás Eduardo\n\n\n\nRojas Murúa, Vicente Ignacio de Jesús\n\n\n\nRojas Santander, Matías Nicolás\n\n\n\nVillatoro Cepeda, Martina Alejandra\n\n\nJesús Díaz M.\nArias Acuña, Antonio Domingo\n\n\n\nConsuegra Erazo, Lucas Andrés\n\n\n\nJiménez Miranda, Constanza María\n\n\n\nJiménez Morales, Rosita Monserrat\n\n\n\nJullian Corral, Maite Ayelen\n\n\n\nMuñoz Caniuqueo, Ignacio Benjamín\n\n\n\nOsorio Huerta, Francisca Andrea\n\n\n\nPlaza Spate, Cristóbal Ignacio\n\n\n\nVenegas Moya, Alonso Elessar\n\n\nLuis Rios\nBalmaceda Yankovic, Bianca\n\n\n\nCaballero Salazar, Amador\n\n\n\nCanales Llanquitrú, Carla Jacqueline\n\n\n\nGaete Morgado, Paulina Andrea\n\n\n\nGatica Pailacura, Carolina Paz\n\n\n\nMartin Gerdes, Bastián Javier\n\n\n\nMena Rojas, Martín Elías\n\n\n\nValencia Almendras, Isidora Paz\n\n\n\nVásquez Olivares, Catalina Ignacia\n\n\nMaría Fernanda Núñez G.\nCalderón Guajardo, Elisa Amanda\n\n\n\nFlores Fuentes, Matías Gabriel\n\n\n\nGallo Novoa, Emilia Antonia\n\n\n\nLagos Zúñiga, Martina Jacinta\n\n\n\nLatorre González, Camila Ignacia\n\n\n\nPoblete Duarte, José Patricio\n\n\n\nRoa Neira, Carla Denisse\n\n\n\nSilva Díaz, Catalina Rosario\n\n\n\nVargas Olivares, Andrés Ignacio\n\n\nSophia Karoussis P.\nBascuñán Soto, Marta del Carmen\n\n\n\nBerríos Puentes, Rocío Belén\n\n\n\nFerran Villagra, Catalina Sofía\n\n\n\nGuerrero Tapia, Daniela Sofía\n\n\n\nPalma Valladares, Elisa Victoria\n\n\n\nPeña Gaete, Micaela Fabiana\n\n\n\nRobledo Dávila, Martina Elisa\n\n\n\nSuárez Urbina, Rocío Belén\n\n\n\nVega Gandolfo, Felipe Ignacio\n\n\nVictoria Arias O.\nCanales Calderón, Fernanda Paz\n\n\n\nCarrasco Gomberoff, Benjamín Eitan\n\n\n\nIbarra Domínguez, Asunción Rebeca\n\n\n\nIsla Hernández, Paz Magdalena\n\n\n\nNúñez Pérez, Joaquín Emilio\n\n\n\nReyes Aqueveque, Valeria Patricia\n\n\n\nRivera Sepúlveda, Sofía Belén\n\n\n\nSanta Cruz Claro, Amalia Magdalena\n\n\n\nSoto Ortega, Martina Paz\n\n\n\n\n\n\n\nPor dudas, comentarios o cambios respecto a esta asignación escribir a Andreas Laffert (Apoyo Docente) por UCursos."
  },
  {
    "objectID": "evaluations/prueba2.html",
    "href": "evaluations/prueba2.html",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "",
    "text": "Usted es parte de un equipo de investigación en un centro de estudios que se encuentra analizando cómo ciertos factores sociales se asocian con actitudes políticas. El centro realizó una encuesta y cuenta con una base de datos con las siguientes variables:\nLa base de datos se encuentra aquí: link"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "href": "evaluations/prueba2.html#pregunta-1-en-qué-medida-se-relacionan-los-ingresos-de-las-personas-con-sus-niveles-de-autoritarismo",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?",
    "text": "Pregunta 1 ¿En qué medida se relacionan los ingresos de las personas con sus niveles de autoritarismo?\n1.1 Estime la asociación entre ambas variables utilizando R y genere un diagrama de dispersión (nube de puntos/scatterplot). Corte y pegue el código en el recuadro de abajo. (1p)\n1.2 Interprete el coeficiente de correlación (considerando inferencia estadística, magnitud y sentido del efecto). (3p)"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-2-cómo-se-relacionan-el-nivel-educacional-autoritarismo-y-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?",
    "text": "Pregunta 2: ¿Cómo se relacionan el nivel educacional, autoritarismo y los ingresos?\n2.1 Estime y reporte la matriz de correlaciones de las variables de nivel educacional, autoritarismo y los ingresos. (1p)\n2.2 Tomando en cuenta la Tabla 1 comente sobre el tratamiento de casos perdidos en el cálculo de las correlaciones, así como también del tipo de correlación calculada entre ingresos y educación. (3p)\n\n\n\n\nTabla 1: Distribución de casos perdidos por variable\n\n\n\n\n\n\n\nVariable\nEtiqueta\nn casos perdidos\n% casos perdidos\n\n\n\n\neduc_rec\nNivel educacional\n0\n0%\n\n\ningresos\nIngresos\n150\n15%\n\n\nautoritarismo\nAutoritarismo\n10\n1%"
  },
  {
    "objectID": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "href": "evaluations/prueba2.html#pregunta-3-cómo-se-relaciona-el-nivel-educacional-con-los-ingresos",
    "title": "Evaluación 2 - Estadística Correlacional 2024",
    "section": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?",
    "text": "Pregunta 3: ¿Cómo se relaciona el nivel educacional con los ingresos?\nUtilizando la versión categórica de ingresos:\n3.1 Reporte tabla de contigencia y el calculo de Chi2 (corte y pegue el código). (1p)\n3.2 Interprete el Chi2 en términos de inferencia y magnitud del efecto. (3p)"
  },
  {
    "objectID": "assignment/02-practico.html",
    "href": "assignment/02-practico.html",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "El objetivo de esta guía práctica es realizar una serie de ejercicios de inferencia estadística, tomando como base todos los contenidos de la Unidad 1. En particular, se abordan pruebas de hipótesis para diferencias de medias y direccionales utilizando la prueba t\nLa guía tiene 3 ejercicios. El primero de ellos es un ejemplo, y los ejercicios 2 y 3 se desarrollan de manera autónoma en la sala (también puede ser en grupo).\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.\n\n\n\n\nEn inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#recursos-de-la-práctica",
    "href": "assignment/02-practico.html#recursos-de-la-práctica",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta de Caracterización Socioeconómica (CASEN) del año 2022, elaborada por el Ministerio de Desarrollo Social y Familia. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  CASEN 20222. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos CASEN 2022.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "href": "assignment/02-practico.html#cinco-pasos-para-la-inferencia-estadística",
    "title": "Práctico 2: Intentando rechazar",
    "section": "",
    "text": "En inferencia, las pruebas de hipótesis nos ayudan a determinar si el resultado que obtenemos en nuestra muestra es un efecto real/extensible a la población o un error. Aquí recomendamos una lista de cinco pasos lógicos para enfrentarnos a la inferencia estadística:\n\n\n\n\nPaso\n\n\nDetalle\n\n\n\n\n1\n\n\nFormula \\(H_0\\) y \\(H_A\\) y estipula la dirección de la prueba\n\n\n\n\n2\n\n\nCalcula el error estándar (SE) y el valor estimado de la prueba (ej: Z o t)\n\n\n\n\n3\n\n\nEspecifica la probabilidad de error \\(\\alpha\\) y el valor crítico de la prueba\n\n\n\n\n4\n\n\nContrasta el valor estimado con el valor crítico\n\n\n\n\n5\n\n\nIntrepreta los resultados\n\n\n\nAdemás de estos 5 pasos también existe la posibilidad de calcular un intervalo de confianza, que acompañe la precisión de nuestra estimación.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#formulación-de-hipótesis",
    "href": "assignment/02-practico.html#formulación-de-hipótesis",
    "title": "Práctico 2: Intentando rechazar",
    "section": "1. Formulación de hipótesis",
    "text": "1. Formulación de hipótesis\nEl primer paso es traducir nuestra pregunta a una hipótesis estadística contrastable. Para ello: a) elija el tipo de hipótesis a plantear ¿direccional o no direccional? y b) especifique la hipótesis nula (\\(H_0\\)) e hipótesis alternativa (\\(H_A\\)).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "href": "assignment/02-practico.html#pasos-2-3-y-4-de-una-vez-con-r",
    "title": "Práctico 2: Intentando rechazar",
    "section": "Pasos 2, 3 y 4 de una vez con R",
    "text": "Pasos 2, 3 y 4 de una vez con R\nSiguiendo el ejemplo del Ejercicio 1, utilice el software para generar los estadísticos correspondientes. Contraste sus hipótesis considerando un 95% de confianza y un 99% de confianza. Comente las diferencias en el paso 5.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "2: Test de hipótesis"
    ]
  },
  {
    "objectID": "news/2024-09-30_reporte-notas1.html",
    "href": "news/2024-09-30_reporte-notas1.html",
    "title": "Reporte Evaluación 1",
    "section": "",
    "text": "← News\nEste reporte realiza un análisis de la Evaluación 1 sobre la Unidad 1: Inferencia estadística"
  },
  {
    "objectID": "news/2024-09-30_reporte-notas1.html#solicitudes-de-recorrección",
    "href": "news/2024-09-30_reporte-notas1.html#solicitudes-de-recorrección",
    "title": "Reporte Evaluación 1",
    "section": "Solicitudes de recorrección",
    "text": "Solicitudes de recorrección\n\nEnviar correo a apoyo docente Martín Venegas, martin.venegas@ug.uchile.cl, quien estará coordinando estas solicitudes\nEn el correo:\n\nmencionar pregunta a corregir\nargumento y puntaje esperado\nfoto de la pregunta\n\n\nSolicitudes hasta el miércoles 2 de Octubre 12PM, las solicitudes responderán hasta el lunes 7 de Octubre."
  },
  {
    "objectID": "news/2024-09-30_reporte-notas1.html#etiquetados",
    "href": "news/2024-09-30_reporte-notas1.html#etiquetados",
    "title": "Reporte Evaluación 1",
    "section": "Etiquetados",
    "text": "Etiquetados\n\n# Label variables\n\nprueba1$p1a &lt;- set_label(x = prueba1$p1a, \n                         label = \"Intervalo de Confianza\")\nprueba1$p1b &lt;- set_label(x = prueba1$p1b, \n                         label = \"Error tipo II\")\nprueba1$p1c &lt;- set_label(x = prueba1$p1c, \n                         label = \"Rechazo H0 valor p\")\nprueba1$p2a &lt;- set_label(x = prueba1$p2a, \n                         label = \"Formulación hipótesis\")\nprueba1$p2b &lt;- set_label(x = prueba1$p2b, \n                         label = \"Contraste de prueba t\")\nprueba1$p2c &lt;- set_label(x = prueba1$p2c, \n                         label = \"Intervalo confianza de prueba t\")\nprueba1$nota &lt;- set_label(x = prueba1$nota, \n                         label = \"Nota final\")\nprueba1$asistida &lt;- set_label(x = prueba1$asistida, \n                         label = \"Asistencia Efectiva\")\nprueba1$asist_total &lt;- set_label(x = prueba1$asist_total, \n                         label = \"Asistencia Registrada\")"
  },
  {
    "objectID": "news/2024-09-30_reporte-notas1.html#tabla-descriptiva",
    "href": "news/2024-09-30_reporte-notas1.html#tabla-descriptiva",
    "title": "Reporte Evaluación 1",
    "section": "Tabla descriptiva",
    "text": "Tabla descriptiva\n\nprueba1 %&gt;% descr(., show = c(\"label\",\"range\", \"mean\", \"sd\", \"n\"))%&gt;% kable(.,\"markdown\", digits=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar\nlabel\nn\nmean\nsd\nrange\n\n\n\n\n4\np1a\nIntervalo de Confianza\n70\n0.55\n0.30\n1 (0-1)\n\n\n5\np1b\nError tipo II\n70\n0.31\n0.45\n1 (0-1)\n\n\n6\np1c\nRechazo H0 valor p\n70\n0.81\n0.70\n2 (0-2)\n\n\n7\np2a\nFormulación hipótesis\n70\n1.47\n0.69\n2 (0-2)\n\n\n8\np2b\nContraste de prueba t\n70\n2.59\n1.32\n4 (0-4)\n\n\n9\np2c\nIntervalo confianza de prueba t\n70\n1.26\n0.74\n2 (0-2)\n\n\n3\nnota\nNota final\n70\n4.50\n1.43\n6 (1-7)\n\n\n2\nasistida\nAsistencia Efectiva\n70\n10.16\n1.86\n8 (4-12)\n\n\n1\nasist_total\nAsistencia Registrada\n70\n10.24\n1.81\n8 (4-12)"
  },
  {
    "objectID": "news/2024-09-30_reporte-notas1.html#gráficos-descriptivos",
    "href": "news/2024-09-30_reporte-notas1.html#gráficos-descriptivos",
    "title": "Reporte Evaluación 1",
    "section": "Gráficos descriptivos",
    "text": "Gráficos descriptivos\n\nhist(prueba1$nota)\n\n\n\n\n\n\n\nplot_frq(data = prueba1$nota,type = \"hist\",show.mean = T)\n\n\n\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;%  mutate(notas_cat=cut(nota, breaks=c(-Inf,4,5,6, Inf), labels=c(\"Menor a 4.0\",\"4.0-5.0\",\"5.0-6.0\",\"6.0-7.0\")))\n\nfrq(prueba1$notas_cat, out=\"browser\", show.na = FALSE, title = \"Rangos de notas\")\n\n\nRangos de notas\n\n\nval\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\nMenor a 4.0\n25\n35.71\n35.71\n35.71\n\n\n\n4.0-5.0\n14\n20.00\n20.00\n55.71\n\n\n\n5.0-6.0\n24\n34.29\n34.29\n90.00\n\n\n\n6.0-7.0\n7\n10.00\n10.00\n100.00\n\n\n\ntotal N=70 · valid N=63 · x̄=2.19 · σ=1.04\n\n\n\n\n\n\nprueba1 &lt;- prueba1 %&gt;% dplyr::select(-notas_cat)"
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "R, librerías y versiones",
    "section": "",
    "text": "Trabajar con el software de programación R y el entorno de desarrollo integrado (IDE) RStudio requiere, la mayor parte del tiempo, estar al tanto de actualizaciones tanto de R como de las librerías que utilizamos para el procesamiento y análisis de datos.\nR y sus librerías tienen distintas versiones. No estar al tanto de esto puede generar problemas cuando, por ejemplo, queremos correr algún código que encontramos en internet, no podemos ejecutar el código de un colega o cuando queremos utilizar librerías o herramientas nuevas que nos ofrece la comunidad de R.\nPor tanto, cuando estemos desarrollando una evaluación práctica en RStudio es de suma importancia contar con una versión actualizada de R y de las librerías necesarias que se utilizan en las sesiones prácticas del curso.\nEn esta guía de recursos te dejaremos algunas buenas prácticas para conocer:\n\nCon qué versión de R y librerías estoy trabajando\nCómo reportar las versiones que utilizo a otras personas\nActualizar mi versión de R y librerías necesarias para este curso",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#actualizar-r",
    "href": "resource/install.html#actualizar-r",
    "title": "R, librerías y versiones",
    "section": "Actualizar R",
    "text": "Actualizar R\nEl método más eficiente es descargar una nueva versión de R desde sitio web de R &gt; CRAN.\n\n\n\n\n\n\n\n\n\nEl CRAN que utilizamos es el de la Universidad de Chile. Debes descargar e instalar la versión de R correspondiente a tu sistema operativo. Luego, reinicia tu RStudio. La nueva versión de R se cargará automáticamente.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLa nueva versión de R aparece justo después de instalar R y reiniciar RStudio.",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#actualizar-librerías",
    "href": "resource/install.html#actualizar-librerías",
    "title": "R, librerías y versiones",
    "section": "Actualizar librerías",
    "text": "Actualizar librerías\nLuego de realizar el paso anterior, para installar y llamar a las librerías que utilizamos en el curso usaremos la función p_load() del paquete pacman. Lo genial de esta función es que instala y llama librerías en un solo movimiento, es decir:\n\nsi incluyo una librería que no tengo instalada previamante, p_load() la instala y llama\nsi incluyo una librería que ya tengo instala previamente, p_load() la reconoce y sólo la llama\n\nEn este curso hemos utilizado diversas librerías y las fundamentales para la evaluación 2 son:\n\ntidyverse\nsjPlot\nsjmisc\nkableExtra\npsych\ncorrplot\nbroom\ncar\n\nAlgunos otros paquetes adicionales muy útiles son:\n\ngginference\nggplot2\nhaven\n\nVeamos cómo instalar estas librerías claves para la evaluación 2 y desarrollo del curso.\n\npacman::p_load(tidyverse, # Manipulacion de datos\n               car, # Recodificar\n               sjPlot, # Tablas y graficos\n               sjmisc, # Descriptivos\n               kableExtra, # Tablas\n               psych, # Bivariados\n               corrplot, # Graficos correlacioj\n               broom) # Varios\n\nComprobemos si se instalaron las librerías y qué versiones con sessionInfo()\n\nutils::sessionInfo()\n\nR version 4.3.3 (2024-02-29)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 24.04.1 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.12.0 \nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.12.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: America/Santiago\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] broom_1.0.7      corrplot_0.94    psych_2.4.6.26   kableExtra_1.4.0\n [5] sjmisc_2.8.10    sjPlot_2.8.16    car_3.1-3        carData_3.0-5   \n [9] lubridate_1.9.3  forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4     \n[13] purrr_1.0.2      readr_2.1.5      tidyr_1.3.1      tibble_3.2.1    \n[17] ggplot2_3.5.1    tidyverse_2.0.0  pacman_0.5.1     knitr_1.48      \n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.5       xfun_0.48          htmlwidgets_1.6.4  insight_0.20.5    \n [5] lattice_0.22-6     tzdb_0.4.0         vctrs_0.6.5        tools_4.3.3       \n [9] sjstats_0.19.0     generics_0.1.3     datawizard_0.13.0  parallel_4.3.3    \n[13] fansi_1.0.6        pkgconfig_2.0.3    ggeffects_1.7.2    lifecycle_1.0.4   \n[17] compiler_4.3.3     munsell_0.5.1      mnormt_2.1.1       htmltools_0.5.8.1 \n[21] yaml_2.3.10        Formula_1.2-5      pillar_1.9.0       abind_1.4-8       \n[25] nlme_3.1-166       tidyselect_1.2.1   sjlabelled_1.2.0   digest_0.6.37     \n[29] performance_0.12.3 stringi_1.8.4      fastmap_1.2.0      grid_4.3.3        \n[33] colorspace_2.1-1   cli_3.6.3          magrittr_2.0.3     utf8_1.2.4        \n[37] withr_3.0.1        backports_1.5.0    scales_1.3.0       timechange_0.3.0  \n[41] rmarkdown_2.28     hms_1.1.3          evaluate_1.0.1     viridisLite_0.4.2 \n[45] rlang_1.1.4        glue_1.8.0         xml2_1.3.6         svglite_2.1.3     \n[49] rstudioapi_0.16.0  jsonlite_1.8.9     R6_2.5.1           systemfonts_1.1.0",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#opción-vía-rstudio",
    "href": "resource/install.html#opción-vía-rstudio",
    "title": "R, librerías y versiones",
    "section": "Opción vía Rstudio",
    "text": "Opción vía Rstudio\nSi queremos actualizar una librería en R, lo que podemos hacer es dirigirnos al panel inferior derecho y dar click en la pestaña de “Packages”. Allí, les aparecerá un listado de las librerías que tienen en su computador, una descripción y su versión.\n\n\n\n\n\n\n\n\n\nPara actualizar una librería, podemos seleccionarla y darle click al botón de “Update” y luego “Install Update” a la librería correspondiente. Veamos un ejemplo",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#opción-vía-código",
    "href": "resource/install.html#opción-vía-código",
    "title": "R, librerías y versiones",
    "section": "Opción vía código",
    "text": "Opción vía código\nBien, pero ¿hay otra alternativa? Sí, como todo en R. Una forma sencilla de actualizar una librería o varias es con la función install.packages pero identificando argumentos adicionales. La estructura del código es así: install.packages(\"package_name\", dependencies = TRUE, update = TRUE). Supongamos que queremos actualizar a la versión más de nueva de corrplot:\n\ninstall.packages(\"corrplot\", dependencies = TRUE, update = TRUE)\n\nCon esto, actualizamos manualmente vía código una librería. Para verificarlo podemos, nuevamente, usar sessionInfo() o de las otras maneras que hemos aprendido.",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "resource/install.html#recursos-adicionales",
    "href": "resource/install.html#recursos-adicionales",
    "title": "R, librerías y versiones",
    "section": "Recursos adicionales",
    "text": "Recursos adicionales\nPara más informaciones, sobre R y Rstudio, revisar link de práctico de estadística descriptiva –&gt; link",
    "crumbs": [
      "Recursos",
      "Guías",
      "R, librerías y versiones"
    ]
  },
  {
    "objectID": "assignment/01-practico.html",
    "href": "assignment/01-practico.html",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "",
    "text": "Sesión del miércoles, 20 de agosto de 2025",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#librerías",
    "href": "assignment/01-practico.html#librerías",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Librerías",
    "text": "Librerías\nCargaremos algunas librerías que serán necesarias en las diferentes partes de esta guía práctica:\n\npacman::p_load permite instalarlas automáticamente si no las tienes.\n\n\nif (!require(\"pacman\")) install.packages(\"pacman\") # instalar pacman\n\npacman::p_load(dplyr, # para sintaxis\n               Publish)   # para IC)    \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls())       # para limpiar el entorno de trabajo\n\n\n\n\n\n\n\n¿Qué es un vector en R?\n\n\n\nEn R, un vector es la estructura de datos más básica:\n\nEs una colección ordenada de valores del mismo tipo (números, caracteres o lógicos).\nPor ejemplo, una columna en una base de datos",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#curvas-de-distribución",
    "href": "assignment/01-practico.html#curvas-de-distribución",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Curvas de distribución",
    "text": "3.1. Curvas de distribución\nPor distribución nos referimos al conjunto de todos los valores posibles de una variable y las frecuencias (o probabilidades) con las que se producen.\nExisten distribuciones empíricas y distribuciones teóricas, en donde:\n\nlas primeras reflejan la distribución de los valores que asume la variable en un grupo concreto a partir de una observación.\nlas segundas son una función matématica que expresan la distribución de un conjunto de números mediante su probabilidad de ocurencia.\n\nEstas últimas son también llamadas curvas de distribución.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-1",
    "href": "assignment/01-practico.html#distribución-normal-1",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.2. Distribución Normal",
    "text": "3.2. Distribución Normal\nEs una distribución teórica que corresponde a una curva que representa la distribución de los casos de la población en torno al promedio y con una varianza conocida.\n\nSimétricas y con un solo punto de elevación\nLa pendiente es más fuerte cerca del centro, y se suaviza hacia los extremos\nCoinciden al centro el promedio, la mediana y la moda\nLa desviación estandar expresa su dispersión.\nEstablece áreas o proporciones bajo la curva en base a desviaciones estándar del promedio.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#distribución-normal-estándar",
    "href": "assignment/01-practico.html#distribución-normal-estándar",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.3. Distribución Normal Estándar",
    "text": "3.3. Distribución Normal Estándar\nLa distribución normal estándar es una distribución normal con una media de 0 y una desviación estándar de 1.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "href": "assignment/01-practico.html#puntaje-z-y-estandarización-de-variables",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.4. Puntaje Z y estandarización de variables",
    "text": "3.4. Puntaje Z y estandarización de variables\nAl estandarizar las variables (como en la Curva Normal Estándar) lo que hacemos es expresar el valor de una distribución en términos de desviaciones estándar basados en la distribución normal. Esto nos permite comparar distribuciones distintas.\nAl valor estandarizado lo llamamos puntaje Z, y corresponde a la cantidad de desviaciones estándar que nos alejamos del promedio (para cada variable con la que trabajemos).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "href": "assignment/01-practico.html#cálculo-de-probabilidades-con-puntaje-z",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "2.1. Cálculo de probabilidades con puntaje Z",
    "text": "2.1. Cálculo de probabilidades con puntaje Z\n\n# Estandarizar el vector\nz_scores &lt;- scale(vector)\n\n# Comparar valores originales y estandarizados\nhead(data.frame(Valor=vector, Z=z_scores), 10)\n\n      Valor           Z\n1  3.879049 -0.71304802\n2  4.539645 -0.35120270\n3  8.117417  1.60854170\n4  5.141017 -0.02179795\n5  5.258575  0.04259548\n6  8.430130  1.77983218\n7  5.921832  0.40589817\n8  2.469878 -1.48492941\n9  3.626294 -0.85149566\n10 4.108676 -0.58726835\n\n\nLos valores estandarizados o puntajes Z además nos permiten conocer probabilidades.\nCon R es posible generar un conjunto de datos simulados con una distribución normal.\n\nx_values &lt;- seq(-4,4,length=1000)\ny_values &lt;- dnorm(x_values)\nplot(x_values,y_values,type=\"l\",xlab=\"Valor Z\",ylab=\"Probabilidad\",main=\"Distribución Normal\")\n\n\n\n\n\n\n\n\nPodemos preguntar qué parte de la curva cae por debajo de un valor particular. Por ejemplo, preguntaremos sobre el valor 0 antes de ejecutar el código. Piense ¿cuál debería ser la respuesta?\n\n# Probabilidades acumuladas\npnorm(0)       # P(Z &lt;= 0)\n\n[1] 0.5\n\n\nAhora probemos los valores Z de +1,96 y -1,96.\nSabemos que estos valores aproximados marcan el 2,5% superior e inferior de la distribución normal estándar. Esto corresponde a un alfa típico \\(\\alpha = 0,05\\) para una prueba de hipótesis de dos colas.\n\npnorm(1.96)    # P(Z &lt;= 1.96)\n\n[1] 0.9750021\n\npnorm(-1.96)   # P(Z &lt;= -1.96)\n\n[1] 0.0249979\n\n\nLa respuesta nos dice lo que ya sabemos: el 97,5% de la distribución normal ocurre por debajo del valor z de 1,96.\ny si lo visualizamos:\n\nplot(x_values, y_values, type=\"l\", lty=1, xlab=\"Z value\", ylab=\"Probability\", main=\"Normal Distribution\") +\nabline(v = 1.96)\n\n\n\n\n\n\n\n\ninteger(0)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "href": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Cálculo de intervalos de confianza",
    "text": "3.1. Cálculo de intervalos de confianza\nEn el caso de nuestro vector aleatorio, un intervalo de confianza para la media se puede calcular de la siguiente manera:\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1] 4.818567 5.543057\nattr(,\"conf.level\")\n[1] 0.95\n\n\n\nIC para Medias\n\nPublish::ci.mean(vector, alpha = 0.01)\n\n mean CI-99%     \n 5.18 [4.70;5.66]\n\n\nContamos con una media 5.18 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre 4.82 y 5.54.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/06-practico.html",
    "href": "assignment/06-practico.html",
    "title": "Tablas en reportes dinámicos",
    "section": "",
    "text": "El objetivo de esta guía práctica es aprender cómo generar, reportar y referenciar tablas en documentos dinámicos mediante Quarto.\n\n\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#recursos-de-la-práctica",
    "href": "assignment/06-practico.html#recursos-de-la-práctica",
    "title": "Tablas en reportes dinámicos",
    "section": "",
    "text": "En esta práctica trabajaremos con un subconjunto de datos previamente procesados derivados de las encuestas realizadas en diferentes países por el Latin American Public Opinion Proyect (LAPOP) en su ola del 2018. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también tienes la opción de acceder a la misma información a través del siguiente enlace:  LAPOP 2018. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos LAPOP 2018.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#chunks",
    "href": "assignment/06-practico.html#chunks",
    "title": "Tablas en reportes dinámicos",
    "section": "Chunks",
    "text": "Chunks\nPara integrar código de R en un archivo Quarto usamos los chunks, que son trozos de código dentro de nuestra hoja. Estos permiten hacer análisis dentro del documento visualizando los resultados en el documento final. Un chunk se especifica mediante una línea de código inicial ```{r}, y se cierra con ```\nLos chunks se ven así dentro del .qmd:\n```{r}\n1 + 1\n```\n\nInsertar chunks\nHay tres formas de insertar chunks:\n\nPulsar ⌘⌥I en macOS o Control + Alt + I en Windows\nPulsa el botón “Insert” en la parte superior de la ventana del editor\n\n\n\n\n\n\n\n\n\n\n\nEscribirlo manualmente\n\n\n\nNombre de chunk\nPara añadir un nombre, inclúyelo inmediatamente después de la {r en la primera línea del chunk. Los nombres no pueden contener espacios, pero sí guiones bajos y guiones.\nImportante: Todos los nombres de chunk de tu documento deben ser únicos.\n```{r nombre-chunk}\n1 + 1\n```\n\n\nOpciones de chunk\nHay distintas opciones diferentes que puedes establecer para cada chunk. Puedes ver una lista completa en la Guía de referencia de RMarkdown o en el sitio web de knitr. Estos recursos se crearon inicialmente para RMarkdown, pero también son aplicables a Quarto.\nEn Quarto, las opciones del chunk van inmediatamente después de la sección {r}. Para especificar una opción, se debe partir con #|, luego la opción y luego el valor lógico. Por ejemplo:\n```{r}\n#| message: false\n#| echo: true\n1 + 1\n```\nOtra forma de hacerlo es configurar las opciones generales de todos los chunks que hagamos al inicio del documento en el YAML:\n\n\n\n\n\n\n\n\n\nDe esta manera ya no es necesario indicar en cada chunk las opciones, y se aplicaran las configuraciones generales que indicamos al comienzo.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#preparación-de-datos",
    "href": "assignment/06-practico.html#preparación-de-datos",
    "title": "Tablas en reportes dinámicos",
    "section": "Preparación de datos",
    "text": "Preparación de datos\nComencemos por preparar nuestros datos. Iniciamos cargando las librerías necesarias.\n\npacman::p_load(tidyverse, # Manipulacion datos\n               sjmisc, # Descriptivos\n               knitr, # Render y tablas\n               kableExtra, # Formateo tablas\n               summarytools, # Tablas\n               sjPlot, # Tablas y gráficos\n               stargazer, # Tablas\n               janitor, # Tablas y formateo\n               crosstable, # Tablas\n               table1 # Tablas\n               ) \n\noptions(scipen = 999) # para desactivar notacion cientifica\nrm(list = ls()) # para limpiar el entorno de trabajo\n\nCargamos los datos desde internet.\n\nload(url(\"https://github.com/cursos-metodos-facso/datos-ejemplos/raw/main/lapop_proc_2018.RData\")) #Cargar base de datos\n\n# Un pequeño procesamiento para algunas variables que usaremos más adelante\nlapop &lt;- lapop %&gt;% mutate(across(c(\"gini\", \"gdp\"), ~ as.numeric(.))) \n\nA continuación, exploramos la base de datos lapop.\n\nnames(lapop) # Nombre de columnas\n\n [1] \"year\"        \"pais\"        \"pais_name\"   \"idnum\"       \"upm\"        \n [6] \"strata\"      \"wt\"          \"weight1500\"  \"sexo\"        \"edad\"       \n[11] \"educ\"        \"l1\"          \"ideologia_f\" \"empleo\"      \"decile\"     \n[16] \"it1\"         \"prot3\"       \"aoj12\"       \"b2\"          \"b3\"         \n[21] \"b4\"          \"b10a\"        \"b12\"         \"b20\"         \"b20a\"       \n[26] \"b21\"         \"b21a\"        \"n9\"          \"n11\"         \"n15\"        \n[31] \"ros4\"        \"ing4\"        \"eff1\"        \"pn4\"         \"exc7\"       \n[36] \"pol1\"        \"vb2\"         \"gini\"        \"gdp\"        \n\ndim(lapop) # Dimensiones\n\n[1] 23386    39\n\n\nContamos con 39 variables (columnas) y 23.386 observaciones (filas).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#funciones-para-tablas-univariadas",
    "href": "assignment/06-practico.html#funciones-para-tablas-univariadas",
    "title": "Tablas en reportes dinámicos",
    "section": "Funciones para tablas univariadas",
    "text": "Funciones para tablas univariadas\nEstas tablas suelen incluir estadísticas descriptivas de una sola variable como medias, medianas, desviaciones estándar, entre otras.\n\nsummarytools:\n\nsummarytools::dfSummary(): Genera un resumen univariado completo de cada variable en el dataset, con estadísticas, frecuencia de valores y gráficos.\n\n\nsummarytools::dfSummary(data_example) %&gt;% \n  summarytools::view(method = \"render\") \n\n\nData Frame Summary\nsummarytools::dfSummary\nDimensions: 23386 x 6\n  Duplicates: 16464\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo\nVariable\nLabel\nStats / Values\nFreqs (% of Valid)\nGraph\nValid\nMissing\n\n\n\n\n1\npais [character]\nPaís\n\n\n\n1. BOL\n\n\n2. COL\n\n\n3. CHL\n\n\n4. URY\n\n\n5. MEX\n\n\n6. HND\n\n\n7. PAN\n\n\n8. ECU\n\n\n9. ARG\n\n\n10. PER\n\n\n[ 5 others ]\n\n\n\n\n\n\n1682\n(\n7.2%\n)\n\n\n1663\n(\n7.1%\n)\n\n\n1638\n(\n7.0%\n)\n\n\n1581\n(\n6.8%\n)\n\n\n1580\n(\n6.8%\n)\n\n\n1560\n(\n6.7%\n)\n\n\n1559\n(\n6.7%\n)\n\n\n1533\n(\n6.6%\n)\n\n\n1528\n(\n6.5%\n)\n\n\n1521\n(\n6.5%\n)\n\n\n7541\n(\n32.2%\n)\n\n\n\n\n23386 (100.0%)\n0 (0.0%)\n\n\n2\nit1 [numeric]\nConfianza Interpersonal\n\n\n\nMean (sd) : 2.7 (1)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 3 ≤ 4\n\n\nIQR (CV) : 1 (0.4)\n\n\n\n\n\n\n1\n:\n2580\n(\n11.3%\n)\n\n\n2\n:\n7157\n(\n31.4%\n)\n\n\n3\n:\n7693\n(\n33.8%\n)\n\n\n4\n:\n5353\n(\n23.5%\n)\n\n\n\n\n22783 (97.4%)\n603 (2.6%)\n\n\n3\nedad [numeric]\nEdad\n\n\n\nMean (sd) : 40.5 (16.8)\n\n\nmin ≤ med ≤ max:\n\n\n16 ≤ 38 ≤ 99\n\n\nIQR (CV) : 25 (0.4)\n\n\n\n81 distinct values\n\n23372 (99.9%)\n14 (0.1%)\n\n\n4\nsexo [factor]\nSexo\n\n\n\n1. Hombre\n\n\n2. Mujer\n\n\n\n\n\n\n11634\n(\n49.8%\n)\n\n\n11739\n(\n50.2%\n)\n\n\n\n\n23373 (99.9%)\n13 (0.1%)\n\n\n5\ngini [numeric]\n\n\n\n\nMean (sd) : 45.8 (4)\n\n\nmin ≤ med ≤ max:\n\n\n38 ≤ 45.7 ≤ 53.3\n\n\nIQR (CV) : 6.1 (0.1)\n\n\n\n15 distinct values\n\n23386 (100.0%)\n0 (0.0%)\n\n\n6\ngdp [numeric]\n\n\n\n\nMean (sd) : 8.7 (4.3)\n\n\nmin ≤ med ≤ max:\n\n\n2.5 ≤ 8 ≤ 16\n\n\nIQR (CV) : 7.2 (0.5)\n\n\n\n15 distinct values\n\n23386 (100.0%)\n0 (0.0%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.3)2024-11-12\n\n\n\n\nsummarytools::descr(): Proporciona estadísticas descriptivas para variables numéricas.\n\n\nsummarytools::descr(data_example$edad) %&gt;%\n  summarytools::view(method = \"render\")\n\nError : Can't find summarytools\n\n\n\nDescriptive Statistics\nvalue\nLabel: Edad\n  N: 23386\n\n\n\n\n\n\nvalue\n\n\n\n\nMean\n40.46\n\n\nStd.Dev\n16.80\n\n\nMin\n16.00\n\n\nQ1\n27.00\n\n\nMedian\n38.00\n\n\nQ3\n52.00\n\n\nMax\n99.00\n\n\nMAD\n17.79\n\n\nIQR\n25.00\n\n\nCV\n0.42\n\n\nSkewness\n0.57\n\n\nSE.Skewness\n0.02\n\n\nKurtosis\n-0.58\n\n\nN.Valid\n23372\n\n\nPct.Valid\n 99.94\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.3)2024-11-12\n\n\n\n\n\nstargazer:\n\nstargazer::stargazer(): Para reportar estadísticas descriptivas.\n\nstargazer(as.data.frame(data_example), type = \"html\", summary.stat = c(\"mean\", \"sd\", \"min\", \"max\"))\n\n\n\n\n\n\n\nStatistic\n\n\nMean\n\n\nSt. Dev.\n\n\nMin\n\n\nMax\n\n\n\n\n\n\n\n\nit1\n\n\n2.694\n\n\n0.953\n\n\n1\n\n\n4\n\n\n\n\nedad\n\n\n40.461\n\n\n16.798\n\n\n16\n\n\n99\n\n\n\n\ngini\n\n\n45.778\n\n\n4.043\n\n\n38.000\n\n\n53.300\n\n\n\n\ngdp\n\n\n8.748\n\n\n4.278\n\n\n2.475\n\n\n16.038\n\n\n\n\n\n\n\n\n\npsych:\n\npsych::describe(): Calcula estadísticas descriptivas adicionales, como curtosis y asimetría.\n\n\npsych::describe(data_example) %&gt;%\n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\n\nvars\nn\nmean\nsd\nmedian\ntrimmed\nmad\nmin\nmax\nrange\nskew\nkurtosis\nse\n\n\n\n\npais*\n1\n23386\n7.950911\n4.3253391\n8.000000\n7.935810\n5.930400\n1.00000\n15.00000\n14.00000\n0.0201754\n-1.2152000\n0.0282841\n\n\nit1\n2\n22783\n2.694333\n0.9532423\n3.000000\n2.742909\n1.482600\n1.00000\n4.00000\n3.00000\n-0.1424032\n-0.9507169\n0.0063154\n\n\nedad\n3\n23372\n40.460551\n16.7983821\n38.000000\n39.158199\n17.791200\n16.00000\n99.00000\n83.00000\n0.5674996\n-0.5770780\n0.1098802\n\n\nsexo*\n4\n23373\n1.502246\n0.5000057\n2.000000\n1.502808\n0.000000\n1.00000\n2.00000\n1.00000\n-0.0089842\n-2.0000048\n0.0032705\n\n\ngini\n5\n23386\n45.777846\n4.0429160\n45.700000\n45.896141\n4.151280\n38.00000\n53.30000\n15.30000\n-0.2035078\n-0.6251471\n0.0264373\n\n\ngdp\n6\n23386\n8.747801\n4.2779214\n7.997761\n8.634054\n6.045964\n2.47517\n16.03793\n13.56276\n0.2534969\n-1.2525404\n0.0279740\n\n\n\n\n\n\n\n\n\nsjmisc:\n\nsjmisc::frq(): Para tablas de frecuencias detalladas de variables categóricas. Incluye labels.\n\n\nsjmisc::frq(data_example$it1) %&gt;%\n  kable() \n\n\n\n\n\n\n\n\nval\nlabel\nfrq\nraw.prc\nvalid.prc\ncum.prc\n\n\n\n\n1\nNada confiable\n2580\n11.03\n11.32\n11.32\n\n\n2\nPoco confiable\n7157\n30.60\n31.41\n42.74\n\n\n3\nAlgo confiable\n7693\n32.90\n33.77\n76.50\n\n\n4\nMuy confiable\n5353\n22.89\n23.50\n100.00\n\n\nNA\nNA\n603\n2.58\nNA\nNA\n\n\n\n\n\n\n\n\n\n\n\ntable1:\n\ntable1::table1(): Permite ver tanto variables categoricas como numericas en la misma tabla de manera estética\n\n\ntable1::table1(~ factor(sexo) + edad + gini + gdp, data = data_example)\n\n\n\n\n\n\n\n\n\n\nOverall\n(N=23386)\n\n\n\n\nfactor(sexo)\n\n\n\nHombre\n11634 (49.7%)\n\n\nMujer\n11739 (50.2%)\n\n\nMissing\n13 (0.1%)\n\n\nEdad\n\n\n\nMean (SD)\n40.5 (16.8)\n\n\nMedian [Min, Max]\n38.0 [16.0, 99.0]\n\n\nMissing\n14 (0.1%)\n\n\ngini\n\n\n\nMean (SD)\n45.8 (4.04)\n\n\nMedian [Min, Max]\n45.7 [38.0, 53.3]\n\n\ngdp\n\n\n\nMean (SD)\n8.75 (4.28)\n\n\nMedian [Min, Max]\n8.00 [2.48, 16.0]",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#funciones-para-tablas-bivariadas",
    "href": "assignment/06-practico.html#funciones-para-tablas-bivariadas",
    "title": "Tablas en reportes dinámicos",
    "section": "Funciones para tablas bivariadas",
    "text": "Funciones para tablas bivariadas\nLas tablas bivariadas permiten explorar relaciones entre pares de variables, útiles para comparar medias o analizar frecuencias conjuntas en tablas de contingencia.\n\nsjPlot:\n\nsjPlot::tab_xtab(): Produce tablas cruzadas de frecuencias y porcentajes, y es útil para comparar variables categóricas entre grupos.\n\n\nsjPlot::tab_xtab(data_example$pais, data_example$it1, show.row.prc = TRUE)\n\n\n \n País\n ConfianzaInterpersonal\n Total\n \n \n\n Nada confiable\n Poco confiable\n Algo confiable\n Muy confiable\n \n \n \nARG\n1228.1 %\n33122.1 %\n68946 %\n35523.7 %\n1497100 % \n\n \n \nBOL\n22813.9 %\n68141.5 %\n53632.7 %\n19511.9 %\n1640100 % \n\n \n \nBRA\n19313.2 %\n68046.4 %\n29620.2 %\n29620.2 %\n1465100 % \n\n \n \nCHL\n17310.7 %\n38423.6 %\n66440.9 %\n40324.8 %\n1624100 % \n\n \n \nCOL\n1529.3 %\n42826.2 %\n57235 %\n48229.5 %\n1634100 % \n\n \n \nCRI\n1288.7 %\n33923 %\n52035.4 %\n48432.9 %\n1471100 % \n\n \n \nDOM\n17111.8 %\n44030.4 %\n47432.7 %\n36425.1 %\n1449100 % \n\n \n \nECU\n17911.8 %\n58038.2 %\n49432.5 %\n26517.5 %\n1518100 % \n\n \n \nHND\n21914.8 %\n44730.2 %\n35624.1 %\n45730.9 %\n1479100 % \n\n \n \nMEX\n17711.6 %\n52434.4 %\n49732.6 %\n32721.4 %\n1525100 % \n\n \n \nPAN\n22214.5 %\n53034.6 %\n49132.1 %\n28818.8 %\n1531100 % \n\n \n \nPER\n22715.1 %\n64442.7 %\n47531.5 %\n16110.7 %\n1507100 % \n\n \n \nPRY\n14710.1 %\n36525 %\n54037 %\n40727.9 %\n1459100 % \n\n \n \nSLV\n1308.9 %\n48833.5 %\n39727.3 %\n44130.3 %\n1456100 % \n\n \n \nURY\n1127.3 %\n29619.4 %\n69245.3 %\n42828 %\n1528100 % \n\n \n \nTotal\n258011.3 %\n715731.4 %\n769333.8 %\n535323.5 %\n22783100 % \n\nχ2=1306.960 · df=42 · Cramer's V=0.138 · p=0.000 \n\n \n\n\n\n\n\nsummarytools:\n\nsummarytools::ctable(): Para tablas de contingencia que incluyen porcentajes y frecuencias, con opciones de personalización.\n\n\nsummarytools::ctable(data_example$pais, data_example$sexo) %&gt;% \n  summarytools::view(method = \"render\")\n\nError : Can't find summarytools\nError : Can't find summarytools\n\n\n\nCross-Tabulation, Row Proportions\ndata_example$pais * data_example$sexo\n\n\n\n\n\ndata_example$sexo\n\n\n\ndata_example$pais\nHombre\nMujer\n&lt;NA&gt;\nTotal\n\n\n\n\nARG\n758\n(\n49.6%\n)\n770\n(\n50.4%\n)\n0\n(\n0.00%\n)\n1528\n(\n100.0%\n)\n\n\nBOL\n846\n(\n50.3%\n)\n836\n(\n49.7%\n)\n0\n(\n0.00%\n)\n1682\n(\n100.0%\n)\n\n\nBRA\n748\n(\n49.9%\n)\n750\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1498\n(\n100.0%\n)\n\n\nCHL\n813\n(\n49.6%\n)\n824\n(\n50.3%\n)\n1\n(\n0.06%\n)\n1638\n(\n100.0%\n)\n\n\nCOL\n830\n(\n49.9%\n)\n833\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1663\n(\n100.0%\n)\n\n\nCRI\n750\n(\n50.0%\n)\n751\n(\n50.0%\n)\n0\n(\n0.00%\n)\n1501\n(\n100.0%\n)\n\n\nDOM\n753\n(\n49.7%\n)\n761\n(\n50.2%\n)\n2\n(\n0.13%\n)\n1516\n(\n100.0%\n)\n\n\nECU\n760\n(\n49.6%\n)\n764\n(\n49.8%\n)\n9\n(\n0.59%\n)\n1533\n(\n100.0%\n)\n\n\nHND\n778\n(\n49.9%\n)\n782\n(\n50.1%\n)\n0\n(\n0.00%\n)\n1560\n(\n100.0%\n)\n\n\nMEX\n775\n(\n49.1%\n)\n805\n(\n50.9%\n)\n0\n(\n0.00%\n)\n1580\n(\n100.0%\n)\n\n\nPAN\n782\n(\n50.2%\n)\n777\n(\n49.8%\n)\n0\n(\n0.00%\n)\n1559\n(\n100.0%\n)\n\n\nPER\n758\n(\n49.8%\n)\n762\n(\n50.1%\n)\n1\n(\n0.07%\n)\n1521\n(\n100.0%\n)\n\n\nPRY\n755\n(\n49.8%\n)\n760\n(\n50.2%\n)\n0\n(\n0.00%\n)\n1515\n(\n100.0%\n)\n\n\nSLV\n755\n(\n50.0%\n)\n756\n(\n50.0%\n)\n0\n(\n0.00%\n)\n1511\n(\n100.0%\n)\n\n\nURY\n773\n(\n48.9%\n)\n808\n(\n51.1%\n)\n0\n(\n0.00%\n)\n1581\n(\n100.0%\n)\n\n\nTotal\n11634\n(\n49.7%\n)\n11739\n(\n50.2%\n)\n13\n(\n0.06%\n)\n23386\n(\n100.0%\n)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.3.3)2024-11-12\n\n\n\n\n\ncrosstable:\n\ncrosstable::crosstable(): También produce tablas de continencia con opciones de personalización.\n\n\ncrosstable::crosstable(data_example, pais, by = sexo, margin=c(\"row\", \"col\"), total = \"both\") %&gt;% \n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\n.id\nlabel\nvariable\nHombre\nMujer\nNA\nTotal\n\n\n\n\npais\nPaís\nARG\n758 (6.52% / 49.61%)\n770 (6.56% / 50.39%)\n0\n1528 (6.53%)\n\n\npais\nPaís\nBOL\n846 (7.27% / 50.30%)\n836 (7.12% / 49.70%)\n0\n1682 (7.19%)\n\n\npais\nPaís\nBRA\n748 (6.43% / 49.93%)\n750 (6.39% / 50.07%)\n0\n1498 (6.41%)\n\n\npais\nPaís\nCHL\n813 (6.99% / 49.66%)\n824 (7.02% / 50.34%)\n1\n1638 (7.00%)\n\n\npais\nPaís\nCOL\n830 (7.13% / 49.91%)\n833 (7.10% / 50.09%)\n0\n1663 (7.11%)\n\n\npais\nPaís\nCRI\n750 (6.45% / 49.97%)\n751 (6.40% / 50.03%)\n0\n1501 (6.42%)\n\n\npais\nPaís\nDOM\n753 (6.47% / 49.74%)\n761 (6.48% / 50.26%)\n2\n1516 (6.48%)\n\n\npais\nPaís\nECU\n760 (6.53% / 49.87%)\n764 (6.51% / 50.13%)\n9\n1533 (6.56%)\n\n\npais\nPaís\nHND\n778 (6.69% / 49.87%)\n782 (6.66% / 50.13%)\n0\n1560 (6.67%)\n\n\npais\nPaís\nMEX\n775 (6.66% / 49.05%)\n805 (6.86% / 50.95%)\n0\n1580 (6.76%)\n\n\npais\nPaís\nPAN\n782 (6.72% / 50.16%)\n777 (6.62% / 49.84%)\n0\n1559 (6.67%)\n\n\npais\nPaís\nPER\n758 (6.52% / 49.87%)\n762 (6.49% / 50.13%)\n1\n1521 (6.50%)\n\n\npais\nPaís\nPRY\n755 (6.49% / 49.83%)\n760 (6.47% / 50.17%)\n0\n1515 (6.48%)\n\n\npais\nPaís\nSLV\n755 (6.49% / 49.97%)\n756 (6.44% / 50.03%)\n0\n1511 (6.46%)\n\n\npais\nPaís\nURY\n773 (6.64% / 48.89%)\n808 (6.88% / 51.11%)\n0\n1581 (6.76%)\n\n\npais\nPaís\nTotal\n11634 (49.78%)\n11739 (50.22%)\n13\n23386 (100.00%)\n\n\n\n\n\n\n\n\n\ntable1:\n\ntable1::table1(): También se puede utilizar agrupando las variables (numericas o categoricas) por alguna variable categórica.\n\n\ntable1::table1(~ factor(sexo) + edad + gini + gdp | pais, data = data_example)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nARG\n(N=1528)\nBOL\n(N=1682)\nBRA\n(N=1498)\nCHL\n(N=1638)\nCOL\n(N=1663)\nCRI\n(N=1501)\nDOM\n(N=1516)\nECU\n(N=1533)\nHND\n(N=1560)\nMEX\n(N=1580)\nPAN\n(N=1559)\nPER\n(N=1521)\nPRY\n(N=1515)\nSLV\n(N=1511)\nURY\n(N=1581)\nOverall\n(N=23386)\n\n\n\n\nfactor(sexo)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHombre\n758 (49.6%)\n846 (50.3%)\n748 (49.9%)\n813 (49.6%)\n830 (49.9%)\n750 (50.0%)\n753 (49.7%)\n760 (49.6%)\n778 (49.9%)\n775 (49.1%)\n782 (50.2%)\n758 (49.8%)\n755 (49.8%)\n755 (50.0%)\n773 (48.9%)\n11634 (49.7%)\n\n\nMujer\n770 (50.4%)\n836 (49.7%)\n750 (50.1%)\n824 (50.3%)\n833 (50.1%)\n751 (50.0%)\n761 (50.2%)\n764 (49.8%)\n782 (50.1%)\n805 (50.9%)\n777 (49.8%)\n762 (50.1%)\n760 (50.2%)\n756 (50.0%)\n808 (51.1%)\n11739 (50.2%)\n\n\nMissing\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n2 (0.1%)\n9 (0.6%)\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n13 (0.1%)\n\n\nEdad\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n41.8 (17.8)\n39.5 (16.3)\n39.1 (16.2)\n42.2 (16.8)\n40.4 (16.3)\n40.5 (16.9)\n40.0 (17.0)\n38.2 (17.1)\n38.2 (16.3)\n42.1 (17.0)\n39.6 (16.2)\n38.8 (15.5)\n40.0 (16.3)\n40.0 (16.6)\n46.2 (17.9)\n40.5 (16.8)\n\n\nMedian [Min, Max]\n39.0 [16.0, 90.0]\n36.0 [18.0, 89.0]\n37.0 [16.0, 92.0]\n40.0 [18.0, 92.0]\n37.0 [18.0, 90.0]\n37.0 [18.0, 89.0]\n37.0 [18.0, 87.0]\n35.0 [16.0, 92.0]\n34.0 [18.0, 89.0]\n40.0 [18.0, 88.0]\n37.5 [18.0, 93.0]\n36.0 [18.0, 91.0]\n37.0 [18.0, 87.0]\n38.0 [18.0, 99.0]\n44.0 [18.0, 95.0]\n38.0 [16.0, 99.0]\n\n\nMissing\n0 (0%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n2 (0.1%)\n9 (0.6%)\n0 (0%)\n0 (0%)\n1 (0.1%)\n1 (0.1%)\n0 (0%)\n0 (0%)\n0 (0%)\n14 (0.1%)\n\n\ngini\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n41.1 (0)\n44.6 (0)\n53.3 (0)\n44.4 (0)\n49.7 (0)\n48.3 (0)\n45.7 (0)\n44.7 (0)\n49.4 (0)\n46.3 (0)\n49.9 (0)\n43.3 (0)\n48.5 (0)\n38.0 (0)\n39.5 (0)\n45.8 (4.04)\n\n\nMedian [Min, Max]\n41.1 [41.1, 41.1]\n44.6 [44.6, 44.6]\n53.3 [53.3, 53.3]\n44.4 [44.4, 44.4]\n49.7 [49.7, 49.7]\n48.3 [48.3, 48.3]\n45.7 [45.7, 45.7]\n44.7 [44.7, 44.7]\n49.4 [49.4, 49.4]\n46.3 [46.3, 46.3]\n49.9 [49.9, 49.9]\n43.3 [43.3, 43.3]\n48.5 [48.5, 48.5]\n38.0 [38.0, 38.0]\n39.5 [39.5, 39.5]\n45.7 [38.0, 53.3]\n\n\ngdp\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n13.1 (0)\n3.29 (0)\n8.58 (0)\n13.9 (0)\n6.27 (0)\n12.5 (0)\n8.00 (0)\n5.95 (0)\n2.48 (0)\n9.95 (0)\n14.9 (0)\n6.57 (0)\n5.87 (0)\n3.92 (0)\n16.0 (0)\n8.75 (4.28)\n\n\nMedian [Min, Max]\n13.1 [13.1, 13.1]\n3.29 [3.29, 3.29]\n8.58 [8.58, 8.58]\n13.9 [13.9, 13.9]\n6.27 [6.27, 6.27]\n12.5 [12.5, 12.5]\n8.00 [8.00, 8.00]\n5.95 [5.95, 5.95]\n2.48 [2.48, 2.48]\n9.95 [9.95, 9.95]\n14.9 [14.9, 14.9]\n6.57 [6.57, 6.57]\n5.87 [5.87, 5.87]\n3.92 [3.92, 3.92]\n16.0 [16.0, 16.0]\n8.00 [2.48, 16.0]\n\n\n\n\n\n\n\n\n\ndplyr y janitor:\n\ndplyr + janitor::tabyl(): Puedes hacer resúmenes bivariados personalizados con count() o group_by(), y tabyl() genera tablas de contingencia de frecuencias para un vistazo rápido.\n\n\ndata_example %&gt;%\n  janitor::tabyl(pais, it1) %&gt;% # Esto reemplaza el procesamiento, buena alternativa\n  kable() %&gt;%\n  kable_styling(full_width = TRUE)\n\n\n\n\npais\n1\n2\n3\n4\nNA_\n\n\n\n\nARG\n122\n331\n689\n355\n31\n\n\nBOL\n228\n681\n536\n195\n42\n\n\nBRA\n193\n680\n296\n296\n33\n\n\nCHL\n173\n384\n664\n403\n14\n\n\nCOL\n152\n428\n572\n482\n29\n\n\nCRI\n128\n339\n520\n484\n30\n\n\nDOM\n171\n440\n474\n364\n67\n\n\nECU\n179\n580\n494\n265\n15\n\n\nHND\n219\n447\n356\n457\n81\n\n\nMEX\n177\n524\n497\n327\n55\n\n\nPAN\n222\n530\n491\n288\n28\n\n\nPER\n227\n644\n475\n161\n14\n\n\nPRY\n147\n365\n540\n407\n56\n\n\nSLV\n130\n488\n397\n441\n55\n\n\nURY\n112\n296\n692\n428\n53",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#a.-tablas",
    "href": "assignment/06-practico.html#a.-tablas",
    "title": "Tablas en reportes dinámicos",
    "section": "a. Tablas",
    "text": "a. Tablas\nPor ejemplo, si queremos referenciar a nuestra tabla1, en el chunk en donde la ejecutemos debemos indicar:\n```{r}\n#| label: tbl-confianza\n\ntabla1\n```\n\ntabla1\nnames(lapop)\n\n [1] \"year\"        \"pais\"        \"pais_name\"   \"idnum\"       \"upm\"        \n [6] \"strata\"      \"wt\"          \"weight1500\"  \"sexo\"        \"edad\"       \n[11] \"educ\"        \"l1\"          \"ideologia_f\" \"empleo\"      \"decile\"     \n[16] \"it1\"         \"prot3\"       \"aoj12\"       \"b2\"          \"b3\"         \n[21] \"b4\"          \"b10a\"        \"b12\"         \"b20\"         \"b20a\"       \n[26] \"b21\"         \"b21a\"        \"n9\"          \"n11\"         \"n15\"        \n[31] \"ros4\"        \"ing4\"        \"eff1\"        \"pn4\"         \"exc7\"       \n[36] \"pol1\"        \"vb2\"         \"gini\"        \"gdp\"        \n\n\n\n\nTabla 1: Confianza interpersonal según país\n\n\n\n\nTabla 1. Confianza interpersonal según país\n\n\nPaís\nNada confiable\nPoco confiable\nAlgo confiable\nMuy confiable\n\n\n\n\nARG\n7.98\n21.66\n45.09\n23.23\n\n\nBOL\n13.56\n40.49\n31.87\n11.59\n\n\nBRA\n12.88\n45.39\n19.76\n19.76\n\n\nCHL\n10.56\n23.44\n40.54\n24.60\n\n\nCOL\n9.14\n25.74\n34.40\n28.98\n\n\nCRI\n8.53\n22.58\n34.64\n32.25\n\n\nDOM\n11.28\n29.02\n31.27\n24.01\n\n\nECU\n11.68\n37.83\n32.22\n17.29\n\n\nHND\n14.04\n28.65\n22.82\n29.29\n\n\nMEX\n11.20\n33.16\n31.46\n20.70\n\n\nPAN\n14.24\n34.00\n31.49\n18.47\n\n\nPER\n14.92\n42.34\n31.23\n10.59\n\n\nPRY\n9.70\n24.09\n35.64\n26.86\n\n\nSLV\n8.60\n32.30\n26.27\n29.19\n\n\nURY\n7.08\n18.72\n43.77\n27.07\n\n\n\na Fuente: Elaboración propia en base a LAPOP 2018.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn este caso, a nuestra tabla le daremos el nombre de confianza más el prefijo tbl-. Y para referenciar dentro de un texto a la tabla usamos: @tbl-confianza.\nTexto de ejemplo:\n\nEn la Tabla 1 se muestra la distribución porcentual del grado de confianza interpersonal por país.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/06-practico.html#b.-resultados",
    "href": "assignment/06-practico.html#b.-resultados",
    "title": "Tablas en reportes dinámicos",
    "section": "b. Resultados",
    "text": "b. Resultados\nTambién podemos referenciar a resultados estadísticos que hayamos realizado con anterioridad en nuestro documento.\nComo ejemplo, obtengamos la correlación entre el índice de Gini de los países y su producto interno bruto (PIB) y lo guardamos en un objeto M.\n\nM &lt;- cor(lapop$gini, lapop$gdp)\n\nM\n\n[1] -0.1125219\n\n\nPara referenciar este resultado, usamos en el texto:\n `r `\nDentro de las comillas ’ ’ y después de la letra r, indicamos el nombre del objeto que contiene un resultado. En este caso, para referenciar el resultado indicamos:\n\nTexto de ejemplo:\n\nEl coeficiente de correlación de Pearson entre el índice de Gini y el producto interno bruto es negativo y pequeño = 'r M'.\n\nTexto de resultado:\n\nEl coeficiente de correlación de Pearson entre el índice de Gini y el producto interno bruto es negativo y pequeño = -0.1125219.\n\nEsta opción es especialmente útil cuando estamos escribiendo un análisis de resultados, ya que ante cualqueier contingencia con los datos, no es necesario cambiar los datos en el texto.\nUn uso más avanzado de esta opción es hacer condicional el texto en base al objeto guardado. Por ejemplo:\n\nEl coeficiente de correlación de Pearson entre el índice de Gíni y el producto interno bruto es 'r if(M &gt; 0){\"positivo\"} else {\"negativo\"}' y pequeño = 'r M'.\n\nY el resultado sería:\n\nEl coeficiente de correlación de Pearson entre el índice de Gíni y el producto interno bruto es negativo y pequeño = -0.1125219.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "6: Visualización 1: Tablas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html",
    "href": "assignment/05-practico.html",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "",
    "text": "El objetivo de esta guía práctica es introducir herramientas estadísticas para el análisis de relación entre variables categóricas (nominales).\nEn detalle, aprenderemos a:\n\nAplicar coeficientes de correlación entre variables categóricas (nominales-ordinales)\nGenerar y analizar tablas de contingencia (o cruzadas)\nEstimar e interpretar la prueba de Chi-cuadrado (\\(X^2\\))\nInterpretar medidas de magnitud para pruebas con variables categóricas\nRealizar pruebas de hipótesis para proporciones\n\nEn esta guía utilizaremos un ejemplo que desarrollaremos progresivamente para exponer los contenidos. Al final de esta guía se proporciona un ejercicio autónomo que deberá resolver de manera individual o grupal tomando como referencia el ejemplo aquí expuesto.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#recursos-de-la-práctica",
    "href": "assignment/05-practico.html#recursos-de-la-práctica",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "Recursos de la práctica",
    "text": "Recursos de la práctica\nEn esta práctica trabajaremos con un subconjunto de datos previamente procesados de la Encuesta Social Longitudinal de Chile (ELSOC) para Chile del año 2019. Para este ejercicio, obtendremos directamente esta base desde internet. No obstante, también es posible acceder a la misma información a través del siguiente enlace:  ELSOC 2019. Desde allí, podrás descargar el archivo que contiene el subconjunto procesado de la base de datos ELSOC 2019.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#correlación-para-variables-nominales",
    "href": "assignment/05-practico.html#correlación-para-variables-nominales",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.1 Correlación para variables nominales",
    "text": "3.1 Correlación para variables nominales\n\n3.1.1 Correlación punto biserial\nLa correlación punto biserial es una extensión del coeficiente de correlación de Pearson y se utiliza cuando una de las variables de estudio tienen un nivel de medición intervalar y la otra un nivel de medición nominal.\n\nEl nombre de punto biserial es una forma de diferenciarla de la correlación de Pearson\nEsta diferenciación es importante ya que nos prevee de que hay que tener consideraciones con su interpretación, particularmente en lo que refiere al sentido\nEn lo que respecta a la magnitud/tamaño y la inferencia, sigue la misma lógica que hemos visto con la correlación de Pearson\n\nPara calcular este coeficiente en R utilizamos una función ya conocida: cor.test(). Probemoslo con las variables jv_cambio_rec e ingreso.\nPrimero, veamos la frecuencia de jv_cambio_rec e ingreso.\n\nsjmisc::frq(proc_elsoc$jv_cambio_rec)\n## Justificación de la violencia por el cambio social (binario) (x) &lt;numeric&gt; \n## # total N=3417 valid N=3405 mean=0.25 sd=0.43\n## \n## Value |        Label |    N | Raw % | Valid % | Cum. %\n## ------------------------------------------------------\n##     0 | No justifica | 2554 | 74.74 |   75.01 |  75.01\n##     1 |    Justifica |  851 | 24.90 |   24.99 | 100.00\n##  &lt;NA&gt; |         &lt;NA&gt; |   12 |  0.35 |    &lt;NA&gt; |   &lt;NA&gt;\n\nmean(proc_elsoc$ingreso, na.rm = TRUE)\n## [1] 537927.2\n\nObtengamos la correlación punto biserial entre el ingreso y la justificación de la violencia por el cambio social.\n\ncor.test(proc_elsoc$jv_cambio_rec, proc_elsoc$ingreso)\n\n\n    Pearson's product-moment correlation\n\ndata:  proc_elsoc$jv_cambio_rec and proc_elsoc$ingreso\nt = -0.51503, df = 2010, p-value = 0.6066\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.05515929  0.03222920\nsample estimates:\n        cor \n-0.01148698 \n\n\nVemos que la correlación entre el ingreso (ingreso) y la justificación de la violencia por el cambio social (jv_cambio_rec) es negativa, muy pequeña y no es estadísticamente significativa (\\(r\\) = -0.01; p &gt; 0.05).\n\n\n3.1.2 Correlación tetracorica\nLa correlación tetracórica también es una extensión del coeficiente de correlación de Pearson, con la diferencia de que se usa cuando ambas variables de estudio son nominales dicotomicas (2 valores).\n\nSe calcula en base a la frecuencias de cada combinación de valores (00,01,10,11).\nSupone que ambas variables son continuas y normalmente distribuidas antes de la categorización\n\nVeamos como vería una correlación tetracórica entre nuestras variables de estudio. En este caso, vamos a usar jv_cambio_rec que ya es dicotomica (1 = Justifica, 0 = No justifica) y una versión recodificada del ingreso ingreso_rec, la cual identifica aquellos entrevistados que tienen un ingreso mayor o menor a 800.000 pesos (1 = Mayor a 800k, 0 = Menor a 800k)\nPrimero, veamos las frecuencias entre jv_cambio_rec e ingreso_rec.\n\nsjmisc::frq(proc_elsoc$jv_cambio_rec)\n## Justificación de la violencia por el cambio social (binario) (x) &lt;numeric&gt; \n## # total N=3417 valid N=3405 mean=0.25 sd=0.43\n## \n## Value |        Label |    N | Raw % | Valid % | Cum. %\n## ------------------------------------------------------\n##     0 | No justifica | 2554 | 74.74 |   75.01 |  75.01\n##     1 |    Justifica |  851 | 24.90 |   24.99 | 100.00\n##  &lt;NA&gt; |         &lt;NA&gt; |   12 |  0.35 |    &lt;NA&gt; |   &lt;NA&gt;\n\nsjmisc::frq(proc_elsoc$ingreso_rec)\n## Ingresos mayores a 800.000 (binario) (x) &lt;numeric&gt; \n## # total N=3417 valid N=2018 mean=0.14 sd=0.34\n## \n## Value |        Label |    N | Raw % | Valid % | Cum. %\n## ------------------------------------------------------\n##     0 | Menor a 800k | 1742 | 50.98 |   86.32 |  86.32\n##     1 | Mayor a 800k |  276 |  8.08 |   13.68 | 100.00\n##  &lt;NA&gt; |         &lt;NA&gt; | 1399 | 40.94 |    &lt;NA&gt; |   &lt;NA&gt;\n\nObtengamos la correlación tetracórica entre jv_cambio_rec e ingreso_rec.\n\nmatriz &lt;- proc_elsoc %&gt;%\n    dplyr::select(jv_cambio_rec, ingreso_rec) # creamos matriz con var de interes\n\npsych::tetrachoric(matriz, na.rm = T)\n\nCall: psych::tetrachoric(x = matriz, na.rm = T)\ntetrachoric correlation \n              jv_c_ ingr_\njv_cambio_rec 1.00       \ningreso_rec   0.02  1.00 \n\n with tau of \njv_cambio_rec   ingreso_rec \n         0.67          1.09 \n\n\nVemos que la correlación entre los ingresos recodificados (ingreso_rec) y la justificación de la violencia por el cambio social (jv_cambio_rec) es positiva y muy pequeña (\\(r\\) = 0.02).",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#tablas-de-contingencia",
    "href": "assignment/05-practico.html#tablas-de-contingencia",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.2 Tablas de contingencia",
    "text": "3.2 Tablas de contingencia\nLas tablas de contingencia son herramientas estadísticas utilizadas para resumir y analizar la relación entre dos o más variables categóricas. Estas tablas muestran la frecuencia de diferentes combinaciones de categorías de las variables, facilitando la visualización de patrones o asociaciones.\nDicho de otra manera, podemos saber cuántos casos de una determinada categoría de la variable \\(Y\\) ocurren conjuntamente con una determinada categoría de la variable \\(X\\).\nVeamos una tabla con nuestro ejemplo usando el comando sjtab.\n\nproc_elsoc %&gt;%\n    sjPlot::sjtab(ingreso_rec,\n        jv_cambio_rec,\n        show.row.prc = TRUE, # porcentaje fila\n        show.col.prc = TRUE # porcentaje columna\n    )\n\n\n \n Ingresos mayores a800.000 (binario)\n Justificación de laviolencia por elcambio social(binario)\n Total\n \n \n\n No justifica\n Justifica\n \n \n \nMenor a 800k\n127373.3 %86.5 %\n46326.7 %85.7 %\n1736100 %86.3 % \n\n \n \nMayor a 800k\n19972.1 %13.5 %\n7727.9 %14.3 %\n276100 %13.7 % \n\n \n \nTotal\n147273.2 %100 %\n54026.8 %100 %\n2012100 %100 % \n\nχ2=0.126 · df=1 · &phi=0.010 · p=0.723 \n\n \n\n\n\nEn esta tabla vemos que los porcentajes coloreados en azul corresponde a las filas y el verde el porcentaje que corresponde a las columnas. Utilizando esta información podemos decir, por ejemplo:\n\n El 72.1% de quienes ganan más de 800k no justifica la violencia por el cambio social \n El 13.5% de quienes no justifican la violencia por el cambio social ganan más de 800k \n\nAhora, ¿cómo sabemos si hay asociación? Repliquemos el ejemplo que vimos en clases, utilizando nuestras variables. Imaginemos que tenemos una base de datos con N = 100.\n\n# Ejemplo de asociación perfecta\ntab1 &lt;- data.frame(\n    \".\" = c(\"Menor a 800k\", \"Mayor a 800k\", \"Total\"),\n    `No justifica` = c(0, 50, 50),\n    \"Justifica\" = c(50, 0, 50),\n    Total = c(50, 50, 100)\n)\n\n# Ejemplo de no asociación\ntab2 &lt;- data.frame(\n    \".\" = c(\"Menor a 800k\", \"Mayor a 800k\", \"Total\"),\n    `No justifica` = c(25, 25, 50),\n    \"Justifica\" = c(25, 25, 50),\n    Total = c(50, 50, 100)\n)\n\nUna distribución con evidencia “perfecta” para nuestra hipótesis alternativa se puede ver en la siguiente tabla:\n\ntab1 %&gt;%\n    kable(format = \"html\", align = \"r\", col.names = c(\"Ingreso\", \"No justifica violencia\", \"Justifica violencia\", \"Total\")) %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = T) %&gt;%\n    kableExtra::kable_styling(latex_options = \"hold_position\", position = \"center\")\n\n\n\n\n\nIngreso\nNo justifica violencia\nJustifica violencia\nTotal\n\n\n\n\nMenor a 800k\n0\n50\n50\n\n\nMayor a 800k\n50\n0\n50\n\n\nTotal\n50\n50\n100\n\n\n\n\n\n\n\n\nEn contraste, una distribución que representaría un caso perfecto de no asociación, se puede ver en la siguiente tabla:\n\ntab2 %&gt;%\n    kable(format = \"html\", align = \"r\", col.names = c(\"Ingreso\", \"No justifica violencia\", \"Justifica violencia\", \"Total\")) %&gt;%\n    kable_styling(bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"), full_width = T) %&gt;%\n    kableExtra::kable_styling(latex_options = \"hold_position\", position = \"center\")\n\n\n\n\n\nIngreso\nNo justifica violencia\nJustifica violencia\nTotal\n\n\n\n\nMenor a 800k\n25\n25\n50\n\n\nMayor a 800k\n25\n25\n50\n\n\nTotal\n50\n50\n100",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#prueba-de-hipótesis-con-chi-cuadrado-x2",
    "href": "assignment/05-practico.html#prueba-de-hipótesis-con-chi-cuadrado-x2",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.3. Prueba de hipótesis con Chi cuadrado (\\(X^2\\))",
    "text": "3.3. Prueba de hipótesis con Chi cuadrado (\\(X^2\\))\nPara determinar si existe una asociación significativa entre dos variables categóricas se utiliza la prueba de Chi-cudrado (\\(X^2\\)). Esta se basa en un test de diferencia, donde se compara nuestra tabla de contingencia y una tabla donde no existe asociación entre variables (\\(H_0\\)), que representa la hipótesis nula. La lógica detrás es que si nuestra tabla es significativamente distinta de una tabla sin asociación, entonces podemos rechazar la hipóteis nula.\n\n\n\n\n\n\nPrueba de Chi-cuadrado\n\n\n\nContrastamos la hipótesis nula (o de trabajo) de que las variables son independientes entre ellas: \\[  H_{0}: \\pi_{fc} =  \\pi_{f}\\pi_{c} \\]\nEn relación a una hipótesis alternativa sobre que las variables están relacionadas: \\[  H_{A}:  \\pi_{fc} \\neq  \\pi_{f}\\pi_{c} \\]\n\n\nEn R, utilizamos la función chisq.test():\n\nchi_results &lt;- chisq.test(proc_elsoc$ingreso_rec, proc_elsoc$jv_cambio_rec)\n\nchi_results\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  proc_elsoc$ingreso_rec and proc_elsoc$jv_cambio_rec\nX-squared = 0.1257, df = 1, p-value = 0.7229\n\n\nObtuvimos nuestro resultado, pero no es muy amigable a la vista. Generemos una tabla de calidad para que sea reportable.\n\nstats.table &lt;- tidy(chi_results)\n\nstats.table %&gt;%\n    dplyr::mutate(\n        statistic = round(statistic, 2),\n        p_value = case_when(\n            p.value &lt; 0.05 & p.value &gt; 0.01 ~ \"&lt; 0.05*\",\n            p.value &lt; 0.01 & p.value &gt; 0.001 ~ \"&lt; 0.01**\",\n            p.value &lt; 0.001 ~ \"&lt; 0.001***\",\n            TRUE ~ \"\"\n        )\n    ) %&gt;%\n    dplyr::select(statistic, p_value, parameter, method) %&gt;%\n    kableExtra::kable(\n        format = \"html\",\n        col.names = c(\"X2\", \"p-value\", \"df\", \"Método\"),\n        booktabs = T,\n        caption = \"Prueba de Chi-cuadrado entre justificación de la violencia por cambio social e injusticia distributiva\"\n    ) %&gt;%\n    kableExtra::kable_styling(\n        bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n        full_width = T,\n        latex_options = \"hold_position\",\n        position = \"center\"\n    ) %&gt;%\n    column_spec(4, width = \"8cm\")\n\n\n\nTabla 1: Prueba de Chi-cuadrado entre justificación de la violencia por cambio social e injusticia distributiva\n\n\n\n\n\n\n\nX2\np-value\ndf\nMétodo\n\n\n\n\n0.13\n\n1\nPearson's Chi-squared test with Yates' continuity correction\n\n\n\n\n\n\n\n\n\n\n\nA partir de estos resultados, podemos reportar lo siguiente:\n\nA raíz de la prueba de \\(X^2\\), vemos que no existe evidencia para rechazar la hipótesis nula sobre no asociación. Por ende, la asociación entre los ingresos y la justificación de la violencia por el cambio social no es estadísticamente significativa (\\(X^2\\) = 0.126, p &gt; 0.05)",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#tamaño-de-efecto-con-phi-y-v-de-cramer",
    "href": "assignment/05-practico.html#tamaño-de-efecto-con-phi-y-v-de-cramer",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "3.4. Tamaño de efecto con Phi y V de Cramer",
    "text": "3.4. Tamaño de efecto con Phi y V de Cramer",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#estadístico-phi-φ",
    "href": "assignment/05-practico.html#estadístico-phi-φ",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "Estadístico Phi (Φ)",
    "text": "Estadístico Phi (Φ)\nEl estadístico Phi mide la asociación entre dos variables categóricas en una tabla de contingencia de 2x2. La fórmula es:\n\\[\n\\Phi = \\sqrt{\\frac{\\chi^2}{n}}\n\\]\ndonde:\n\n\\(\\chi^2\\) es el valor del estadístico chi-cuadrado,\n\\(n\\) es el tamaño total de la muestra.\n\nEl valor de \\(\\Phi\\) varía entre -1 y 1. Un valor de 0 indica ausencia de asociación, mientras que valores cercanos a -1 o 1 indican una asociación más fuerte.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "assignment/05-practico.html#v-de-cramer",
    "href": "assignment/05-practico.html#v-de-cramer",
    "title": "Práctico 5: Asociación entre categóricas",
    "section": "V de Cramer",
    "text": "V de Cramer\nEl V de Cramer es una extensión del estadístico Phi para tablas de contingencia mayores de 2x2. Su fórmula es:\n\\[\nV = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\n\\]\ndonde:\n\n\\(\\chi^2\\) es el valor del chi-cuadrado,\n\\(n\\) es el tamaño de la muestra,\n\\(k\\) es el número de filas o columnas, el que sea menor.\n\nLos valores de \\(V\\) también varían entre 0 y 1, donde 0 indica ausencia de asociación, y valores cercanos a 1 indican una asociación más fuerte.\nEn nuestro ejemplo, nuestra tabla de contingencia es de 2x2, por ende, debemos usar el estadístico Phi. En R lo podemos calcular directamente siguiendo la formula:\n\n# Guardar el test de chi cuadrado\nchi_result &lt;- chisq.test(proc_elsoc$ingreso_rec, proc_elsoc$jv_cambio_rec)\nn &lt;- na.omit(proc_elsoc %&gt;% select(ingreso_rec, jv_cambio_rec)) %&gt;% nrow()\n\n# Cálculo de Phi\nphi &lt;- sqrt(chi_result$statistic / n)\nphi\n\n  X-squared \n0.007904267 \n\n\nCon un valor de 0.008, vemos que la magnitud de la asociación entre las variables es muy baja.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "5: Asociación entre categóricas"
    ]
  },
  {
    "objectID": "news/2025-08-04_inicio.html",
    "href": "news/2025-08-04_inicio.html",
    "title": "Informaciones por acá",
    "section": "",
    "text": "← News\n\n\n\n\nEstimad_s estudiantes, acá en esta pestaña quedará registro de las informaciones y actualizaciones del curso. De todas maneras se enviará link por correo a UCursos cuando haya noticias relevantes."
  },
  {
    "objectID": "syllabus.html#sobre-asistencia-participación-y-comunicación",
    "href": "syllabus.html#sobre-asistencia-participación-y-comunicación",
    "title": "Programa",
    "section": "Sobre asistencia, participación y comunicación",
    "text": "Sobre asistencia, participación y comunicación\n\nAsistencia mínima: 75%, se controlará a la entrada de la clase con código QR (8:30 - tope 8:45). Si no se cumple con asistencia, se pasa directo a examen de primera oportunidad.\nInformar flexibilidades académicas al principio del semestre (en caso que la jefatura de carrera no lo haga de manera centralizada). Las flexibilidades académicas no aplican para cambios de fechas de evaluaciones grupales.\nSe espera y enfatiza la participación activa por distintos canales disponibles. Estos son:\n\ncontacto por correo con equipo docente del curso (profesor y apoyos docentes)\nespacio para resolver dudas individualmente al final de la clase\nreuniones con equipo docente, para lo cual se deben inscribir previamente en la página inicial de este sitio\nforos, disponibles tanto para las clases como para los prácticos.\nmentorías con ayudantes asignados\n\nTambién se enfatiza un trato respetuoso y horizontal. Quienes están tomando este curso serán referidos como participantes y/o estudiantes, evitar el uso de “l_s cabr_s” o “l_s chiquill_s”, que si bien puede intentar transmitir cercanía finalmente expresan un trato paternalista y peyorativo de la contraparte. Quien no se sienta tratad_ apropiadamente o vea que otr_s no lo están siendo, se solicita reportar para solucionar la situación.\nNo se responderán mensajes fuera del horario laboral (incluyendo por supuesto fines de semana)."
  },
  {
    "objectID": "news/2025-08-12_padlet.html",
    "href": "news/2025-08-12_padlet.html",
    "title": "Padlet",
    "section": "",
    "text": "← News\n\n\n\n\n\nVamos a probar Padlet para realizar preguntas sobre los contenidos del curso, se pueden hacer durante o después de clases, pueden ser anónimas.\nLink: https://padlet.com/juancarloscastillo/correlacional\nY acá disponible (con QR):"
  },
  {
    "objectID": "assignment/01-practico.html#revisión-básica-de-r-y-rstudio",
    "href": "assignment/01-practico.html#revisión-básica-de-r-y-rstudio",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Revisión básica de R y RStudio",
    "text": "Revisión básica de R y RStudio\nAntes de comenzar, repasemos algunos puntos clave:\n\n\n\nEstructura de RStudio\n\n\n\nConsola: aquí se pueden escribir y ejecutar comandos de manera directa.\n\nArchivo de código (.R o .qmd): permite guardar el código, comentarios y reproducir el análisis.\n\nEjecutar código:\n\nSelecciona la línea y presiona Ctrl + Enter (Windows/Linux) o Cmd + Enter (Mac).\n\nTambién puedes ejecutar un bloque completo con el botón Run.\n\n\nComentarios: se escriben con #. Todo lo que sigue en la línea después de # no se ejecuta.\n\nAtajos útiles:\n\nCtrl + Shift + C: comentar o descomentar líneas seleccionadas.\n\nCtrl + Shift + J: Añade pipe %&gt;%\nCtrl + L: limpiar la consola.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "assignment/01-practico.html#instrucciones",
    "href": "assignment/01-practico.html#instrucciones",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "Instrucciones",
    "text": "Instrucciones\n\nGenere un vector de datos simulados\n\n\nCree un vector con 500 observaciones distribuidas normalmente\nDebe tener \\(\\mu = 10\\) y \\(\\sigma = 5\\)\n\n\nset.seed(123) # Fijar la semilla para reproducibilidad\nvector2 &lt;- rnorm(500, mean = 10, sd = 5) # cambiamos a vector2 para no confundir con el otro\n\n\nCalcule y describa la distribución\n\n\nObtenga la media y desviación estándar de su vector.\n\n\nmedia &lt;- mean(vector2)\ndesv_estandar &lt;- sd(vector2)\n\ncat(\"Media:\", media, \"\\n\")\n\nMedia: 10.17295 \n\ncat(\"Desviación Estándar:\", desv_estandar, \"\\n\")\n\nDesviación Estándar: 4.863847 \n\n\n\nVisualice la distribución en un histograma\n\n\nhist(vector2,main=\"Histograma del Vector\",xlab=\"Valor\",ylab=\"Frecuencia\",col=\"cyan4\",border=\"black\")\n\n\n\n\n\n\n\n\n\nEstandarice los datos (puntajes Z)\n\n\nTransforme tu vector a puntajes Z usando scale().\n\n\nz_scores2 &lt;- scale(vector2)\n\n\nMuestre los primeros 10 valores (head()).\n\n\n# Comparar valores originales y estandarizados\nhead(data.frame(Valor=vector2, Z=z_scores2), 10)\n\n       Valor           Z\n1   7.197622 -0.61172371\n2   8.849113 -0.27217955\n3  17.793542  1.56678232\n4  10.352542  0.03692339\n5  10.646439  0.09734814\n6  18.575325  1.72751586\n7  12.304581  0.43825984\n8   3.674694 -1.33603268\n9   6.565736 -0.74163858\n10  7.771690 -0.49369607\n\n\n\nMuestre también los últimos 10 valores (tail()).\n\n\n# Comparar valores originales y estandarizados\ntail(data.frame(Valor=vector2, Z=z_scores2), 10)\n\n        Valor          Z\n491  9.471079 -0.1443041\n492 17.020251  1.4077949\n493 16.470420  1.2947503\n494  4.550041 -1.1560626\n495  5.634645 -0.9330695\n496  3.209605 -1.4316543\n497 10.909236  0.1513789\n498 10.824204  0.1338965\n499 11.820573  0.3387486\n500 12.760789  0.5320555\n\n\n\n¿Cuál es el máximo puntaje Z y el mínimo puntaje Z?\n\n\nmax_z &lt;- max(z_scores2)\nmin_z &lt;- min(z_scores2)\n\n\nVerifique la media y sd\n\n\nmean(z_scores2) # Debe ser 0\n\n[1] -1.457272e-16\n\nsd(z_scores2)    # Debe ser 1\n\n[1] 1\n\n\n\nCalcule el intervalo de confianza (IC 95%) para la media\n\n\nEstime el IC para un 95% de confianza\n\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector2)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1]  9.745589 10.600316\nattr(,\"conf.level\")\n[1] 0.95",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  },
  {
    "objectID": "news/2025-08-19_practicos.html",
    "href": "news/2025-08-19_practicos.html",
    "title": "Inicio practicos",
    "section": "",
    "text": "← News\n\n\n\n\n\nEl día Miércoles 20 de agosto vamos a comenzar con la realización de los talleres prácticos de R.\nLos talleres prácticos consisten en guías de trabajo con énfasis en la aplicación práctica de los contenidos mediante el uso de R.\nLa estructura de la sesión será la siguiente:\n\n8:30 en la sala B1 comenzamos con la revisión del taller práctico correspondiente (30min aprox.)\n9:00 tendremos una sección de trabajo autónomo donde podrán aplicar los contenidos vistos en el taller. Para esto, es necesario que cada estudiante asista con su computador personal:\n\nSi asiste con su propio computador, deben traer instalado R (versión 4.5.1), RStudio (versión 2025.05.1+513) y las librerías pacman, dplyr y Publish.\nSi no pueden asistir con su propio computador, tenemos 30 cupos disponibles en la sala 45 del edificio antiguo de FACSO. Para asistir a esta sala deben inscribirse en el siguiente formulario: https://forms.gle/jsFdiWNkjLmCAP5D6"
  },
  {
    "objectID": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza-para-medias",
    "href": "assignment/01-practico.html#cálculo-de-intervalos-de-confianza-para-medias",
    "title": "Distribución Normal e Intervalos de Confianza",
    "section": "3.1. Cálculo de intervalos de confianza para medias",
    "text": "3.1. Cálculo de intervalos de confianza para medias\nEn el caso de nuestro vector aleatorio, un intervalo de confianza para la media se puede calcular de dos maneras:\nPrimero, con la función t.test que, por defecto, estima el intervalo de confianza del 95%\n\n# Calcular un intervalo de confianza para la media\nintervalo_confianza &lt;- t.test(vector)$conf.int  # Intervalo de confianza del 95% para la media\nintervalo_confianza\n\n[1] 4.818567 5.543057\nattr(,\"conf.level\")\n[1] 0.95\n\n\nOtra opción es con la función ci.mean del paquete Publish. Con esta función también podemos especificar si queremos estimar los CI al 95% (alpha = 0.05) o al 99% (alpha = 0.05)\n\nPublish::ci.mean(vector, alpha = 0.05)\n\n mean CI-95%     \n 5.18 [4.82;5.54]\n\n\nContamos con una media 5.18 como estimación puntual. Pero también podemos decir que con un 95% de confianza el parámetro poblacional se encontrará entre 4.82 y 5.54.\n\nPublish::ci.mean(vector, alpha = 0.01)\n\n mean CI-99%     \n 5.18 [4.70;5.66]\n\n\nContamos con una media 5.18 como estimación puntual. Pero también podemos decir que con un 99% de confianza el parámetro poblacional se encontrará entre 4.70 y 5.66.",
    "crumbs": [
      "Prácticos",
      "Guías",
      "1: Curva Normal e Intervalos de Confianza"
    ]
  }
]